[
{
"id": "dva-c02-development-001",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais das seguintes opções são bons casos de uso em que o Amazon ElastiCache pode ajudar uma aplicação? (Selecione DUAS)",
"option_a": "Melhorar a performance de operações S3 PUT.",
"option_b": "Melhorar a latência de implantações realizadas pelo AWS CodeDeploy.",
"option_c": "Melhorar a latência e a taxa de transferência para workloads de leitura intensa.",
"option_d": "Reduzir o tempo necessário para fazer merge de branches do AWS CodeCommit.",
"option_e": "Melhorar a performance de aplicações com uso intensivo de computação.",
"correct_answers": ["C", "E"],
"explanation_detailed": "O Amazon ElastiCache é um cache em memória de alta performance, ideal para reduzir a latência e aumentar a taxa de transferência de workloads de leitura intensa, armazenando dados frequentemente acessados. Ele também pode ajudar aplicações com uso intensivo de computação ao armazenar resultados intermediários, evitando recomputações custosas.",
"incorrect_explanations": {
"A": "Operações S3 PUT são otimizadas pelo próprio S3; o ElastiCache não é usado para acelerar gravações diretas no S3.",
"B": "CodeDeploy não usa ElastiCache para melhorar a latência de deploy; otimização de deploy envolve estratégias de implantação e capacidade, não cache de dados.",
"D": "Merge de branches no CodeCommit é um processo de controle de versão e não se beneficia de um cache de dados como o ElastiCache."
}
},
{
"id": "dva-c02-development-002",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 3,
"active": true,
"question_text": "Quais dos seguintes serviços são armazenamentos chave/valor? (Escolha 3 respostas)",
"option_a": "Amazon ElastiCache.",
"option_b": "Amazon Simple Notification Service (SNS).",
"option_c": "Amazon DynamoDB.",
"option_d": "Amazon Simple Workflow Service (SWF).",
"option_e": "Amazon Simple Storage Service (S3).",
"correct_answers": ["A", "C", "E"],
"explanation_detailed": "ElastiCache armazena dados em memória usando um modelo chave/valor. O DynamoDB é um banco NoSQL onde itens são acessados por chave primária, funcionando efetivamente como chave/valor. O S3 também expõe um modelo chave/valor, em que o nome do objeto (key) aponta para o valor (objeto armazenado).",
"incorrect_explanations": {
"B": "O SNS é um serviço de mensageria pub/sub, não um armazenamento de dados chave/valor.",
"D": "O SWF é um serviço de orquestração de workflows, não é usado como banco de dados chave/valor."
}
},
{
"id": "dva-c02-development-003",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor deseja enviar cabeçalhos de valores múltiplos para uma função AWS Lambda que está registrada como alvo em um Application Load Balancer (ALB). O que o desenvolvedor deve fazer para conseguir isso?",
"option_a": "Colocar a função Lambda e o target group na mesma conta.",
"option_b": "Enviar o corpo da requisição para a função Lambda com tamanho menor que 1 MB.",
"option_c": "Incluir o status de codificação Base64, código de status, descrição do status e cabeçalhos na função Lambda.",
"option_d": "Habilitar multi-value headers no ALB.",
"correct_answers": ["D"],
"explanation_detailed": "Para que o Application Load Balancer encaminhe cabeçalhos com múltiplos valores para a função Lambda, é necessário habilitar o suporte a multi-value headers na configuração do ALB. Isso permite que múltiplos valores para o mesmo cabeçalho sejam preservados e entregues à função.",
"incorrect_explanations": {
"A": "Estar na mesma conta pode ser comum, mas não tem relação com suporte a multi-value headers.",
"B": "Reduzir o tamanho do corpo da requisição não altera o comportamento de cabeçalhos com múltiplos valores.",
"C": "A função pode lidar com codificação e cabeçalhos, mas o recurso de multi-value headers é ativado no ALB, não apenas no código da função."
}
},
{
"id": "dva-c02-development-004",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "O site de e-commerce de uma empresa está sofrendo picos massivos de tráfego, causando problemas de performance no banco de dados. O desenvolvedor quer implementar uma camada de cache usando Amazon ElastiCache. O site deve ser responsivo para qualquer produto visualizado, e as atualizações de informações e preços devem ser fortemente consistentes. Qual política de escrita em cache atende a esses requisitos?",
"option_a": "Escrever diretamente no cache e sincronizar o backend posteriormente.",
"option_b": "Escrever primeiro no backend e aguardar o cache expirar.",
"option_c": "Escrever no cache e no backend ao mesmo tempo.",
"option_d": "Escrever primeiro no backend e invalidar o cache.",
"correct_answers": ["C"],
"explanation_detailed": "Uma política de write-through, em que a aplicação escreve simultaneamente no cache e no backend, garante que o cache e a base de dados fiquem sincronizados, fornecendo forte consistência para leituras subsequentes e mantendo o site responsivo.",
"incorrect_explanations": {
"A": "Escrever apenas no cache e sincronizar depois pode introduzir inconsistência entre cache e backend, o que viola a exigência de forte consistência.",
"B": "Depender apenas da expiração de cache permite que dados obsoletos sejam servidos até o TTL expirar.",
"D": "Invalidar o cache ao escrever no backend força um cache miss na próxima leitura, o que aumenta a latência para o usuário."
}
},
{
"id": "dva-c02-security-005",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor quer fazer upload de dados para o Amazon S3 e precisa criptografar os dados em trânsito. Quais das seguintes soluções irão realizar essa tarefa? (Escolha DUAS)",
"option_a": "Configurar túneis VPN de hardware para uma VPC e acessar o S3 por meio de um endpoint de VPC.",
"option_b": "Configurar criptografia no lado do cliente com uma CMK gerenciada pelo AWS KMS.",
"option_c": "Configurar criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS.",
"option_d": "Transferir os dados por meio de uma conexão SSL.",
"option_e": "Configurar criptografia no lado do servidor com chaves gerenciadas pelo S3.",
"correct_answers": ["A", "D"],
"explanation_detailed": "Criptografia em trânsito significa proteger os dados enquanto trafegam pela rede. Túneis VPN de hardware até a VPC, somados ao acesso via endpoint de VPC, fornecem um canal criptografado para o S3. Além disso, usar HTTPS (SSL/TLS) para transferir dados diretamente para o S3 também garante criptografia em trânsito.",
"incorrect_explanations": {
"B": "Criptografia no lado do cliente protege dados em repouso antes do envio, não trata especificamente da criptografia do canal de transporte.",
"C": "SSE-KMS protege dados em repouso no S3, não lida diretamente com a criptografia em trânsito.",
"E": "SSE-S3 também é para criptografia em repouso e não garante que o canal de transporte esteja criptografado."
}
},
{
"id": "dva-c02-security-006",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor quer criptografar novos objetos que estão sendo enviados para um bucket Amazon S3 por uma aplicação. Deve haver trilha de auditoria de quem usou a chave durante o processo e não deve haver mudança na performance da aplicação. Qual tipo de criptografia atende a esses requisitos?",
"option_a": "Criptografia no lado do servidor usando chaves gerenciadas pelo S3.",
"option_b": "Criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS.",
"option_c": "Criptografia no lado do cliente com uma chave mestra simétrica no cliente.",
"option_d": "Criptografia no lado do cliente com chaves gerenciadas pelo AWS KMS.",
"correct_answers": ["B"],
"explanation_detailed": "A criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS (SSE-KMS) oferece integração com CloudTrail e logs de uso de chaves, permitindo auditoria detalhada. A lógica de criptografia continua no S3, mantendo a performance da aplicação praticamente inalterada.",
"incorrect_explanations": {
"A": "SSE-S3 não fornece trilhas de auditoria detalhadas de uso de chave no KMS.",
"C": "Criptografia no lado do cliente exige alterações na aplicação e gerenciamento local de chaves.",
"D": "Criptografia no lado do cliente com KMS introduz complexidade adicional no cliente e não é necessária se SSE-KMS já atende requisitos."
}
},
{
"id": "dva-c02-security-007",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação está sendo desenvolvida para auditar várias contas AWS. A aplicação será executada na Conta A e deve acessar serviços AWS nas Contas B e C. Qual é a forma MAIS segura de permitir que a aplicação chame serviços AWS em cada conta auditada?",
"option_a": "Configurar roles de cross-account em cada conta auditada. Escrever código na Conta A que assuma essas roles.",
"option_b": "Usar replicação entre regiões do S3 para se comunicar entre contas, com notificações de evento do S3 acionando funções Lambda.",
"option_c": "Implantar uma aplicação em cada conta auditada com sua própria role. Fazer a Conta A autenticar com essa aplicação.",
"option_d": "Criar um usuário IAM com access key em cada conta auditada. Escrever código na Conta A que use essas chaves de acesso.",
"correct_answers": ["A"],
"explanation_detailed": "A forma recomendada e mais segura para acesso entre contas é criar roles de cross-account nas contas B e C e permitir que a aplicação na Conta A use o AWS STS AssumeRole para obter credenciais temporárias. Isso evita o uso de chaves de longo prazo e facilita o controle de permissões.",
"incorrect_explanations": {
"B": "Usar replicação de S3 e notificações é um padrão de integração de dados, não um mecanismo genérico e seguro de acesso a serviços em múltiplas contas.",
"C": "Criar aplicações intermediárias em cada conta adiciona complexidade e não é o padrão nativo de segurança da AWS para cross-account.",
"D": "Usar usuários IAM com chaves de acesso estáticas em múltiplas contas aumenta a superfície de risco e é uma prática desencorajada."
}
},
{
"id": "dva-c02-deployment-008",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa usa uma ferramenta de terceiros para build, empacotamento e armazenamento local de aplicações web. A empresa usa instâncias Amazon EC2 para executar as aplicações front-end. Como a aplicação pode ser implantada do sistema de controle de versão para as instâncias EC2?",
"option_a": "Usar o AWS CodeDeploy e apontá-lo para o armazenamento local para fazer o deploy diretamente de um bundle em formato zip, tar ou tar.gz.",
"option_b": "Fazer upload do bundle para um bucket Amazon S3 e especificar o local no S3 ao fazer um deployment usando o AWS CodeDeploy.",
"option_c": "Criar um repositório usando o AWS CodeCommit para acionar automaticamente um deployment para as instâncias EC2.",
"option_d": "Usar o AWS CodeBuild para fazer deploy automático do último build para as instâncias EC2.",
"correct_answers": ["B"],
"explanation_detailed": "O AWS CodeDeploy espera que os artefatos de aplicação estejam acessíveis a partir de um bucket S3 ou de um repositório Git. Ao fazer upload do bundle para o S3 e referenciá-lo na configuração do CodeDeploy, o serviço consegue distribuir o pacote para as instâncias EC2 durante o deployment.",
"incorrect_explanations": {
"A": "O CodeDeploy não acessa diretamente armazenamento local da empresa; ele precisa de S3 ou Git como origem.",
"C": "Migrar tudo para CodeCommit não é necessário quando uma ferramenta de build de terceiros já produz o bundle pronto.",
"D": "O CodeBuild é voltado para compilar e criar artefatos; ele não é o serviço principal de orquestração de deploy em EC2."
}
},
{
"id": "dva-c02-security-009",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está construindo uma aplicação de uso intensivo de computação que será executada em um fleet de instâncias Amazon EC2. A aplicação usa discos Amazon EBS anexados para armazenar dados e todos os dados devem ser criptografados. O que o desenvolvedor deve fazer para garantir que os dados estejam criptografados em disco sem impactar a performance?",
"option_a": "Configurar o fleet de instâncias EC2 para usar volumes EBS criptografados para armazenamento de dados.",
"option_b": "Adicionar lógica para gravar todos os dados em um bucket Amazon S3 criptografado.",
"option_c": "Adicionar um algoritmo de criptografia customizado na aplicação para criptografar e descriptografar todos os dados.",
"option_d": "Criar uma nova AMI com volume raiz criptografado e armazenar os dados em discos efêmeros.",
"correct_answers": ["A"],
"explanation_detailed": "Volumes EBS criptografados usam criptografia transparente, acelerada por hardware, com impacto mínimo de performance e sem exigir mudanças na aplicação. Isso atende o requisito de dados criptografados em disco com simplicidade.",
"incorrect_explanations": {
"B": "Enviar todos os dados para S3 muda o design da aplicação e não resolve a necessidade de criptografia em disco local.",
"C": "Implementar criptografia customizada aumenta a complexidade e risco de erros, além de consumir CPU da aplicação.",
"D": "Usar discos efêmeros não garante criptografia por padrão e adiciona complexidade desnecessária."
}
},
{
"id": "dva-c02-development-010",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa global tem uma aplicação em instâncias Amazon EC2 que serve arquivos de imagem a partir do Amazon S3. As requisições dos usuários a partir do navegador estão gerando tráfego alto e causando degradação de performance. Qual solução de otimização o desenvolvedor deve implementar para aumentar a performance da aplicação?",
"option_a": "Criar múltiplos prefixes no bucket S3 para aumentar a taxa de requisições.",
"option_b": "Criar um cluster Amazon ElastiCache para cachear e servir itens frequentemente acessados.",
"option_c": "Usar o Amazon CloudFront para servir o conteúdo de imagens armazenadas no Amazon S3.",
"option_d": "Abrir um chamado no suporte da AWS para solicitar aumento de limite de taxa do bucket S3.",
"correct_answers": ["C"],
"explanation_detailed": "O Amazon CloudFront é uma CDN global que distribui e cacheia o conteúdo em edge locations próximas aos usuários, reduzindo a latência e a carga direta no S3, o que melhora sensivelmente a performance da aplicação.",
"incorrect_explanations": {
"A": "Múltiplos prefixes podem ajudar em casos antigos de limite por prefixo, mas não resolvem por si só problemas de latência global.",
"B": "ElastiCache é mais indicado para cache de dados de aplicação, não para distribuição global de arquivos estáticos armazenados no S3.",
"D": "Limites de taxa do S3 geralmente não são o gargalo típico para servir imagens; o uso de CDN é o padrão recomendado."
}
},
{
"id": "dva-c02-security-011",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma função AWS Lambda gera diariamente um arquivo JSON de 3 MB e faz upload para um bucket Amazon S3. O arquivo contém informações sensíveis e o desenvolvedor deve garantir que ele esteja criptografado antes de ser enviado ao bucket. Qual modificação o desenvolvedor deve fazer para garantir que os dados sejam criptografados antes do upload?",
"option_a": "Usar a CMK padrão do AWS KMS para S3 no código da função Lambda.",
"option_b": "Usar a chave gerenciada pelo S3 e chamar a API GenerateDataKey para criptografar o arquivo.",
"option_c": "Usar a API GenerateDataKey e, em seguida, usar essa data key para criptografar o arquivo no código da função Lambda.",
"option_d": "Usar uma CMK customizada criada para o S3 no código da função Lambda.",
"correct_answers": ["C"],
"explanation_detailed": "Para garantir que o arquivo esteja criptografado antes de sair da função, o padrão é usar a API GenerateDataKey do KMS para obter uma chave de dados, criptografar o arquivo localmente na função Lambda e, então, enviar apenas o arquivo já criptografado para o S3.",
"incorrect_explanations": {
"A": "A CMK padrão do KMS para S3 é usada em SSE-KMS no lado do servidor, não garante que o arquivo chegue criptografado à borda da AWS.",
"B": "Chaves gerenciadas pelo S3 (SSE-S3) não usam GenerateDataKey; essa API é de KMS.",
"D": "Apenas usar uma CMK customizada para SSE-KMS não garante criptografia no lado do cliente antes do upload."
}
},
{
"id": "dva-c02-development-012",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "A Empresa D executa seu site corporativo em um bucket Amazon S3 acessado em [http://www.companyd.com](http://www.companyd.com). O time de marketing publicou novas web fonts em um bucket S3 separado acessado pelo endpoint [https://s3-us-west-1.amazonaws.com/cdfonts](https://s3-us-west-1.amazonaws.com/cdfonts). Ao testar as novas fontes, a empresa percebeu que elas estão sendo bloqueadas pelo navegador. O que deve ser feito para evitar esse bloqueio?",
"option_a": "Habilitar versionamento no bucket cdfonts para cada web font.",
"option_b": "Criar uma policy no bucket cdfonts para habilitar acesso para todos.",
"option_c": "Adicionar o cabeçalho Content-MD5 na requisição das web fonts no bucket cdfonts a partir do site.",
"option_d": "Configurar o bucket cdfonts para permitir requisições de origem cruzada criando uma configuração CORS.",
"correct_answers": ["D"],
"explanation_detailed": "Quando um site em um domínio acessa recursos em outro domínio ou endpoint, o navegador aplica regras CORS. Para permitir que o site use as fontes do bucket cdfonts, é necessário configurar CORS no bucket S3 para autorizar essas origens.",
"incorrect_explanations": {
"A": "Versionamento não tem relação com bloqueio de fontes pelo navegador.",
"B": "Tornar o bucket público não resolve as restrições de origem cruzada impostas pelo navegador.",
"C": "O cabeçalho Content-MD5 é para integridade de dados, não para controle de CORS."
}
},
{
"id": "dva-c02-deployment-013",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor precisa estender uma aplicação existente baseada no AWS Serverless Application Model (AWS SAM). O projeto contém diferentes funções AWS Lambda. Qual combinação de comandos deve ser usada para reimplantar a aplicação AWS SAM? (Selecione DUAS)",
"option_a": "sam init.",
"option_b": "sam validate.",
"option_c": "sam build.",
"option_d": "sam deploy.",
"option_e": "sam publish.",
"correct_answers": ["C", "D"],
"explanation_detailed": "Para reimplantar uma aplicação SAM, o fluxo típico é compilar/empacotar os artefatos com sam build e, em seguida, enviar e atualizar a stack com sam deploy. Esses dois comandos cuidam do build e da implantação dos recursos.",
"incorrect_explanations": {
"A": "sam init é usado para inicializar um novo projeto SAM, não para reimplantar uma aplicação existente.",
"B": "sam validate apenas valida o template, mas não executa build nem deployment.",
"E": "sam publish é usado para publicar aplicações no Serverless Application Repository, não é necessário para reimplantar internamente."
}
},
{
"id": "dva-c02-deployment-014",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação implantada no AWS Elastic Beanstalk apresenta aumento na taxa de erros durante deploys de novas versões, resultando em degradação de serviço. O time de desenvolvimento quer mudar a política de deployment para manter capacidade total durante o deploy usando as instâncias existentes. Qual política de implantação atende a esses requisitos?",
"option_a": "All at once.",
"option_b": "Rolling.",
"option_c": "Rolling with additional batch.",
"option_d": "Immutable.",
"correct_answers": ["B"],
"explanation_detailed": "A política Rolling atualiza o ambiente em batches, mantendo parte das instâncias antigas em operação enquanto outras são atualizadas. Isso preserva a capacidade total usando apenas as instâncias existentes, sem criar capacity extra como em Rolling with additional batch.",
"incorrect_explanations": {
"A": "All at once substitui todas as instâncias de uma vez, reduzindo a disponibilidade durante o deploy.",
"C": "Rolling with additional batch precisa de instâncias extras para manter capacidade total, o que contraria o requisito de usar apenas as instâncias existentes.",
"D": "Immutable cria um novo grupo de instâncias, o que aumenta custo e não reutiliza apenas as instâncias existentes."
}
},
{
"id": "dva-c02-development-015",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma aplicação que precisa descobrir o endereço IPv4 público da instância Amazon EC2 em que está sendo executada. Como a aplicação pode localizar essa informação?",
"option_a": "Obter os metadados da instância acessando [http://169.254.169.254/latest/metadata/](http://169.254.169.254/latest/metadata/).",
"option_b": "Obter os user data da instância acessando [http://169.254.169.254/latest/userdata/](http://169.254.169.254/latest/userdata/).",
"option_c": "Fazer a aplicação executar IFCONFIG para obter o endereço IP público.",
"option_d": "Fazer a aplicação executar IPCONFIG para obter o endereço IP público.",
"correct_answers": ["A"],
"explanation_detailed": "A forma recomendada é usar os Instance Metadata, acessando o endpoint 169.254.169.254 a partir da própria instância. Lá estão disponíveis atributos como o endereço IPv4 público.",
"incorrect_explanations": {
"B": "User data contém dados passados na inicialização, não informações dinâmicas como IP público.",
"C": "IFCONFIG mostrará os endereços da interface de rede, normalmente endereços privados, não o IP público atribuído pelo AWS.",
"D": "IPCONFIG é comando de Windows; além disso, também mostra IP local, não necessariamente o IP público da instância."
}
},
{
"id": "dva-c02-refactoring-016",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "O time de desenvolvimento está criando uma API que será servida pelo Amazon API Gateway em três ambientes: desenvolvimento, teste e produção. O API Gateway está configurado para usar 237 GB de cache em todos os três stages. Qual é a estratégia de implantação MAIS econômica?",
"option_a": "Criar um único API Gateway com todos os três stages.",
"option_b": "Criar três API Gateways, um para cada stage, em uma única conta AWS.",
"option_c": "Criar um API Gateway em três contas AWS separadas.",
"option_d": "Habilitar o cache para desenvolvimento e teste apenas quando necessário.",
"correct_answers": ["A"],
"explanation_detailed": "Um único API Gateway com múltiplos stages (dev, test, prod) permite compartilhar a infraestrutura e facilita o gerenciamento, aproveitando melhor os recursos de cache e reduzindo custos em comparação a múltiplos gateways separados.",
"incorrect_explanations": {
"B": "Ter três API Gateways separados aumenta custo e complexidade de gerenciamento sem necessidade.",
"C": "Três contas distintas complicam billing, permissões e não trazem benefício claro para esse cenário.",
"D": "Ligar e desligar cache manualmente em dev e test complica a operação e não é a principal recomendação de arquitetura."
}
},
{
"id": "dva-c02-development-017",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está migrando seu banco de dados on-premises para Amazon RDS for MySQL. A carga é intensiva em leitura e o time quer refatorar o código para obter performance ideal de leitura. Como esse objetivo pode ser alcançado?",
"option_a": "Adicionar tentativas de conexão ao banco para usar o RDS com escalabilidade vertical de forma mais eficaz.",
"option_b": "Usar RDS com implantação Multi-AZ.",
"option_c": "Adicionar uma string de conexão para usar uma read replica do RDS para consultas de leitura.",
"option_d": "Adicionar uma string de conexão para usar uma read replica em uma instância EC2.",
"correct_answers": ["C"],
"explanation_detailed": "Read replicas do RDS são projetadas para escalar leituras, permitindo que consultas de leitura sejam distribuídas entre instâncias secundárias. Ajustar a aplicação para enviar leituras para a read replica melhora a performance sem impactar a instância primária.",
"incorrect_explanations": {
"A": "Mais retries não melhoram performance de leitura, apenas tratam falhas temporárias.",
"B": "Multi-AZ aumenta disponibilidade e resiliência, mas não é voltado a escalar leituras.",
"D": "Uma read replica em EC2 exigiria gerenciamento de replicação manual e não é o padrão recomendado quando RDS já fornece essa funcionalidade."
}
},
{
"id": "dva-c02-development-018",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Dados de aplicação são armazenados em Amazon DynamoDB e processados em batch noturno para análise. Os analistas não querem esperar até o dia seguinte para ver os dados processados e pediram disponibilidade quase em tempo real. Qual padrão de arquitetura de aplicação permite que os dados sejam processados à medida que são recebidos?",
"option_a": "Event driven.",
"option_b": "Client served driven.",
"option_c": "Fan-out driven.",
"option_d": "Schedule driven.",
"correct_answers": ["A"],
"explanation_detailed": "Um padrão dirigido a eventos (event driven) permite reagir às mudanças no momento em que ocorrem, por exemplo usando streams do DynamoDB ou eventos para acionar processamento quase em tempo real.",
"incorrect_explanations": {
"B": "Client served driven não descreve um padrão claro para processamento assíncrono em tempo real.",
"C": "Fan-out é um subtipo de padrão de eventos, mas o enunciado pede o padrão geral que habilita processamento imediato dos dados.",
"D": "Schedule driven refere-se a jobs agendados (como o batch noturno atual), que não resolvem a necessidade de near real-time."
}
},
{
"id": "dva-c02-development-019",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor criou uma aplicação que insere dados em uma tabela Amazon DynamoDB configurada com capacidade provisionada. A aplicação roda em uma instância Amazon EC2 nano burstable. Os logs indicam falhas com o erro ProvisionedThroughputExceedException. Quais ações o desenvolvedor deve tomar para resolver o problema? (Escolha duas.)",
"option_a": "Mover a aplicação para uma instância EC2 maior.",
"option_b": "Aumentar o número de unidades de capacidade de leitura (RCUs) provisionadas para a tabela DynamoDB.",
"option_c": "Reduzir a frequência de requisições ao DynamoDB implementando exponential backoff.",
"option_d": "Aumentar a frequência de requisições ao DynamoDB reduzindo o tempo de retry.",
"option_e": "Alterar o modo de capacidade da tabela DynamoDB de provisionado para sob demanda (on-demand).",
"correct_answers": ["B", "C"],
"explanation_detailed": "O erro ProvisionedThroughputExceedException indica que a tabela está recebendo mais tráfego do que a capacidade provisionada. Aumentar a capacidade (RCUs/WCUs) e implementar exponential backoff nas tentativas reduz o risco de throttling e distribui melhor as requisições ao longo do tempo.",
"incorrect_explanations": {
"A": "Aumentar o tamanho da instância EC2 não resolve o limite de throughput imposto pelo DynamoDB.",
"D": "Aumentar a frequência de requisições reduzindo o delay de retry tende a piorar o problema de throttling.",
"E": "Mudar para on-demand poderia ser uma solução alternativa, mas a pergunta foca em ajustar a tabela provisionada e o padrão recomendado clássico é aumentar capacidade e usar backoff."
}
},
{
"id": "dva-c02-security-020",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa precisa armazenar documentos enviados pelos usuários com segurança em um bucket Amazon S3. Os documentos devem ser criptografados em repouso. A empresa não quer gerenciar a infraestrutura de segurança, mas precisa de proteção extra para manter controle sobre as chaves de criptografia devido a regulações. Qual estratégia de criptografia o desenvolvedor deve usar?",
"option_a": "Criptografia no lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3).",
"option_b": "Criptografia no lado do servidor com chaves fornecidas pelo cliente (SSE-C).",
"option_c": "Criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS (SSE-KMS).",
"option_d": "Criptografia no lado do cliente.",
"correct_answers": ["C"],
"explanation_detailed": "SSE-KMS combina gerenciamento centralizado de chaves no AWS KMS, trilha de auditoria e integração com S3, sem exigir que a empresa mantenha infraestrutura de HSM própria. Isso fornece maior controle sobre chaves do que SSE-S3, atendendo exigências regulatórias.",
"incorrect_explanations": {
"A": "SSE-S3 é simples, mas não oferece o mesmo nível de controle e auditoria de chaves que o KMS.",
"B": "SSE-C exige que o cliente gerencie e envie chaves em cada requisição, aumentando muito a complexidade operacional.",
"D": "Criptografia no lado do cliente transfere toda a responsabilidade de gerenciamento de chaves para a empresa, o que contraria a intenção de usar um serviço gerenciado."
}
},
{
"id": "dva-c02-development-021",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação usa Amazon Kinesis Data Streams para ingerir e processar grandes fluxos de dados em tempo real. Instâncias Amazon EC2 consomem e processam dados dos shards usando a Amazon Kinesis Client Library (KCL). Um shard específico está recebendo mais dados que o esperado e foi feito um resharding. Considerando que o stream tinha inicialmente 4 shards e, após o resharding, passou a ter 6 shards, qual é o número máximo de instâncias EC2 que podem ser implantadas para processar dados de todos os shards?",
"option_a": "12.",
"option_b": "6.",
"option_c": "4.",
"option_d": "1.",
"correct_answers": ["B"],
"explanation_detailed": "Cada worker da KCL é responsável por um ou mais shards, e normalmente se busca um worker por shard para paralelismo máximo. Com 6 shards após o resharding, o máximo de instâncias EC2 que podem ser plenamente utilizadas em paralelo é 6, cada uma processando um shard.",
"incorrect_explanations": {
"A": "12 instâncias excederia o número de shards; algumas instâncias ficariam ociosas ou competindo pelo mesmo shard.",
"C": "4 instâncias limitaram o paralelismo ao número inicial de shards, desperdiçando a divisão extra em 6 shards.",
"D": "1 instância processaria todos os shards, mas não exploraria paralelismo e poderia se tornar gargalo."
}
},
{
"id": "dva-c02-security-022",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa de jogos está desenvolvendo um game mobile para iOS e Android. O jogo armazena dados do usuário localmente no dispositivo e a empresa quer permitir que os usuários usem múltiplos dispositivos, sincronizando seus dados sem precisar criar um backend. Qual serviço deve ser usado para sincronizar dados de usuários entre dispositivos sem criar uma aplicação de backend?",
"option_a": "AWS Lambda.",
"option_b": "Amazon S3.",
"option_c": "Amazon DynamoDB.",
"option_d": "Amazon Cognito.",
"correct_answers": ["D"],
"explanation_detailed": "O Amazon Cognito, por meio de Cognito Sync (ou equivalente moderno com Cognito + backend leve), fornece sincronização de dados de usuário entre dispositivos, junto com autenticação, sem exigir que a empresa mantenha um backend tradicional.",
"incorrect_explanations": {
"A": "Lambda é compute serverless, mas não provê sozinho sincronização de dados entre dispositivos.",
"B": "S3 armazena objetos, mas exigiria lógica de sincronização customizada e um backend para coordenar acessos.",
"C": "DynamoDB é um banco NoSQL, mas ainda exigiria um backend de API para acessar e sincronizar dados."
}
},
{
"id": "dva-c02-deployment-023",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor está fazendo alterações em uma aplicação customizada que usa AWS Elastic Beanstalk. Após concluir as mudanças, quais soluções podem atualizar o ambiente Elastic Beanstalk com a nova versão da aplicação? (Escolha DUAS)",
"option_a": "Empacotar o código da aplicação em um arquivo .zip, fazer upload e depois fazer deploy do pacote pelo AWS Management Console.",
"option_b": "Empacotar o código da aplicação em um arquivo .tar, criar uma nova versão de aplicação pelo AWS Management Console e atualizar o ambiente usando AWS CLI.",
"option_c": "Empacotar o código da aplicação em um arquivo .tar, fazer upload e deploy do pacote pelo AWS Management Console.",
"option_d": "Empacotar o código da aplicação em um arquivo .zip, criar uma nova versão de aplicação a partir do pacote usando AWS CLI e, em seguida, atualizar o ambiente usando AWS CLI.",
"option_e": "Empacotar o código da aplicação em um arquivo .zip, criar uma nova versão de aplicação pelo AWS Management Console e depois rebuildar o ambiente usando AWS CLI.",
"correct_answers": ["A", "D"],
"explanation_detailed": "O Elastic Beanstalk espera pacotes em formato .zip. É possível subir e fazer deploy da nova versão diretamente pelo console (opção A) ou automatizar via AWS CLI, criando a versão de aplicação e atualizando o ambiente (opção D).",
"incorrect_explanations": {
"B": "O formato suportado padrão é .zip; usar .tar não é o fluxo recomendado para EB.",
"C": "Mesma limitação de formato; além disso, a questão destaca o uso suportado de .zip.",
"E": "Rebuildar o ambiente não é necessário apenas para atualizar a versão da aplicação e aumenta a complexidade e o tempo de indisponibilidade."
}
},
{
"id": "dva-c02-development-024",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está executando uma aplicação em funções AWS Lambda. Uma função tem problemas de performance porque precisa baixar um arquivo de 50 MB da Internet a cada execução. Essa função é chamada várias vezes por segundo. Qual solução trará o MAIOR ganho de performance?",
"option_a": "Cachear o arquivo no diretório /tmp.",
"option_b": "Aumentar o tempo máximo de execução da função Lambda.",
"option_c": "Colocar um Elastic Load Balancer na frente da função Lambda.",
"option_d": "Cachear o arquivo no Amazon S3.",
"correct_answers": ["A"],
"explanation_detailed": "O diretório /tmp em Lambda é preservado entre invocações no mesmo ambiente de execução. Ao baixar o arquivo uma vez e cacheá-lo em /tmp, execuções subsequentes podem reutilizar o arquivo localmente, evitando downloads repetidos e melhorando muito a performance.",
"incorrect_explanations": {
"B": "Aumentar o tempo máximo de execução apenas tolera execuções mais lentas, não resolve o gargalo do download repetido.",
"C": "Um load balancer na frente da Lambda não resolve o custo de baixar o arquivo dentro da função.",
"D": "Armazenar no S3 ainda exigiria download em cada invocação; o ganho é pequeno em relação ao cache local em /tmp."
}
},
{
"id": "dva-c02-development-025",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Consultas a uma tabela Amazon DynamoDB estão consumindo grande quantidade de capacidade de leitura. A tabela possui um número significativo de atributos grandes, mas a aplicação não precisa de todos eles. Como os custos podem ser minimizados enquanto a performance é maximizada?",
"option_a": "Agrupar todas as operações de escrita e executá-las quando poucas leituras estiverem sendo realizadas.",
"option_b": "Criar um índice secundário global (GSI) com um conjunto mínimo de atributos projetados.",
"option_c": "Implementar exponential backoff na aplicação.",
"option_d": "Balancear a carga de leituras para a tabela usando um Application Load Balancer.",
"correct_answers": ["B"],
"explanation_detailed": "Projetar um GSI com apenas os atributos necessários reduz a quantidade de dados lidos por consulta, diminuindo o consumo de RCUs e tornando as operações mais baratas e rápidas. A aplicação pode então ler desse índice mais enxuto em vez da tabela completa.",
"incorrect_explanations": {
"A": "Agrupar escritas não ataca o problema de leituras custosas com muitos atributos.",
"C": "Exponential backoff ajuda em throttling, mas não reduz a quantidade de dados lidos por requisição.",
"D": "Um Application Load Balancer não se aplica a DynamoDB; o serviço já é gerenciado e escalável sem ALB."
}
},


{
"id": "dva-c02-development-026",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo um serviço REST que adicionará itens a uma lista de compras. O serviço é construído no Amazon API Gateway com integrações AWS Lambda. Os itens da lista de compras são enviados como parâmetros de query string na requisição do método. Como o desenvolvedor deve converter os parâmetros de query string em argumentos para a função Lambda?",
"option_a": "Habilitar validação de requisição.",
"option_b": "Incluir o Amazon Resource Name (ARN) da função Lambda.",
"option_c": "Alterar o tipo de integração.",
"option_d": "Criar um mapping template.",
"correct_answers": [
"D"
],
"explanation_detailed": "Quando parâmetros vêm na query string e precisam ser mapeados para o payload da função Lambda, usa-se um mapping template no API Gateway. O template transforma os parâmetros de entrada no formato de evento esperado pela função.",
"incorrect_explanations": {
"A": "A validação de requisição garante formato/obrigatoriedade dos parâmetros, mas não faz a transformação em payload para a Lambda.",
"B": "O ARN da Lambda é usado para vincular a integração, não para mapear query string em argumentos.",
"C": "O tipo de integração (por exemplo, Lambda proxy vs non-proxy) não substitui a necessidade de mapeamento explícito quando se quer controle sobre o payload."
}
},
{
"id": "dva-c02-security-027",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um time de desenvolvimento está criando uma nova aplicação para rodar na AWS. Ambientes de teste e produção rodarão em instâncias Amazon EC2, mas cada desenvolvedor terá seu próprio ambiente local no notebook. Qual é a forma mais simples e MAIS segura de acessar serviços AWS a partir das máquinas de desenvolvimento locais?",
"option_a": "Usar uma role IAM para assumir uma role e executar chamadas de API usando essa role.",
"option_b": "Criar um usuário IAM compartilhado com todo o time, fornecendo uma única access key.",
"option_c": "Criar um usuário IAM para cada desenvolvedor do time, fornecendo uma access key única para cada um.",
"option_d": "Configurar uma federação via um user pool do Amazon Cognito.",
"correct_answers": [
"C"
],
"explanation_detailed": "A prática recomendada é dar a cada desenvolvedor um usuário IAM individual com suas próprias credenciais de acesso. Isso permite rastreabilidade, revogação seletiva e aplicação de políticas específicas por usuário.",
"incorrect_explanations": {
"A": "Assumir roles a partir de credenciais ainda exige uma identidade de origem; para notebooks locais, usuários IAM individuais são mais simples e diretos.",
"B": "Compartilhar um único usuário IAM viola boas práticas de segurança e torna auditoria e revogação praticamente impossíveis.",
"D": "Cognito é voltado principalmente para autenticação de usuários de aplicações, não para credenciais administrativas de desenvolvimento em notebooks."
}
},
{
"id": "dva-c02-development-028",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Como o throughput provisionado é afetado pelo modelo de consistência escolhido ao ler dados de uma tabela DynamoDB?",
"option_a": "Leituras fortemente consistentes usam a mesma quantidade de throughput que leituras eventualmente consistentes.",
"option_b": "Leituras fortemente consistentes usam mais throughput do que leituras eventualmente consistentes.",
"option_c": "Leituras fortemente consistentes usam menos throughput do que leituras eventualmente consistentes.",
"option_d": "Leituras fortemente consistentes usam throughput variável dependendo da atividade de leitura.",
"correct_answers": [
"B"
],
"explanation_detailed": "No DynamoDB, uma unidade de capacidade de leitura fortemente consistente consegue ler metade da quantidade de dados de uma unidade eventualmente consistente. Portanto, leituras fortemente consistentes consomem mais throughput para o mesmo volume de dados lidos.",
"incorrect_explanations": {
"A": "Modelos de consistência diferentes têm custos de capacidade diferentes; eles não usam a mesma quantidade de throughput.",
"C": "Fortemente consistente é mais “caro” em termos de RCUs, não mais barato.",
"D": "O throughput consumido é determinístico com base no tamanho dos itens e no tipo de consistência, não “variável” em função da atividade."
}
},
{
"id": "dva-c02-deployment-029",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa implantar uma nova versão de uma aplicação AWS Elastic Beanstalk. Como o desenvolvedor pode realizar essa tarefa?",
"option_a": "Fazer upload e deploy da nova versão da aplicação no console do Elastic Beanstalk.",
"option_b": "Usar o comando de CLI eb init para implantar uma nova versão.",
"option_c": "Encerrar o ambiente atual do Elastic Beanstalk e criar um novo.",
"option_d": "Modificar a pasta .ebextensions para adicionar uma opção de source em services.",
"correct_answers": [
"A"
],
"explanation_detailed": "O fluxo típico é criar uma nova versão da aplicação e implantá-la no ambiente existente a partir do console ou da CLI (por exemplo, eb deploy). Fazer upload e deploy da nova versão no console atende diretamente ao requisito.",
"incorrect_explanations": {
"B": "eb init é usado para inicializar configuração de projeto EB, não para fazer o deploy de uma nova versão.",
"C": "Encerrar o ambiente e recriá-lo é desnecessário e causa mais downtime.",
"D": "Modificar .ebextensions controla configuração do ambiente, não substitui o processo de deploy de nova versão."
}
},
{
"id": "dva-c02-security-030",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um aplicativo de jogos armazena pontuações de jogadores em uma tabela Amazon DynamoDB com quatro atributos: user_id, user_name, user_score e user_rank. Os usuários podem atualizar seus nomes apenas se estiverem autenticados por federação de identidade via web identity. Qual conjunto de condições deve ser adicionado na policy anexada à role para a chamada dynamodb:PutItem?",
"option_a": "Opção A. Question 30 option A.",
"option_b": "Opção B. Question 30 option B.",
"option_c": "Opção C. Question 30 option C.",
"option_d": "Opção D. Question 30 option D.",
"correct_answers": [
"A"
],
"explanation_detailed": "O enunciado original não traz o conteúdo detalhado das opções, apenas referências genéricas (Question 30 option A, etc.). Por isso, a resposta foi marcada como A de forma provisória e este item requer revisão manual com o texto completo das opções para determinar a condição correta.",
"incorrect_explanations": {
"B": "O texto completo da opção B não foi fornecido no enunciado, então não é possível avaliá-la com precisão sem material adicional.",
"C": "Da mesma forma, a opção C é apenas um placeholder no enunciado e não pode ser analisada corretamente neste contexto.",
"D": "A opção D também é um placeholder; a escolha correta deve ser revisada quando a questão completa estiver disponível."
}
},
{
"id": "dva-c02-deployment-031",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor quer ter a capacidade de fazer rollback para uma versão anterior de uma função AWS Lambda em caso de erros causados por um novo deploy, com IMPACTO MÍNIMO para os usuários. Como isso pode ser feito?",
"option_a": "Alterar a aplicação para usar um alias que aponta para a versão atual. Fazer deploy da nova versão do código. Atualizar o alias para usar a nova versão. Se muitos erros forem encontrados, apontar o alias de volta para a versão anterior.",
"option_b": "Alterar a aplicação para usar um alias que aponta para a versão atual. Fazer deploy da nova versão. Atualizar o alias para direcionar 10% dos usuários para a nova versão. Se muitos erros forem encontrados, enviar 100% do tráfego para a versão anterior.",
"option_c": "Não fazer alterações na aplicação. Fazer deploy da nova versão. Se muitos erros forem encontrados, apontar a aplicação de volta para a versão anterior usando o número de versão no ARN.",
"option_d": "Criar três aliases: new, existing e router. Usar o alias router para dividir o tráfego entre new e existing. Ajustar o router para testes e rollback conforme necessário.",
"correct_answers": [
"A"
],
"explanation_detailed": "Usar aliases de Lambda permite apontar a aplicação sempre para um nome estável, enquanto o alias é atualizado entre versões. Atualizar o alias para a nova versão e, em caso de falhas, voltar rapidamente para o alias apontando para a versão anterior oferece rollback simples e com impacto mínimo para os usuários.",
"incorrect_explanations": {
"B": "Direcionar apenas 10% do tráfego é uma estratégia de canary deployment, útil para testes graduais, mas não é a forma mais simples enfatizada na questão.",
"C": "Alterar diretamente o ARN codificado na aplicação é mais propenso a erros e menos flexível do que usar aliases.",
"D": "Três aliases e roteamento indireto aumentam a complexidade desnecessariamente para o cenário descrito."
}
},
{
"id": "dva-c02-refactoring-032",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação contém dois componentes: um para lidar com requisições HTTP e outro para processar tarefas em background. Cada componente deve escalar de forma independente. O desenvolvedor quer implantar essa aplicação usando AWS Elastic Beanstalk. Como ela deve ser implantada com base nesses requisitos?",
"option_a": "Implantar a aplicação em um único ambiente Elastic Beanstalk.",
"option_b": "Implantar cada componente em um ambiente Elastic Beanstalk separado.",
"option_c": "Usar múltiplos ambientes Elastic Beanstalk para o componente HTTP e um único ambiente para o componente de background.",
"option_d": "Usar múltiplos ambientes Elastic Beanstalk para o componente de background e um único ambiente para o componente HTTP.",
"correct_answers": [
"B"
],
"explanation_detailed": "Separar os componentes em ambientes Elastic Beanstalk distintos permite que cada um tenha sua própria configuração de escalabilidade, capacidade e ciclo de vida, atendendo ao requisito de escalarem de forma independente.",
"incorrect_explanations": {
"A": "Um único ambiente faz com que ambos os componentes escalem juntos, o que viola o requisito de escalabilidade independente.",
"C": "Ter múltiplos ambientes apenas para o componente HTTP não resolve a necessidade de escalar o componente de background separadamente.",
"D": "O inverso também não resolve; o requisito é independência de ambos, logo cada componente deve ter seu próprio ambiente."
}
},
{
"id": "dva-c02-deployment-033",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa usa templates AWS CloudFormation para implantar recursos AWS e precisa atualizar um dos stacks. O que a empresa pode fazer para descobrir como as mudanças vão impactar os recursos em execução?",
"option_a": "Analisar os change sets.",
"option_b": "Analisar as stack policies.",
"option_c": "Analisar a seção Metadata.",
"option_d": "Analisar a seção Resources.",
"correct_answers": [
"A"
],
"explanation_detailed": "Change sets mostram uma prévia das alterações que serão aplicadas em um stack CloudFormation, permitindo entender exatamente quais recursos serão criados, modificados ou excluídos antes de executar a atualização.",
"incorrect_explanations": {
"B": "Stack policies controlam quais ações podem ser realizadas em certos recursos, mas não mostram o diff de uma atualização específica.",
"C": "A seção Metadata guarda informações auxiliares, não a comparação entre o estado atual e o pretendido.",
"D": "A seção Resources descreve os recursos desejados, porém não mostra diretamente o impacto da mudança no stack já existente."
}
},
{
"id": "dva-c02-deployment-034",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma aplicação web serverless e mantém diferentes branches de código. Ele quer evitar atualizar o endpoint de destino do Amazon API Gateway sempre que houver um novo push de código. Qual solução permite fazer deploy de código de forma eficiente sem precisar atualizar o API Gateway?",
"option_a": "Associar funções AWS Lambda diferentes a um endpoint de destino do API Gateway.",
"option_b": "Criar diferentes stages no API Gateway e associar o API Gateway com AWS Lambda.",
"option_c": "Criar aliases e versões nas funções AWS Lambda.",
"option_d": "Marcar as funções AWS Lambda com diferentes tags.",
"correct_answers": [
"C"
],
"explanation_detailed": "Ao usar versões e aliases nas funções Lambda, o API Gateway pode apontar para um alias estável (como \"prod\"), enquanto o alias é atualizado para a nova versão da função a cada deploy. Assim, o endpoint do API Gateway permanece o mesmo.",
"incorrect_explanations": {
"A": "Apenas associar funções diferentes não resolve o problema de ter que atualizar o endpoint para apontar para outra função.",
"B": "Stages diferentes ajudam a separar ambientes, mas o problema central é atualizar o destino a cada novo código, o que é melhor resolvido com aliases de versão.",
"D": "Tags servem para organização e filtragem, não para controle de roteamento ou versionamento de execução."
}
},
{
"id": "dva-c02-security-035",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação em instâncias EC2 armazena dados em um bucket S3. A política de segurança exige que todo o tráfego seja criptografado em trânsito. Como o desenvolvedor pode garantir que todo tráfego para o bucket S3 seja criptografado?",
"option_a": "Instalar certificados nas instâncias EC2.",
"option_b": "Criar uma bucket policy que permita tráfego onde SecureTransport é true.",
"option_c": "Criar um redirecionamento HTTPS nas instâncias EC2.",
"option_d": "Criar uma bucket policy que negue tráfego onde SecureTransport é false.",
"correct_answers": [
"D"
],
"explanation_detailed": "A forma mais robusta é aplicar uma bucket policy que negue qualquer requisição em que o campo de contexto aws:SecureTransport seja false. Isso força que todas as chamadas sejam feitas via HTTPS/TLS.",
"incorrect_explanations": {
"A": "Certificados nas instâncias ajudam, mas não impedem que alguém faça chamadas HTTP diretas ao bucket.",
"B": "Permitir apenas SecureTransport true não é suficiente se não houver uma negação explícita para o caso false.",
"C": "Redirecionamentos em EC2 não controlam acesso direto ao bucket S3 por outros clientes ou serviços."
}
},
{
"id": "dva-c02-development-036",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um fornecedor está criando uma nova API RESTful para clientes consultarem o status de pedidos. Os clientes solicitaram o endpoint [http://www.supplierdomain.com/status/customerID](http://www.supplierdomain.com/status/customerID). Quais designs de aplicação atendem a esses requisitos? (Selecione DUAS)",
"option_a": "Amazon SQS; Amazon SNS.",
"option_b": "Elastic Load Balancing; Amazon EC2.",
"option_c": "Amazon ElastiCache; Amazon Elasticsearch Service.",
"option_d": "Amazon API Gateway; AWS Lambda.",
"option_e": "Amazon S3; Amazon CloudFront.",
"correct_answers": [
"B",
"D"
],
"explanation_detailed": "Uma API RESTful pode ser implementada em uma arquitetura tradicional com instâncias EC2 atrás de um Elastic Load Balancer ou de forma totalmente serverless com API Gateway e Lambda. Ambos os desenhos atendem ao padrão de endpoint solicitado.",
"incorrect_explanations": {
"A": "SQS e SNS são serviços de mensageria, não expõem diretamente uma API RESTful HTTP pública.",
"C": "ElastiCache e Elasticsearch são serviços de dados, não frontends HTTP REST completos por si só.",
"E": "S3 e CloudFront são ótimos para conteúdo estático; não são ideais para lógica dinâmica de consulta de status de pedidos."
}
},
{
"id": "dva-c02-development-037",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está projetando uma função AWS Lambda que cria arquivos temporários menores que 10 MB durante a execução. Os arquivos temporários serão acessados e modificados várias vezes durante a execução e não precisam ser salvos depois. Onde esses arquivos devem ser armazenados?",
"option_a": "No diretório /tmp.",
"option_b": "No Amazon EFS.",
"option_c": "No Amazon EBS.",
"option_d": "No Amazon S3.",
"correct_answers": [
"A"
],
"explanation_detailed": "O ambiente de execução da Lambda fornece um sistema de arquivos temporário acessível em /tmp, com tamanho limitado, ideal para arquivos transitórios que só precisam existir durante a execução.",
"incorrect_explanations": {
"B": "EFS é para armazenamento de arquivos de rede persistente, o que é desnecessário para arquivos temporários de uma única execução.",
"C": "EBS é um volume de bloco anexado a instâncias EC2, não ao ambiente serverless da Lambda.",
"D": "S3 é armazenamento de objetos persistente, não adequado para arquivos temporários que não precisam sobreviver à execução."
}
},
{
"id": "dva-c02-development-038",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "O tempo de carregamento de páginas de um website está aumentando gradualmente à medida que mais usuários acessam o sistema simultaneamente. A análise indica que o perfil do usuário é carregado do banco de dados em todas as páginas visitadas por cada usuário, aumentando a carga no banco e a latência. Para resolver, o desenvolvedor decide cachear os perfis de usuário. Qual estratégia de cache atende melhor a essa situação?",
"option_a": "Criar uma nova instância EC2 e executar um banco NoSQL nela. Cachear os perfis usando estratégia write-through.",
"option_b": "Criar um cluster Amazon ElastiCache para cachear os perfis de usuário. Usar estratégia cache-aside.",
"option_c": "Usar uma instância Amazon RDS dedicada para cachear perfis com write-through.",
"option_d": "Criar um cluster ElastiCache para cachear perfis de usuário. Usar write-through.",
"correct_answers": [
"B"
],
"explanation_detailed": "Usar ElastiCache como cache dedicado e aplicar o padrão cache-aside (lazy loading) é eficiente e comum: a aplicação tenta ler do cache e, em caso de miss, busca no banco, atualiza o cache e devolve o resultado.",
"incorrect_explanations": {
"A": "Gerenciar um banco NoSQL em EC2 adiciona complexidade desnecessária quando há um serviço gerenciado de cache disponível.",
"C": "Usar RDS como \"cache\" é um anti-padrão; RDS é um banco relacional, não um cache em memória dedicado.",
"D": "Write-through é possível, mas para perfis que mudam com baixa frequência, cache-aside costuma ser mais simples e econômico."
}
},
{
"id": "dva-c02-refactoring-039",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa de publicidade tem um site dinâmico com tráfego intenso e quer migrar a infraestrutura para a AWS, delegando toda a operação de infraestrutura para a AWS, exceto o desenvolvimento do site. Qual solução atende MELHOR a esses requisitos?",
"option_a": "Usar AWS VM Import para migrar uma imagem de servidor web para a AWS e executá-la em uma instância EC2 otimizada para computação.",
"option_b": "Lançar múltiplas instâncias Amazon Lightsail atrás de um load balancer e configurar o site nelas.",
"option_c": "Implantar o código do site em um ambiente AWS Elastic Beanstalk e usar Auto Scaling para escalar o número de instâncias.",
"option_d": "Usar o Amazon S3 para hospedar o site e o Amazon CloudFront para entregar o conteúdo em escala.",
"correct_answers": [
"C"
],
"explanation_detailed": "O Elastic Beanstalk abstrai grande parte da gestão de infraestrutura (provisionamento, balanceamento, Auto Scaling, monitoramento), permitindo que a equipe foque principalmente no código da aplicação web dinâmica.",
"incorrect_explanations": {
"A": "Migrar uma VM e gerenciar manualmente EC2 não reduz significativamente o esforço operacional.",
"B": "Lightsail é simples, mas não fornece a mesma automação de implantação e escalabilidade que o Beanstalk.",
"D": "S3 + CloudFront é ótimo para sites estáticos; para sites dinâmicos é necessário backend compute adicional."
}
},
{
"id": "dva-c02-monitoring-040",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma função AWS Lambda e quer registrar eventos importantes durante a execução, incluindo um identificador único para associar os eventos a uma invocação específica. O que ajuda o desenvolvedor a atingir esse objetivo?",
"option_a": "Obter o request identifier do objeto de contexto da Lambda e registrar logs no console.",
"option_b": "Obter o request identifier do objeto de evento da Lambda e registrar logs em arquivo.",
"option_c": "Obter o request identifier do objeto de evento da Lambda e registrar logs no console.",
"option_d": "Obter o request identifier do objeto de contexto da Lambda e registrar logs em arquivo.",
"correct_answers": [
"A"
],
"explanation_detailed": "O objeto de contexto da Lambda contém o request ID da invocação. Escrever logs no console (stdout) faz com que eles sejam enviados automaticamente ao CloudWatch Logs, facilitando rastreamento por request ID.",
"incorrect_explanations": {
"B": "O objeto de evento não contém o request ID gerenciado pela Lambda, e gravar em arquivo não é o fluxo padrão de logging.",
"C": "Mesmo problema: o request ID vem do contexto, não do evento.",
"D": "Gravar em arquivo dificulta a integração com o CloudWatch Logs e não segue o padrão idiomático de Lambda."
}
},
{
"id": "dva-c02-security-041",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma empresa armazena todas as informações de identificação pessoal (PII) em uma tabela Amazon DynamoDB chamada PII na Conta A. Uma aplicação executando em instâncias EC2 na Conta B precisa acessar essa tabela. Um administrador na Conta A criou uma role IAM chamada AccessPII com privilégios de acesso à tabela PII e configurou a Conta B como entidade confiável. Quais passos os desenvolvedores devem tomar para acessar a tabela? (Selecione DUAS)",
"option_a": "Permitir que a role IAM da EC2 tenha permissão para assumir a role AccessPII.",
"option_b": "Permitir que a role IAM da EC2 tenha permissão para acessar diretamente a tabela PII.",
"option_c": "Incluir na lógica da aplicação uma chamada de API da AWS para obter credenciais temporárias da role EC2 para acessar a tabela PII.",
"option_d": "Incluir a operação AssumeRole na lógica da aplicação para obter credenciais temporárias para acessar a tabela PII.",
"option_e": "Incluir a operação GetSessionToken na lógica da aplicação para obter credenciais temporárias para acessar a tabela PII.",
"correct_answers": [
"A",
"D"
],
"explanation_detailed": "A aplicação na Conta B precisa assumir a role AccessPII definida na Conta A. Para isso, a role anexada às instâncias EC2 deve ter permissão para chamar sts:AssumeRole na role AccessPII, e o código deve executar a operação AssumeRole para obter credenciais temporárias que serão usadas para acessar a tabela PII.",
"incorrect_explanations": {
"B": "Acesso direto à tabela PII deve ser concedido pela role da Conta A (AccessPII), não pela role da EC2 na Conta B.",
"C": "Obter credenciais temporárias da role EC2 apenas replica as permissões da própria EC2, não as da role cross-account AccessPII.",
"E": "GetSessionToken é usado para credenciais temporárias de um usuário IAM, não é o mecanismo recomendado para acesso cross-account baseado em roles."
}
},
{
"id": "dva-c02-monitoring-042",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma função AWS Lambda acessa duas tabelas Amazon DynamoDB. Um desenvolvedor quer melhorar a performance identificando gargalos na função, inspecionando o tempo das chamadas de API ao DynamoDB. Como ele pode fazer isso?",
"option_a": "Adicionar DynamoDB como event source da função Lambda e ver a performance por métricas do CloudWatch.",
"option_b": "Colocar um Application Load Balancer (ALB) em frente às duas tabelas DynamoDB e inspecionar os logs do ALB.",
"option_c": "Limitar a Lambda a no máximo cinco invocações concorrentes e monitorar pelo console da Lambda.",
"option_d": "Habilitar o AWS X-Ray tracing para a função e visualizar os traces no serviço X-Ray.",
"correct_answers": [
"D"
],
"explanation_detailed": "O AWS X-Ray fornece rastreamento detalhado de chamadas feitas pela função Lambda, incluindo latência de cada chamada ao DynamoDB, o que permite identificar gargalos de forma visual.",
"incorrect_explanations": {
"A": "Configurar DynamoDB como event source não mede a latência de chamadas feitas pela função às tabelas.",
"B": "Um ALB não fica na frente do DynamoDB; o serviço é acessado diretamente via API.",
"C": "Limitar concorrência não fornece visibilidade granular de latência por chamada de API."
}
},
{
"id": "dva-c02-development-043",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma instância Amazon RDS é usada por muitas aplicações para consultar dados históricos com taxa de leitura relativamente constante. Quando os dados históricos são atualizados diariamente, o tráfego de escrita resultante reduz a performance de leitura e afeta todos os usuários. O que pode ser feito para eliminar esse impacto?",
"option_a": "Garantir que o Amazon RDS seja Multi-AZ para absorver melhor o aumento de tráfego.",
"option_b": "Criar uma Read Replica do RDS e direcionar todo o tráfego de leitura para a réplica.",
"option_c": "Implementar Amazon ElastiCache na frente do RDS para bufferizar o tráfego de escrita.",
"option_d": "Usar Amazon DynamoDB em vez de Amazon RDS para bufferizar o tráfego de leitura.",
"correct_answers": [
"B"
],
"explanation_detailed": "Uma read replica em RDS permite que as leituras sejam direcionadas para uma instância separada, isolando o impacto de operações de escrita na instância primária e mantendo a performance de leitura estável para os usuários.",
"incorrect_explanations": {
"A": "Multi-AZ melhora disponibilidade, mas a réplica em standby não recebe tráfego de leitura e não resolve o gargalo.",
"C": "ElastiCache ajuda em leitura, não em absorver picos de escrita; o problema descrito é o impacto das escritas sobre as leituras.",
"D": "Migrar para DynamoDB é uma mudança arquitetural grande e não é necessária apenas para separar leitura e escrita em RDS."
}
},
{
"id": "dva-c02-development-044",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está desenvolvendo uma aplicação web de e-commerce serverless. A aplicação precisa fazer mudanças coordenadas, tudo-ou-nada, em múltiplos itens na tabela de inventário em Amazon DynamoDB. Qual solução atende a esses requisitos?",
"option_a": "Habilitar transações para a tabela DynamoDB e usar a operação BatchWriteItem para atualizar os itens.",
"option_b": "Usar a operação TransactWriteItems para agrupar as mudanças e atualizar os itens na tabela.",
"option_c": "Configurar uma fila FIFO no Amazon SQS, agrupar as mudanças na fila e atualizar a tabela com base nesses grupos.",
"option_d": "Criar uma tabela de transações em um cluster Amazon Aurora para gerenciar as transações e sincronizar com a tabela DynamoDB.",
"correct_answers": [
"B"
],
"explanation_detailed": "A operação TransactWriteItems do DynamoDB foi projetada exatamente para operações transacionais, tudo-ou-nada, envolvendo múltiplos itens (até limites do serviço) em uma ou mais tabelas.",
"incorrect_explanations": {
"A": "BatchWriteItem executa operações em lote, mas não garante atomicidade transacional entre múltiplos itens.",
"C": "Uma fila FIFO pode ajudar na ordenação, mas não fornece semântica de transação no DynamoDB.",
"D": "Manter uma tabela de transações em Aurora adiciona complexidade e não aproveita recursos nativos de transação do DynamoDB."
}
},
{
"id": "dva-c02-monitoring-045",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação está executando em uma instância EC2. O desenvolvedor quer armazenar uma métrica customizada da aplicação no Amazon CloudWatch. Qual é a melhor prática para implementar esse requisito?",
"option_a": "Usar a API PUT Object para enviar dados para um bucket S3 e usar notificação de eventos para acionar uma função Lambda que publica no CloudWatch.",
"option_b": "Publicar dados da métrica em um stream Amazon Kinesis usando PutRecord e subscrever uma Lambda que publica no CloudWatch.",
"option_c": "Usar a API PutMetricData do CloudWatch para enviar uma métrica customizada, fornecendo credenciais necessárias na aplicação.",
"option_d": "Usar a API PutMetricData do CloudWatch para enviar uma métrica customizada, lançando a instância EC2 com uma IAM role que permita essa chamada.",
"correct_answers": [
"D"
],
"explanation_detailed": "A prática recomendada é anexar uma IAM role à instância EC2 com permissão para PutMetricData e chamar diretamente a API do CloudWatch a partir da aplicação, sem embutir credenciais estáticas.",
"incorrect_explanations": {
"A": "Encadear via S3 e Lambda é complexo e desnecessário para enviar uma métrica simples.",
"B": "Usar Kinesis como intermediário adiciona sobrecarga sem benefício para o caso de uso.",
"C": "Embutir credenciais na aplicação é inseguro e difícil de gerenciar, preferindo-se IAM roles."
}
},
{
"id": "dva-c02-development-046",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa projetar uma aplicação executando na AWS que consumirá mensagens Amazon SQS variando de 1 KB até 1 GB de tamanho. Como essas mensagens SQS devem ser gerenciadas?",
"option_a": "Usar Amazon S3 e a AWS CLI do Amazon SQS.",
"option_b": "Usar Amazon S3 e a Amazon SQS Extended Client Library for Java.",
"option_c": "Usar Amazon EBS e a AWS CLI do Amazon SQS.",
"option_d": "Usar Amazon EFS e a AWS CLI do Amazon SQS.",
"correct_answers": [
"B"
],
"explanation_detailed": "O tamanho máximo de mensagem direto no SQS é limitado, então a abordagem correta é armazenar o payload grande em S3 e usar a SQS Extended Client Library, que integra SQS e S3 para lidar com mensagens de até gigabytes.",
"incorrect_explanations": {
"A": "Apenas usar S3 e a CLI não integra automaticamente a referência ao objeto com a mensagem SQS.",
"C": "EBS não é usado como backend para SQS; é um volume de bloco para EC2.",
"D": "EFS também não é backend de SQS; é sistema de arquivos compartilhado."
}
},
{
"id": "dva-c02-monitoring-047",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor escreveu uma aplicação multithread rodando em um fleet de instâncias EC2. A equipe de operações quer um método gráfico para monitorar o número de threads em execução ao longo do tempo. Qual é a forma MAIS eficiente de atender a esse pedido?",
"option_a": "Enviar periodicamente a contagem de threads para segmentos AWS X-Ray e gerar um service graph sob demanda.",
"option_b": "Criar uma métrica customizada no Amazon CloudWatch e, periodicamente, chamar PutMetricData com a contagem atual de threads.",
"option_c": "Registrar periodicamente a contagem de threads em um bucket S3 e usar Amazon Kinesis para processar os dados em um gráfico.",
"option_d": "Escrever periodicamente a contagem de threads em uma tabela DynamoDB e usar Amazon CloudFront para criar um gráfico.",
"correct_answers": [
"B"
],
"explanation_detailed": "Uma métrica customizada no CloudWatch é a forma direta e integrada de acompanhar a contagem de threads ao longo do tempo e visualizar gráficos no console do CloudWatch.",
"incorrect_explanations": {
"A": "X-Ray é mais voltado para rastrear chamadas e latências entre serviços, não contadores simples como número de threads.",
"C": "Gravar em S3 e processar via Kinesis é muito mais complexo do que necessário.",
"D": "CloudFront é um CDN, não uma ferramenta de gráficos; armazenar dados em DynamoDB também é desnecessário para esse caso."
}
},
{
"id": "dva-c02-development-048",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma função AWS Lambda está sendo chamada via Amazon API Gateway. O tempo médio de execução é de cerca de 1 segundo. O pseudocódigo mostra várias operações, incluindo conexão ao Amazon RDS. Quais duas ações podem melhorar a performance dessa função sem aumentar o custo da solução? (Selecione DUAS)",
"option_a": "Empacotar apenas os módulos que a função Lambda requer.",
"option_b": "Usar Amazon DynamoDB em vez de Amazon RDS.",
"option_c": "Mover a inicialização da conexão com o Amazon RDS para fora da função handler.",
"option_d": "Implementar pooling de conexões customizado dentro da função Lambda.",
"option_e": "Implementar cache local dos dados do Amazon RDS para que a Lambda possa reutilizar o cache.",
"correct_answers": [
"A",
"C"
],
"explanation_detailed": "Reduzir o tamanho do pacote, incluindo apenas os módulos necessários, diminui o tempo de cold start. Mover a criação da conexão RDS para fora do handler permite que a conexão seja reutilizada entre invocações dentro do mesmo ambiente de execução, reduzindo o tempo gasto em cada chamada.",
"incorrect_explanations": {
"B": "Migrar para DynamoDB é uma mudança arquitetural e pode alterar custos e requisitos; não é uma otimização simples da função existente.",
"D": "Um pooling complexo dentro da Lambda pode não trazer ganho significativo em comparação com apenas reutilizar a conexão fora do handler.",
"E": "Cache local de dados pode ficar desatualizado e nem sempre é aplicável; além disso, não é garantido entre reusos de ambiente."
}
},
{
"id": "dva-c02-monitoring-049",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação usa APIs de terceiros. O desenvolvedor precisa monitorar erros dessas APIs no código e receber notificações se as falhas ultrapassarem um limite. Como isso pode ser feito?",
"option_a": "Publicar uma métrica customizada no Amazon CloudWatch e usar Amazon SES para notificações.",
"option_b": "Usar uma métrica de erro de API nativa do CloudWatch e Amazon SNS para notificação.",
"option_c": "Usar uma métrica de erro de API nativa do CloudWatch e Amazon SES para notificação.",
"option_d": "Publicar uma métrica customizada no Amazon CloudWatch e usar Amazon SNS para notificações.",
"correct_answers": [
"D"
],
"explanation_detailed": "Como se trata de erros em chamadas de APIs de terceiros feitas pela própria aplicação, é necessário publicar uma métrica customizada refletindo a taxa de erros, e então configurar um alarme do CloudWatch para enviar notificações via Amazon SNS quando o limiar for excedido.",
"incorrect_explanations": {
"A": "SES pode enviar email, mas SNS é o mecanismo padrão para alarmes do CloudWatch e integrações diversas; além disso, o ponto principal é a métrica customizada.",
"B": "Não existe uma métrica nativa de \"erro de API de terceiro\"; é preciso criar uma métrica customizada.",
"C": "Mesmo problema: não há métrica nativa para essas chamadas específicas."
}
},
{
"id": "dva-c02-deployment-050",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "O workflow de release de uma aplicação exige uma aprovação manual antes do deploy do código em produção usando AWS CodePipeline. Qual é a MELHOR forma de implementar isso?",
"option_a": "Usar múltiplos pipelines para permitir aprovação.",
"option_b": "Usar uma approval action em um stage.",
"option_c": "Desabilitar a transição de stage para permitir aprovação manual.",
"option_d": "Desabilitar um stage logo antes do stage de deploy.",
"correct_answers": [
"B"
],
"explanation_detailed": "O CodePipeline oferece explicitamente ações de aprovação manual (manual approval actions) que podem ser inseridas em um stage. A execução do pipeline fica em espera até que alguém aprove ou rejeite, atendendo exatamente ao requisito.",
"incorrect_explanations": {
"A": "Criar múltiplos pipelines complica o fluxo e não explora o recurso nativo de aprovação.",
"C": "Desabilitar transitions é uma forma de bloquear stages, mas não fornece um fluxo estruturado de aprovação com registro.",
"D": "Desabilitar um stage não é o mesmo que ter um ponto de aprovação claramente definido e auditável."
}
},


{
"id": "dva-c02-development-051",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor foi solicitado a implementar uma camada de cache na frente de um Amazon RDS. O conteúdo em cache é caro de regenerar em caso de falha de serviço. Qual implementação abaixo funcionaria mantendo o máximo de uptime?",
"option_a": "Implementar Amazon ElastiCache Redis em Cluster Mode.",
"option_b": "Instalar Redis em uma instância Amazon EC2.",
"option_c": "Implementar Amazon ElastiCache Memcached.",
"option_d": "Migrar o banco de dados para Amazon Redshift.",
"correct_answers": ["A"],
"explanation_detailed": "Para dados em cache caros de regenerar e necessidade de alta disponibilidade, o Amazon ElastiCache Redis em Cluster Mode é a melhor opção. Redis oferece replicação, failover automático e persistência, o que reduz o risco de perda de dados em cache e mantém o serviço disponível mesmo em caso de falha de nó.",
"incorrect_explanations": {
"B": "Rodar Redis em EC2 exige gerenciamento manual de alta disponibilidade, backups, patching e failover, aumentando o risco de indisponibilidade.",
"C": "Memcached é puramente em memória, sem persistência nem replicação nativa entre nós, tornando a perda de dados em caso de falha mais provável.",
"D": "Redshift é um data warehouse analítico, não uma camada de cache na frente do RDS."
}
},
{
"id": "dva-c02-development-052",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa escreveu uma função AWS Lambda em Java para ser disparada sempre que um usuário faz upload de uma imagem em um bucket Amazon S3. A função converte a imagem original para vários formatos diferentes e copia as imagens resultantes para outro bucket S3. Os desenvolvedores percebem que nenhuma imagem está sendo copiada para o segundo bucket. Eles testaram o código em uma instância Amazon EC2 com 1 GB de RAM e isso leva em média 500 segundos para concluir. Qual é a causa MAIS provável do problema?",
"option_a": "A função Lambda tem memória insuficiente e precisa ser aumentada para 1 GB para combinar com a instância EC2.",
"option_b": "Os arquivos precisam ser copiados para o mesmo bucket S3 para processamento, portanto o segundo bucket precisa ser excluído.",
"option_c": "Funções Lambda têm um limite máximo de tempo de execução, portanto a função não está completando.",
"option_d": "Há um problema com o runtime Java para Lambda, e a função precisa ser convertida para Node.js.",
"correct_answers": ["C"],
"explanation_detailed": "Historicamente, funções Lambda tinham um limite máximo de tempo de execução menor que 500 segundos. Como o código leva em média 500 segundos para terminar em uma instância EC2, é provável que a execução em Lambda esteja excedendo o limite de timeout e sendo interrompida antes de copiar os arquivos para o segundo bucket.",
"incorrect_explanations": {
"A": "A quantidade de memória afeta performance, mas o sintoma relatado está mais alinhado com timeout do que com falha por memória insuficiente.",
"B": "Lambda pode perfeitamente ler de um bucket e gravar em outro; não há requisito de usar o mesmo bucket.",
"D": "Não há indicação de bug específico no runtime Java; o comportamento é consistente com limite de tempo de execução."
}
},
{
"id": "dva-c02-security-053",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação web está usando Amazon Kinesis Streams para dados de clickstream que podem não ser consumidos por até 12 horas. Como o desenvolvedor pode implementar criptografia em repouso para os dados no Kinesis Streams?",
"option_a": "Habilitar conexões SSL com o Kinesis.",
"option_b": "Usar a Amazon Kinesis Consumer Library.",
"option_c": "Criptografar os dados quando estiverem em repouso com uma função Lambda.",
"option_d": "Habilitar server-side encryption no Kinesis Streams.",
"correct_answers": ["D"],
"explanation_detailed": "A forma nativa e recomendada de proteger dados em repouso no Kinesis Streams é habilitar server-side encryption (SSE) usando AWS KMS. Isso garante que todos os dados gravados nos shards sejam criptografados automaticamente sem exigir mudanças complexas na aplicação.",
"incorrect_explanations": {
"A": "SSL protege dados em trânsito, não em repouso dentro do serviço Kinesis.",
"B": "A Kinesis Client/Consumer Library auxilia no consumo e balanceamento de shards, mas não provê criptografia em repouso.",
"C": "Criptografar manualmente com Lambda aumenta complexidade e custo, além de duplicar funcionalidade já fornecida pelo serviço."
}
},
{
"id": "dva-c02-security-054",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando um aplicativo mobile com orçamento limitado. A solução exige um serviço escalável que permita aos clientes se cadastrar e autenticar no aplicativo mobile usando o provedor de identidade SAML 2.0 atual da organização. Qual serviço AWS deve ser usado?",
"option_a": "AWS Lambda.",
"option_b": "Amazon Cognito.",
"option_c": "AWS IAM.",
"option_d": "Amazon EC2.",
"correct_answers": ["B"],
"explanation_detailed": "O Amazon Cognito é projetado para autenticação de usuários em aplicações web e mobile e integra com provedores de identidade SAML 2.0. Ele oferece signup, signin, tokens e escalabilidade automatizada sem que seja necessário gerenciar servidores.",
"incorrect_explanations": {
"A": "Lambda é compute serverless, não um serviço de identidade completo para usuários finais.",
"C": "IAM é voltado para identidades e permissões de recursos AWS, não para autenticação de usuários de aplicação.",
"D": "EC2 exigiria que a equipe construísse e mantivesse um serviço de autenticação inteiro, aumentando custo e complexidade."
}
},
{
"id": "dva-c02-monitoring-055",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa quer migrar sua aplicação web para a AWS e usar Auto Scaling para lidar com picos de carga. O arquiteto de soluções determinou que a melhor métrica para eventos de Auto Scaling é o número de usuários concorrentes. Com base nisso, o que o desenvolvedor deve usar para escalonar com base em usuários concorrentes?",
"option_a": "Um tópico Amazon SNS acionado quando o limite de usuários concorrentes for atingido.",
"option_b": "A métrica NetworkIn do Amazon CloudWatch.",
"option_c": "Amazon CloudFront para aproveitar Edge Locations da AWS.",
"option_d": "Uma métrica customizada do Amazon CloudWatch para usuários concorrentes.",
"correct_answers": ["D"],
"explanation_detailed": "Como \"usuários concorrentes\" não é uma métrica nativa, é necessário publicar uma métrica customizada no CloudWatch representando esse valor e configurar políticas de Auto Scaling com base nela.",
"incorrect_explanations": {
"A": "SNS é um mecanismo de notificação/pub-sub, não um sistema de métrica para Auto Scaling.",
"B": "NetworkIn é um proxy de tráfego, mas não reflete diretamente o número de usuários concorrentes.",
"C": "CloudFront pode reduzir latência, mas não fornece automaticamente métrica de usuários concorrentes para Auto Scaling."
}
},
{
"id": "dva-c02-deployment-056",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor escreveu uma aplicação serverless usando múltiplos serviços AWS. A lógica de negócio está em uma função Lambda com dependências em bibliotecas de terceiros. Os endpoints da função serão expostos via Amazon API Gateway e a função irá gravar dados no Amazon DynamoDB. O desenvolvedor está pronto para fazer deploy, mas precisa ter a capacidade de rollback. Como essa implantação pode ser automatizada com capacidade de rollback?",
"option_a": "Fazer deploy usando operações de API do Lambda para criar a função fornecendo um pacote de deploy.",
"option_b": "Usar um template AWS CloudFormation e sintaxe CloudFormation para definir o recurso Lambda no template.",
"option_c": "Usar sintaxe conforme o Serverless Application Model no template AWS CloudFormation para definir o recurso Lambda.",
"option_d": "Criar um script bash usando AWS CLI para empacotar e fazer deploy da aplicação.",
"correct_answers": ["C"],
"explanation_detailed": "Usar AWS SAM (Serverless Application Model) dentro de um template CloudFormation permite descrever toda a aplicação serverless como infraestrutura como código. CloudFormation/SAM oferece histórico de deployments e suporte nativo a rollback automático em caso de falhas.",
"incorrect_explanations": {
"A": "Fazer deploy apenas via APIs do Lambda não gerencia todos os recursos (API Gateway, DynamoDB) como uma unidade nem oferece rollback automático da stack.",
"B": "É possível usar CloudFormation puro, mas SAM simplifica muito a definição de recursos serverless e é a abordagem recomendada.",
"D": "Scripts bash com AWS CLI podem automatizar o deploy, mas não oferecem mecanismo nativo de rollback transacional de todos os recursos."
}
},
{
"id": "dva-c02-security-057",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um jogo armazena dados de usuários em uma tabela Amazon DynamoDB com os atributos user_id, user_name, user_score e user_rank. Usuários individuais não devem ter acesso aos dados de jogo de outros usuários. Como isso pode ser alcançado?",
"option_a": "Criptografar os dados do jogo com chaves individuais por usuário.",
"option_b": "Restringir o acesso a itens específicos com base em determinados valores de chave primária.",
"option_c": "Estagiar os dados em filas SQS para injetar metadados antes de acessar o DynamoDB.",
"option_d": "Ler registros do DynamoDB e descartar no cliente os dados irrelevantes.",
"correct_answers": ["B"],
"explanation_detailed": "O padrão recomendado é usar políticas IAM com condições sobre a chave primária (por exemplo, user_id) para que cada identidade só possa acessar itens cujo user_id corresponda ao seu próprio identificador.",
"incorrect_explanations": {
"A": "Criptografia por usuário protege confidencialidade, mas não resolve sozinha o controle de acesso lógico no DynamoDB.",
"C": "Inserir filas SQS no caminho aumenta complexidade sem resolver diretamente a autorização por item.",
"D": "Filtrar dados no lado do cliente permite que o cliente veja dados de outros usuários antes de descartar, o que viola o requisito."
}
},
{
"id": "dva-c02-security-058",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma aplicação web que exige autenticação, mas também precisa oferecer acesso de convidado, permitindo uso limitado sem login. Que serviço pode fornecer suporte para acesso de convidado?",
"option_a": "Credenciais temporárias IAM usando AWS STS.",
"option_b": "Amazon Directory Service.",
"option_c": "Amazon Cognito com acesso não autenticado habilitado.",
"option_d": "IAM com integração SAML.",
"correct_answers": ["C"],
"explanation_detailed": "O Amazon Cognito Identity Pools permite acesso autenticado e não autenticado (guest) a recursos, atribuindo credenciais temporárias diferentes dependendo do tipo de usuário, o que se encaixa exatamente nesse caso.",
"incorrect_explanations": {
"A": "STS é a base para credenciais temporárias, mas não oferece, por si só, uma solução completa de gerenciamento de usuários de aplicação.",
"B": "Directory Service é focado em integração com diretórios corporativos (AD), não em guest access para aplicações web.",
"D": "IAM + SAML é voltado para federação de identidades corporativas, não para acesso convidado anônimo."
}
},
{
"id": "dva-c02-deployment-059",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Dado o código-fonte de uma função AWS Lambda no arquivo local store.py contendo uma função handler chamada get_store e o seguinte template AWS CloudFormation, o que deve ser feito para preparar o template para que ele possa ser implantado usando o comando aws cloudformation deploy?",
"option_a": "Usar AWS CloudFormation compile para codificar em base64 e embutir o arquivo fonte em um template CloudFormation modificado.",
"option_b": "Usar AWS CloudFormation package para enviar o código-fonte para um bucket Amazon S3 e produzir um template CloudFormation modificado.",
"option_c": "Usar AWS Lambda zip para empacotar o arquivo fonte junto com o template CloudFormation e fazer deploy do arquivo zip resultante.",
"option_d": "Usar AWS Serverless create-package para embutir o arquivo fonte diretamente no template CloudFormation existente.",
"correct_answers": ["B"],
"explanation_detailed": "O fluxo suportado é usar o comando aws cloudformation package, que empacota o código, faz upload para S3 e gera um template transformado com os URIs corretos, pronto para uso com aws cloudformation deploy.",
"incorrect_explanations": {
"A": "Não existe comando CloudFormation compile com esse propósito, e embutir código em base64 não é o padrão suportado.",
"C": "\"AWS Lambda zip\" não é uma ferramenta oficial de empacotamento integrada ao CloudFormation.",
"D": "O comando descrito não corresponde a uma ferramenta padrão; o caminho recomendado é package + deploy."
}
},
{
"id": "dva-c02-refactoring-060",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor criou uma função Lambda grande e o deploy está falhando com o erro InvalidParameterValueException indicando que o tamanho descompactado deve ser menor que o limite atual da Lambda. O que o desenvolvedor pode fazer para corrigir o problema?",
"option_a": "Enviar uma solicitação de aumento de limite ao suporte da AWS para aumentar o tamanho da função.",
"option_b": "Usar um algoritmo de compressão mais eficiente que ZIP.",
"option_c": "Quebrar a função em múltiplas funções Lambda menores.",
"option_d": "Compactar o arquivo ZIP duas vezes para comprimi-lo mais.",
"correct_answers": ["C"],
"explanation_detailed": "O limite é para o tamanho descompactado do código. Dividir a lógica em múltiplas funções Lambda menores reduz o tamanho de cada pacote e melhora a manutenção e a separação de responsabilidades.",
"incorrect_explanations": {
"A": "O limite de tamanho é geral e normalmente não é aumentado por solicitação de suporte; a recomendação é reduzir o tamanho do pacote.",
"B": "O erro é sobre tamanho descompactado; mudar o algoritmo de compressão não resolve isso.",
"D": "Compactar o ZIP duas vezes não faz sentido, e o tamanho descompactado continuará excedendo o limite."
}
},
{
"id": "dva-c02-development-061",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação serverless usa Amazon API Gateway e AWS Lambda. Onde a função Lambda deve armazenar informações de sessão entre chamadas da função?",
"option_a": "Em uma tabela Amazon DynamoDB.",
"option_b": "Em uma fila Amazon SQS.",
"option_c": "No sistema de arquivos local.",
"option_d": "Em uma tabela de sessão SQLite usando CDSQLITE_ENABLE_SESSION.",
"correct_answers": ["A"],
"explanation_detailed": "Funções Lambda são efêmeras e não garantem estado entre invocações. DynamoDB é um serviço totalmente gerenciado, de baixa latência, ideal para armazenar estado de sessão compartilhado entre invocações e instâncias diferentes da função.",
"incorrect_explanations": {
"B": "SQS é para filas de mensagens assíncronas, não é adequado para armazenamento e leitura frequente de dados de sessão.",
"C": "O sistema de arquivos local não é persistente entre execuções nem entre diferentes ambientes de execução.",
"D": "SQLite local não persiste entre ambientes de execução da Lambda e não é compartilhado entre instâncias."
}
},
{
"id": "dva-c02-development-062",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação lê dados de uma tabela Amazon DynamoDB. Várias vezes ao dia, por um período de 15 segundos, a aplicação recebe múltiplos erros ProvisionedThroughputExceeded. Como essa exceção deve ser tratada?",
"option_a": "Criar um novo índice secundário global para a tabela para ajudar nas requisições adicionais.",
"option_b": "Repetir as requisições de leitura que falharam com exponential backoff.",
"option_c": "Repetir imediatamente as requisições de leitura que falharam.",
"option_d": "Usar a API UpdateItem do DynamoDB para aumentar a capacidade provisionada da tabela.",
"correct_answers": ["B"],
"explanation_detailed": "Quando há picos momentâneos de tráfego, a recomendação é implementar retries com exponential backoff. Isso reduz a pressão no serviço durante períodos de pico e permite que as requisições sejam atendidas assim que houver capacidade disponível.",
"incorrect_explanations": {
"A": "Adicionar um GSI pode ajudar em padrões de acesso, mas não resolve picos de throughput que causam throttling.",
"C": "Retries imediatos aumentam a contenção e podem prolongar o período de throttling.",
"D": "Aumentar a capacidade provisionada pode ser válido, mas a questão foca em lidar com breves períodos de 15 segundos, onde backoff é a abordagem padrão."
}
},
{
"id": "dva-c02-deployment-063",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação Linux para rodar no AWS Elastic Beanstalk. Os requisitos dizem que a aplicação deve manter capacidade total durante updates, minimizando custos. Qual política de deploy do Elastic Beanstalk deve ser especificada?",
"option_a": "Immutable.",
"option_b": "Rolling.",
"option_c": "All at Once.",
"option_d": "Rolling with additional batch.",
"correct_answers": ["D"],
"explanation_detailed": "A política Rolling with additional batch adiciona temporariamente uma pequena quantidade de capacidade extra para que cada batch possa ser atualizado sem reduzir a capacidade disponível para atender requisições. Isso mantém capacidade total durante o deploy com custo menor que um deploy totalmente imutável.",
"incorrect_explanations": {
"A": "Immutable cria um novo fleet completo de instâncias, garantindo alta segurança mas com custo maior.",
"B": "Rolling sem batch adicional reduz temporariamente a capacidade disponível em cada passo do deploy.",
"C": "All at once substitui todas as instâncias de uma só vez, causando indisponibilidade temporária."
}
},
{
"id": "dva-c02-development-064",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Ao escrever uma função Lambda, qual é o benefício de instanciar clientes AWS (por exemplo, SDK) fora do escopo do handler?",
"option_a": "Legibilidade e convenção de estilo.",
"option_b": "Aproveitar o reuso de conexões.",
"option_c": "Melhor tratamento de erros.",
"option_d": "Criar uma nova instância por invocação.",
"correct_answers": ["B"],
"explanation_detailed": "Instanciar clientes fora do handler permite que o ambiente de execução da Lambda reutilize conexões entre invocações, reduzindo o tempo de criação de clientes e conexões TCP em cada chamada e melhorando a performance.",
"incorrect_explanations": {
"A": "Pode até ser legível, mas o principal benefício é técnico: reuso de conexões.",
"C": "Tratamento de erros não depende diretamente do local onde o cliente é instanciado.",
"D": "Criar uma nova instância por invocação aumenta overhead e é justamente o que se busca evitar."
}
},
{
"id": "dva-c02-refactoring-065",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma arquitetura atual usa muitas funções Lambda chamando umas às outras como uma grande máquina de estados. A coordenação dessa máquina de estados é feita por código legado e frágil. Qual serviço AWS pode ajudar a refatorar e gerenciar essa máquina de estados?",
"option_a": "AWS Data Pipeline.",
"option_b": "AWS SNS com AWS SQS.",
"option_c": "Amazon Elastic MapReduce.",
"option_d": "AWS Step Functions.",
"correct_answers": ["D"],
"explanation_detailed": "O AWS Step Functions foi criado justamente para orquestrar fluxos de trabalho baseados em múltiplas funções Lambda e outros serviços, fornecendo um mecanismo visual e gerenciado de máquina de estados com retries, timeouts e controle de erros.",
"incorrect_explanations": {
"A": "Data Pipeline é voltado para movimentação e processamento de dados em batch, não para orquestrar chamadas de Lambda em tempo de execução.",
"B": "SNS e SQS podem coordenar mensagens, mas não oferecem uma máquina de estados declarativa com controle explícito de passos.",
"C": "EMR é um serviço de big data para processamento de grandes volumes usando frameworks como Hadoop e Spark."
}
},
{
"id": "dva-c02-security-066",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está desenvolvendo um novo jogo online em cima do Amazon ECS. Quatro serviços distintos do ECS farão parte da arquitetura, cada um exigindo permissões específicas para vários serviços AWS. A empresa quer otimizar o uso das instâncias EC2 subjacentes fazendo bin packing com base em reserva de memória. Qual configuração permite ao time atender a esses requisitos com MAIS segurança?",
"option_a": "Criar um novo instance profile IAM com as permissões necessárias para os vários serviços ECS e associar essa role às instâncias EC2.",
"option_b": "Criar quatro roles IAM distintas, cada uma com as permissões necessárias para o serviço ECS associado, e configurar cada serviço ECS para referenciar a role associada.",
"option_c": "Criar quatro roles IAM distintas, cada uma com as permissões necessárias, depois criar um grupo IAM e configurar o cluster ECS para referenciar esse grupo.",
"option_d": "Criar quatro roles IAM distintas, cada uma com as permissões necessárias para o serviço ECS associado, e configurar cada task definition do ECS para referenciar a role associada.",
"correct_answers": ["D"],
"explanation_detailed": "A abordagem mais segura é usar IAM roles por tarefa (task role). Assim, cada contêiner/tarefa obtém apenas as permissões de que precisa, independentemente da instância EC2 onde está rodando, permitindo bin packing seguro.",
"incorrect_explanations": {
"A": "Uma única instance role compartilhada dá a todas as tarefas as mesmas permissões, o que viola o princípio do menor privilégio.",
"B": "Roles associadas ao serviço ECS não controlam diretamente as permissões dos contêineres individuais.",
"C": "Grupos IAM não são anexados a tasks ECS; essa opção não corresponde ao modelo de permissão suportado."
}
},
{
"id": "dva-c02-refactoring-067",
"certification_id": "DVA-C02",
"domain": "REFACTORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa reimplementar a lógica de negócio de um sistema de fulfilment de pedidos. A lógica precisa fazer requisições a múltiplos fornecedores para decidir onde comprar um item. Todo o processo pode levar até uma semana para completar. Qual é a forma MAIS eficiente e SIMPLES de implementar um sistema que atenda a esses requisitos?",
"option_a": "Usar AWS Step Functions para executar funções Lambda em paralelo e combinar os resultados.",
"option_b": "Criar uma fila SQS para cada fornecedor, fazer polling a partir de instâncias worker e juntar os resultados.",
"option_c": "Usar AWS Lambda para chamar assincronamente uma função Lambda para cada fornecedor e juntar os resultados.",
"option_d": "Usar Amazon CloudWatch Events para orquestrar as funções Lambda.",
"correct_answers": ["A"],
"explanation_detailed": "AWS Step Functions suporta fluxos de trabalho de longa duração e pode coordenar chamadas paralelas para múltiplos fornecedores, lidar com retries, timeouts e esperas de longo prazo, tudo de forma declarativa.",
"incorrect_explanations": {
"B": "Gerenciar filas SQS e workers EC2 aumenta muito a complexidade em comparação a Step Functions.",
"C": "Chamar Lambdas assíncronas sem orquestrador dificulta tratar timeouts de até uma semana e re-tentativas coordenadas.",
"D": "CloudWatch Events é adequado para agendamento e eventos, não para coordenar um fluxo complexo e longo de negócio."
}
},
{
"id": "dva-c02-development-068",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um aplicativo mobile armazena posts de blog em uma tabela Amazon DynamoDB. Milhões de posts são adicionados diariamente, cada post sendo um item. O app só precisa de posts recentes e qualquer post com mais de 48 horas pode ser removido. Qual é a forma MAIS econômica de apagar posts com mais de 48 horas?",
"option_a": "Adicionar um atributo String com timestamp de criação e executar um script com table scan para remover posts mais antigos que 48 horas usando BatchWriteItem, agendando um cron em EC2.",
"option_b": "Adicionar um atributo String com timestamp de criação e executar um script em container ECS no Fargate a cada 5 minutos para fazer scan e remoção via BatchWriteItem.",
"option_c": "Adicionar um atributo Date com timestamp definido para 48 horas após a criação; criar um GSI com esse atributo; usar Lambda agendada para remover itens expirados via BatchWriteItem.",
"option_d": "Adicionar um atributo Number com um timestamp definido para 48 horas após a criação e configurar TTL na tabela DynamoDB referenciando esse atributo.",
"correct_answers": ["D"],
"explanation_detailed": "O recurso de Time To Live (TTL) do DynamoDB permite marcar itens para expiração automática com base em um atributo numérico de timestamp. Isso remove itens de forma automática e econômica, sem necessidade de scripts ou jobs adicionais.",
"incorrect_explanations": {
"A": "Executar scans periódicos e scripts consome capacidade de leitura e manutenção adicional.",
"B": "Usar ECS/Fargate para executar scripts aumenta custos e complexidade sem necessidade.",
"C": "A combinação GSI + Lambda ainda depende de processamento ativo para remoção, mais caro que usar TTL nativo."
}
},
{
"id": "dva-c02-monitoring-069",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está recebendo erros HTTP 400: ThrottlingException de forma intermitente ao chamar a API do Amazon CloudWatch. Quando uma chamada falha, nenhum dado é retornado. Qual boa prática deve ser aplicada primeiro para resolver isso?",
"option_a": "Contactar o suporte da AWS para um aumento de limite.",
"option_b": "Usar a AWS CLI para obter as métricas.",
"option_c": "Analisar a aplicação e remover a chamada de API.",
"option_d": "Repetir a chamada com exponential backoff.",
"correct_answers": ["D"],
"explanation_detailed": "ThrottlingException indica que o limite de taxa foi excedido. A prática recomendada é implementar retries com exponential backoff, permitindo que as chamadas sejam espaçadas e evitando sobrecarregar ainda mais o serviço.",
"incorrect_explanations": {
"A": "Pedir aumento de limite pode ser necessário em casos extremos, mas a primeira ação é aplicar o padrão de retry com backoff.",
"B": "Trocar para CLI não altera o limite de API nem resolve o throttling.",
"C": "Remover a chamada de API ignora o problema em vez de tratá-lo adequadamente."
}
},
{
"id": "dva-c02-development-070",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação está processando em tempo real milhões de eventos recebidos por uma API. Qual serviço pode ser usado para permitir que múltiplos consumidores processem os dados concorrentemente da forma MAIS econômica?",
"option_a": "Amazon SNS com fanout para uma fila SQS para cada aplicação.",
"option_b": "Amazon SNS com fanout para uma fila SQS FIFO para cada aplicação.",
"option_c": "Amazon Kinesis Firehose.",
"option_d": "Amazon Kinesis Streams.",
"correct_answers": ["D"],
"explanation_detailed": "O Amazon Kinesis Data Streams permite múltiplos consumidores lendo do mesmo stream em paralelo, com retenção de dados e capacidade de reprocessamento, o que é ideal para processar milhões de eventos em tempo real com vários consumidores.",
"incorrect_explanations": {
"A": "SNS + SQS funciona para fanout, mas não oferece a mesma capacidade de reprocessamento e consumo paralelo coordenado que Kinesis Streams.",
"B": "SQS FIFO é focado em ordenação e deduplicação, não em múltiplos consumidores concorrentes para o mesmo conjunto de mensagens.",
"C": "Kinesis Firehose é projetado para entrega em destinos como S3/Redshift/Elasticsearch, não para múltiplos consumidores em tempo real."
}
},
{
"id": "dva-c02-deployment-071",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Onde o arquivo appspec.yml deve ser colocado para que o AWS CodeDeploy funcione?",
"option_a": "Na raiz do diretório de código-fonte da aplicação.",
"option_b": "Na pasta bin junto com todo o código compilado.",
"option_c": "Em um bucket S3.",
"option_d": "Na mesma pasta dos arquivos de configuração da aplicação.",
"correct_answers": ["A"],
"explanation_detailed": "O CodeDeploy espera encontrar o arquivo appspec.yml na raiz do bundle de aplicação. Ele descreve como o deployment deve ser executado e onde colocar os arquivos.",
"incorrect_explanations": {
"B": "Colocar o appspec.yml em bin não é detectado pelo CodeDeploy por padrão.",
"C": "O bundle pode ser armazenado em S3, mas o arquivo precisa estar na raiz dentro do artefato de deploy.",
"D": "Arquivo de configuração da aplicação pode ficar em outra pasta; o appspec.yml tem localização própria na raiz."
}
},
{
"id": "dva-c02-development-072",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação irá ingerir dados com taxa muito alta de múltiplas fontes e deve armazenar esses dados em um bucket Amazon S3. Qual serviço realiza essa tarefa da melhor forma?",
"option_a": "Amazon Kinesis Firehose.",
"option_b": "Amazon S3 Transfer Acceleration.",
"option_c": "Amazon SQS.",
"option_d": "Amazon SNS.",
"correct_answers": ["A"],
"explanation_detailed": "O Amazon Kinesis Data Firehose é projetado para ingestão de alto throughput e entrega automática para destinos como S3, gerenciando bufferização, escalabilidade e tentativas de reenvio sem necessidade de infraestrutura própria.",
"incorrect_explanations": {
"B": "S3 Transfer Acceleration acelera uploads individuais, mas não gerencia ingestão contínua de múltiplas fontes com bufferização.",
"C": "SQS é um serviço de fila, não um pipeline de ingestão otimizado para despejar dados em S3.",
"D": "SNS é um serviço de notificação/pub-sub e não grava dados diretamente em S3."
}
},
{
"id": "dva-c02-development-073",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma função Lambda e usará bibliotecas externas que não estão incluídas nas bibliotecas padrão da Lambda. Que ação minimiza o tempo de computação consumido pela Lambda?",
"option_a": "Instalar as dependências e bibliotecas externas no início da função Lambda.",
"option_b": "Criar um pacote de implantação da Lambda que inclua as bibliotecas externas.",
"option_c": "Copiar as bibliotecas externas para o Amazon S3 e referenciá-las a partir de lá.",
"option_d": "Instalar as bibliotecas externas em uma Lambda Layer para estarem disponíveis para todas as funções Lambda.",
"correct_answers": ["B"],
"explanation_detailed": "Incluir as bibliotecas externas diretamente no pacote de implantação evita instalar ou baixar dependências em tempo de execução, reduzindo o tempo de inicialização e o consumo de computação da função.",
"incorrect_explanations": {
"A": "Instalar dependências a cada execução aumenta o tempo de inicialização e o custo de computação.",
"C": "Baixar bibliotecas de S3 em tempo de execução adiciona latência e complexidade desnecessárias.",
"D": "Lambda Layers facilitam o reuso entre funções, mas em termos de tempo de execução, o benefício principal é similar ao de empacotar as libs; a pergunta foca em evitar trabalho em tempo de execução, que a opção B descreve explicitamente."
}
},
{
"id": "dva-c02-development-074",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Durante horas de menor uso, um desenvolvedor quer minimizar o tempo de execução de um scan completo de uma tabela Amazon DynamoDB sem afetar workloads normais. Os workloads utilizam em média metade das unidades de capacidade de leitura fortemente consistente durante as horas de menor uso. Como otimizar esse scan?",
"option_a": "Usar parallel scans limitando a taxa.",
"option_b": "Usar scans sequenciais.",
"option_c": "Aumentar as unidades de capacidade de leitura durante a operação de scan.",
"option_d": "Mudar a consistência para eventually consistent durante a operação de scan.",
"correct_answers": ["A"],
"explanation_detailed": "Parallel scan divide a tabela em múltiplas partes, permitindo que o scan seja executado em paralelo e complete mais rápido. Ao limitar a taxa, o desenvolvedor pode aproveitar a capacidade ociosa (metade das RCUs) sem impactar workloads normais.",
"incorrect_explanations": {
"B": "Scans sequenciais são mais lentos e podem manter a carga na tabela por mais tempo.",
"C": "Aumentar RCUs aumenta custo; o problema informa que já há capacidade ociosa disponível.",
"D": "Usar leitura eventualmente consistente reduz custo por item, mas não resolve por si só o tempo de execução; paralelismo é o fator principal aqui."
}
},
{
"id": "dva-c02-development-075",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um grande site de e-commerce está sendo projetado para entregar objetos estáticos a partir do Amazon S3. O bucket S3 irá atender mais de 300 requisições GET por segundo. O que deve ser feito para otimizar a performance? (Escolha DUAS)",
"option_a": "Integrar o Amazon CloudFront com o Amazon S3.",
"option_b": "Habilitar replicação entre regiões no Amazon S3.",
"option_c": "Excluir arquivos de log do S3 já expirados.",
"option_d": "Configurar regras de ciclo de vida (lifecycle) no S3.",
"option_e": "Randomizar os prefixes de nome de chave (key name) no Amazon S3.",
"correct_answers": ["A", "E"],
"explanation_detailed": "Integrar o S3 com CloudFront cria uma CDN global, reduzindo latência e distribuindo o tráfego. Randomizar prefixes de chave ajuda o S3 a distribuir as requisições sobre múltiplas partições internas, permitindo altas taxas de requisição por segundo sem hot spots.",
"incorrect_explanations": {
"B": "Replicação entre regiões aumenta resiliência e disponibilidade geográfica, mas não é a principal otimização para throughput de GET no mesmo bucket.",
"C": "Excluir logs pode reduzir uso de armazenamento, mas não afeta diretamente a performance de leitura dos objetos.",
"D": "Regras de lifecycle tratam transição/expiração de objetos, não throughput de requisições."
}
},


{
"id": "dva-c02-development-076",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um serviço legado expõe uma interface SOAP baseada em XML. O desenvolvedor quer expor essa funcionalidade para clientes externos usando Amazon API Gateway. Qual técnica atende a esse requisito?",
"option_a": "Criar uma API RESTful no API Gateway e transformar o JSON de entrada em uma mensagem XML válida para a interface SOAP usando mapping templates.",
"option_b": "Criar uma API RESTful no API Gateway e encaminhar o JSON de entrada para a interface SOAP por meio de um Application Load Balancer.",
"option_c": "Criar uma API RESTful no API Gateway e encaminhar o XML de entrada diretamente para a interface SOAP por meio de um Application Load Balancer.",
"option_d": "Criar uma API RESTful no API Gateway e transformar o XML de entrada em uma mensagem válida para a interface SOAP usando mapping templates.",
"correct_answers": ["A"],
"explanation_detailed": "O padrão comum é que clientes REST usem JSON. O API Gateway pode receber JSON e, com mapping templates, transformá-lo em XML no formato esperado pelo backend SOAP. Isso permite expor uma API REST moderna sem alterar o serviço legado.",
"incorrect_explanations": {
"B": "Encaminhar JSON diretamente para o serviço SOAP não funciona, pois o backend espera XML estruturado.",
"C": "Isso presume que os clientes já enviam XML, o que foge do objetivo de oferecer uma API RESTful moderna com JSON.",
"D": "Transformar XML em outro XML não resolve o problema se os clientes falam JSON; a transformação relevante é de JSON para XML."
}
},
{
"id": "dva-c02-security-077",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor tem uma aplicação que faz upload de dezenas de milhares de objetos por segundo para um bucket Amazon S3 em paralelo, em uma única conta AWS. Novos requisitos exigem que todos os dados armazenados usem criptografia no lado do servidor com AWS KMS (SSE-KMS). Após essa mudança, a performance da aplicação ficou mais lenta. Qual é a causa MAIS provável da latência?",
"option_a": "O Amazon S3 está limitando a taxa com que objetos enviados podem ser criptografados usando Customer Master Keys.",
"option_b": "O limite de chamadas à API do AWS KMS é menor do que o necessário para atingir a performance desejada.",
"option_c": "A criptografia feita no cliente está usando um algoritmo fraco.",
"option_d": "O KMS exige que um alias seja usado para criar um nome independente mapeado para uma CMK.",
"correct_answers": ["B"],
"explanation_detailed": "Cada operação SSE-KMS envolve chamadas ao AWS KMS. Com dezenas de milhares de uploads por segundo, é fácil atingir limites de taxa do KMS, o que introduz latência adicional e degrada a performance geral da aplicação.",
"incorrect_explanations": {
"A": "O S3 não impõe um throttle específico de criptografia por CMK além dos limites do próprio KMS.",
"C": "A questão descreve SSE-KMS, não criptografia no cliente; o algoritmo do cliente não é o fator aqui.",
"D": "O uso de alias é apenas conveniência de nomenclatura e não causa latência perceptível."
}
},
{
"id": "dva-c02-deployment-078",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um cliente quer fazer deploy de seu código-fonte em um ambiente AWS Elastic Beanstalk. O cliente precisa executar o deployment com interrupção mínima e usar apenas instâncias existentes para manter acesso aos logs de aplicação. Qual política de deployment satisfaz esses requisitos?",
"option_a": "Rolling.",
"option_b": "All at once.",
"option_c": "Rolling with an additional batch.",
"option_d": "Immutable.",
"correct_answers": ["A"],
"explanation_detailed": "A política Rolling atualiza o ambiente em lotes usando as mesmas instâncias existentes. Isso minimiza interrupções (apenas parte das instâncias é atualizada de cada vez) e garante que os logs permaneçam nas instâncias originais.",
"incorrect_explanations": {
"B": "All at once atualiza todas as instâncias simultaneamente, causando downtime perceptível.",
"C": "Rolling with additional batch cria instâncias extras temporariamente, violando o requisito de usar apenas instâncias existentes.",
"D": "Immutable cria um novo conjunto de instâncias, o que também não atende à exigência sobre logs e instâncias existentes."
}
},
{
"id": "dva-c02-development-079",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação usa Amazon Kinesis Data Streams para ingerir e processar grandes fluxos de dados em tempo real. Instâncias EC2 consomem os dados dos shards usando a Kinesis Client Library (KCL). Um shard \"quente\" foi reparticionado e o número total de shards aumentou de 4 para 6. Qual é o número MÁXIMO de instâncias EC2 que podem ser implantadas para processar dados de todos os shards?",
"option_a": "12.",
"option_b": "6.",
"option_c": "4.",
"option_d": "1.",
"correct_answers": ["B"],
"explanation_detailed": "A KCL faz o balanceamento de shards entre workers, mas cada shard só pode ser processado ativamente por um único worker dentro de um mesmo grupo de consumidores. Com 6 shards, o máximo útil é 6 instâncias (ou 6 workers) para que cada shard tenha um consumidor dedicado.",
"incorrect_explanations": {
"A": "Ter mais workers do que shards não aumenta throughput, pois shards não podem ser divididos entre múltiplos consumidores concorrentes no mesmo grupo.",
"C": "4 instâncias só seriam suficientes antes do reshard; com 6 shards, isso reduziria paralelismo.",
"D": "Uma única instância pode consumir todos os shards, mas a pergunta é sobre o número máximo para paralelismo ideal."
}
},
{
"id": "dva-c02-security-080",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma organização deve armazenar milhares de arquivos de áudio e vídeo sensíveis em um bucket Amazon S3. As políticas de segurança exigem que todos os dados gravados nesse bucket sejam criptografados. Como garantir conformidade com essa política?",
"option_a": "Usar AWS Lambda para enviar notificações à equipe de segurança se objetos não criptografados forem gravados no bucket.",
"option_b": "Configurar uma bucket policy no S3 para impedir o upload de objetos que não contenham o cabeçalho x-amz-server-side-encryption.",
"option_c": "Criar uma regra de evento do Amazon CloudWatch para verificar se todos os objetos no bucket estão criptografados.",
"option_d": "Configurar uma bucket policy no S3 para impedir o upload de objetos que contenham o cabeçalho x-amz-server-side-encryption.",
"correct_answers": ["B"],
"explanation_detailed": "A abordagem mais robusta é usar uma bucket policy que negue qualquer PUT que não inclua o cabeçalho x-amz-server-side-encryption, forçando que todos os objetos sejam criptografados ao serem gravados.",
"incorrect_explanations": {
"A": "Notificar depois não impede que objetos não criptografados sejam armazenados.",
"C": "Monitorar com CloudWatch Events pode alertar, mas não bloqueia operações de gravação não conformes.",
"D": "Bloquear uploads que contenham o cabeçalho é o oposto do desejado; isso impediria justamente os objetos criptografados."
}
},
{
"id": "dva-c02-development-081",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação foi projetada para usar Amazon SQS para gerenciar mensagens de muitos remetentes independentes. As mensagens de cada remetente precisam ser processadas na ordem em que são recebidas. Qual recurso do SQS deve ser implementado?",
"option_a": "Configurar cada remetente com um MessageGroupId exclusivo.",
"option_b": "Habilitar MessageDeduplicationIds na fila SQS.",
"option_c": "Configurar cada mensagem com MessageGroupIds exclusivos.",
"option_d": "Habilitar ContentBasedDeduplication na fila SQS.",
"correct_answers": ["A"],
"explanation_detailed": "Com filas FIFO, o uso de um MessageGroupId exclusivo por remetente garante a ordem de processamento das mensagens daquele grupo, mantendo a sequência por remetente.",
"incorrect_explanations": {
"B": "MessageDeduplicationId trata de remoção de duplicados, não de ordenação.",
"C": "Um MessageGroupId diferente para cada mensagem destruiria a ordem, pois cada grupo teria apenas uma mensagem.",
"D": "ContentBasedDeduplication ajuda com duplicatas derivadas do conteúdo, não mantém ordenação por remetente."
}
},
{
"id": "dva-c02-security-082",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor criou um dashboard para uma aplicação usando Amazon API Gateway, Amazon S3, AWS Lambda e Amazon RDS. É necessário um mecanismo de autenticação que permita ao usuário fazer login e ver o dashboard a partir de apps mobile, desktops e tablets, lembrando preferências do usuário em todas as plataformas. Qual serviço AWS deve ser usado?",
"option_a": "AWS KMS.",
"option_b": "Amazon Cognito.",
"option_c": "AWS Directory Service.",
"option_d": "Amazon IAM.",
"correct_answers": ["B"],
"explanation_detailed": "O Amazon Cognito fornece cadastro, login, sincronização de dados de usuário e gerenciamento de identidades para múltiplas plataformas, sendo ideal para autenticação de usuários finais e persistência de preferências.",
"incorrect_explanations": {
"A": "KMS é usado para gerenciamento de chaves e criptografia, não para autenticação de usuários.",
"C": "Directory Service é voltado para integração com diretórios corporativos como AD.",
"D": "IAM é para identidades e permissões de recursos AWS, não para usuários de aplicação e suas preferências."
}
},
{
"id": "dva-c02-development-083",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma função Lambda é empacotada para deployment em múltiplos ambientes (desenvolvimento, teste, produção, etc.). Cada ambiente possui um conjunto exclusivo de recursos (como bancos de dados). Como a função Lambda pode usar os recursos referentes ao ambiente atual?",
"option_a": "Aplicar tags nas funções Lambda.",
"option_b": "Colocar os recursos diretamente no código-fonte (hardcode).",
"option_c": "Usar variáveis de ambiente nas funções Lambda.",
"option_d": "Criar uma função separada para desenvolvimento e outra para produção.",
"correct_answers": ["C"],
"explanation_detailed": "Variáveis de ambiente permitem que a mesma função Lambda seja configurada de forma diferente por ambiente (por exemplo, URLs de banco, ARNs, etc.) sem alterar o código-fonte.",
"incorrect_explanations": {
"A": "Tags são úteis para organização e billing, mas a função não lê tags automaticamente para descobrir recursos.",
"B": "Hardcodear recursos torna o deploy por ambiente rígido e difícil de manter.",
"D": "Criar funções diferentes aumenta a complexidade; o padrão recomendado é uma função com configuração por ambiente."
}
},
{
"id": "dva-c02-security-084",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa de acesso temporário a recursos em uma segunda conta AWS. Qual é a forma MAIS segura de conseguir isso?",
"option_a": "Usar Amazon Cognito user pools para obter credenciais de curta duração para a segunda conta.",
"option_b": "Criar uma access key IAM dedicada para a segunda conta e enviá-la por e-mail.",
"option_c": "Criar uma role de acesso cross-account e usar a API sts:AssumeRole para obter credenciais temporárias.",
"option_d": "Estabelecer confiança e adicionar uma chave SSH da segunda conta ao usuário IAM.",
"correct_answers": ["C"],
"explanation_detailed": "A prática recomendada para acesso entre contas é usar uma role cross-account e a API AssumeRole para obter credenciais temporárias, sem compartilhar chaves estáticas.",
"incorrect_explanations": {
"A": "Cognito é voltado para usuários de aplicações, não para acesso administrativo entre contas.",
"B": "Compartilhar access keys é inseguro e difícil de revogar e auditar.",
"D": "Chaves SSH são usadas para login em instâncias, não para acesso a APIs AWS entre contas."
}
},
{
"id": "dva-c02-monitoring-085",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa usar AWS X-Ray para monitorar uma aplicação implantada em instâncias EC2. Quais passos devem ser executados para realizar o monitoramento?",
"option_a": "Implantar o X-Ray SDK com a aplicação e usar X-Ray annotation.",
"option_b": "Instalar o X-Ray daemon e instrumentar o código da aplicação.",
"option_c": "Instalar o X-Ray daemon e configurá-lo para encaminhar dados para Amazon CloudWatch Events.",
"option_d": "Implantar o X-Ray SDK com a aplicação e instrumentar o código da aplicação.",
"correct_answers": ["B"],
"explanation_detailed": "Para aplicações em EC2, é necessário instrumentar o código com o X-Ray SDK e executar o X-Ray daemon na instância. O daemon recebe os segmentos do SDK e os envia para o serviço X-Ray.",
"incorrect_explanations": {
"A": "Apenas o SDK não é suficiente; sem o daemon os dados não serão enviados ao serviço X-Ray.",
"C": "CloudWatch Events não é o destino principal para traces X-Ray; o daemon deve enviar diretamente ao X-Ray.",
"D": "Novamente, falta o daemon, que é parte obrigatória da arquitetura do X-Ray em EC2."
}
},
{
"id": "dva-c02-monitoring-086",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando um Auto Scaling group cujas instâncias precisam publicar uma métrica customizada no Amazon CloudWatch. Qual é a forma MAIS segura de autenticar a chamada PutMetricData?",
"option_a": "Criar um usuário IAM com permissão PutMetricData, colocar as credenciais em um repositório privado e fazer as aplicações buscarem essas credenciais.",
"option_b": "Criar um usuário IAM com permissão PutMetricData e modificar a launch configuration para injetar as credenciais no user data da instância.",
"option_c": "Modificar as policies do CloudWatch para permitir PutMetricData a partir das instâncias do Auto Scaling group.",
"option_d": "Criar uma IAM role com permissão PutMetricData e modificar a launch configuration para lançar instâncias com essa role.",
"correct_answers": ["D"],
"explanation_detailed": "A abordagem correta é anexar uma IAM role às instâncias via instance profile. Assim, cada instância obtém credenciais temporárias automaticamente via metadata, sem expor chaves estáticas.",
"incorrect_explanations": {
"A": "Armazenar credenciais de usuário IAM em repositórios é inseguro e difícil de gerenciar.",
"B": "Injetar chaves no user data expõe credenciais e viola boas práticas.",
"C": "Policies do CloudWatch não substituem a necessidade de autenticação via roles ou usuários; o caminho recomendado é role por instância."
}
},
{
"id": "dva-c02-development-087",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação rastreia centenas de milhões de avaliações de produtos em uma tabela Amazon DynamoDB. Os registros incluem starRating, reviewID, comment e productID. Qual campo, quando usado como partition key, resulta na performance MAIS consistente?",
"option_a": "starRating.",
"option_b": "reviewID.",
"option_c": "comment.",
"option_d": "productID.",
"correct_answers": ["B"],
"explanation_detailed": "reviewID é único por avaliação e tende a ser distribuído de forma uniforme, resultando em boa distribuição de carga entre partições. productID pode concentrar muitos acessos em poucos produtos populares, causando hot partitions.",
"incorrect_explanations": {
"A": "starRating possui poucos valores possíveis (1–5), criando forte desigualdade entre partições.",
"C": "comment é texto livre e pouco adequado como chave de partição, além de difícil de projetar consultas.",
"D": "productID pode levar a hot spots em produtos muito populares, prejudicando a consistência de performance."
}
},
{
"id": "dva-c02-security-088",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um time de desenvolvimento possui 10 membros. O gerente quer conceder acesso a pastas específicas em um bucket S3, como se fosse um diretório \"home\" para cada membro (por exemplo, s3://bucket/TeamMemberX/). Em vez de criar policies distintas para cada membro, que abordagem pode tornar esse snippet de policy genérico para todos?",
"option_a": "Usar condition em policies IAM.",
"option_b": "Usar principal em policies IAM.",
"option_c": "Usar variáveis em policies IAM.",
"option_d": "Usar resource em policies IAM.",
"correct_answers": ["C"],
"explanation_detailed": "IAM policy variables permitem interpolar, por exemplo, o nome do usuário (${aws:username}) no ARN do recurso, criando uma única policy que se adapta ao usuário que a recebe.",
"incorrect_explanations": {
"A": "Conditions complementam o controle, mas não substituem o uso de variáveis para gerar paths por usuário.",
"B": "O principal define quem recebe a policy, mas não resolve a necessidade de ARN dinâmico por usuário.",
"D": "A seção resource define os ARNs, mas sem variáveis seria necessário especificar cada path manualmente."
}
},
{
"id": "dva-c02-security-089",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa precisa criptografar dados em repouso, mas quer usar um serviço gerenciado da AWS com sua própria chave mestra. Qual serviço atende a esses requisitos?",
"option_a": "SSE com Amazon S3 (SSE-S3).",
"option_b": "SSE com AWS KMS.",
"option_c": "Criptografia no lado do cliente.",
"option_d": "Roles e policies do AWS IAM.",
"correct_answers": ["B"],
"explanation_detailed": "Server-side encryption com AWS KMS (SSE-KMS) permite que a empresa use chaves gerenciadas pelo KMS (inclusive CMKs gerenciadas pelo cliente), com trilhas de auditoria e rotação controlada.",
"incorrect_explanations": {
"A": "SSE-S3 usa chaves gerenciadas pelo S3, não CMKs de propriedade do cliente.",
"C": "Criptografia no cliente funciona, mas exige que a empresa gerencie toda a infraestrutura de chaves.",
"D": "IAM trata de autorização, não de criptografia em repouso."
}
},
{
"id": "dva-c02-security-090",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor criou um pacote de software para ser implantado em múltiplas instâncias EC2 usando IAM roles. Que ações podem ser realizadas para verificar o acesso IAM para obter registros de Amazon Kinesis Streams? (Selecione DUAS)",
"option_a": "Usar a AWS CLI para recuperar o IAM group.",
"option_b": "Consultar os metadados da EC2 em busca de inline policies de IAM.",
"option_c": "Solicitar um token ao AWS STS e executar uma ação de describe.",
"option_d": "Executar uma ação de get usando o argumento --dry-run.",
"option_e": "Validar a policy da IAM role com o IAM policy simulator.",
"correct_answers": ["C", "E"],
"explanation_detailed": "Uma forma prática é solicitar credenciais temporárias via STS e testar chamadas de describe/get na API do Kinesis. Além disso, o IAM policy simulator permite validar de forma estática se a policy anexada à role permite as ações desejadas.",
"incorrect_explanations": {
"A": "Recuperar o IAM group não ajuda a validar permissões da role usada pelas instâncias.",
"B": "Metadados da EC2 fornecem a role anexada, não a validação efetiva de permissões.",
"D": "O parâmetro --dry-run não é suportado por APIs do Kinesis e, mesmo quando existe, verifica apenas formato e autorização básica, não o fluxo de acesso completo."
}
},
{
"id": "dva-c02-deployment-091",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa quer implementar integração contínua para seus workloads na AWS. Precisa disparar testes unitários no pipeline a cada commit no repositório de código e ser notificada em caso de falha no pipeline. Como atender a esses requisitos?",
"option_a": "Armazenar o código no AWS CodeCommit, criar um CodePipeline para automatizar testes unitários e usar Amazon SNS para disparar notificações de falha.",
"option_b": "Armazenar o código no GitHub, criar um CodePipeline para automatizar testes unitários e usar Amazon SES para notificações.",
"option_c": "Armazenar o código no GitHub, criar um CodePipeline para automatizar testes unitários e usar Amazon CloudWatch para notificações.",
"option_d": "Armazenar o código no AWS CodeCommit, criar um CodePipeline para automatizar testes unitários e usar Amazon CloudWatch para disparar notificações de falha.",
"correct_answers": ["D"],
"explanation_detailed": "CodeCommit integra nativamente com CodePipeline para disparar o pipeline em cada commit. Eventos de mudança de estado no CodePipeline podem ser capturados por regras do CloudWatch Events, que então disparam notificações (por exemplo, via SNS), atendendo ao requisito de alerta em caso de falha.",
"incorrect_explanations": {
"A": "A opção não menciona o uso de CloudWatch/Events para capturar falhas no pipeline; o enunciado enfatiza notificação baseada em eventos de falha.",
"B": "É possível integrar GitHub com CodePipeline, mas a opção não descreve claramente o encadeamento de notificação por falha; SES também não é a escolha mais típica aqui.",
"C": "Falta a ligação explícita entre CloudWatch e um mecanismo de notificação; por si só CloudWatch não envia notificações sem alarmes/regras adicionais."
}
},
{
"id": "dva-c02-development-092",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação leva 40 segundos para processar instruções recebidas em uma mensagem Amazon SQS. Considerando que a fila está com o VisibilityTimeout padrão, qual é a melhor forma de garantir que nenhuma outra instância possa receber a mesma mensagem enquanto ela está sendo processada?",
"option_a": "Usar a API ChangeMessageVisibility para aumentar o VisibilityTimeout e depois usar DeleteMessage para apagar a mensagem.",
"option_b": "Usar DeleteMessage para apagar a mensagem da fila e depois DeleteQueue para remover a fila.",
"option_c": "Usar ChangeMessageVisibility para diminuir o timeout e depois DeleteMessage para apagar a mensagem.",
"option_d": "Usar DeleteMessageVisibility para cancelar o VisibilityTimeout e depois DeleteMessage para apagar a mensagem.",
"correct_answers": ["A"],
"explanation_detailed": "Como o processamento leva mais que os 30 segundos padrão, é necessário aumentar o VisibilityTimeout para um valor acima de 40 segundos usando ChangeMessageVisibility. Após o processamento bem-sucedido, a mensagem deve ser removida com DeleteMessage.",
"incorrect_explanations": {
"B": "Apagar a fila não é necessário e ainda interrompe todo o fluxo de mensagens.",
"C": "Diminuir o timeout tornaria mais provável que outras instâncias recebessem a mesma mensagem antes do fim do processamento.",
"D": "DeleteMessageVisibility não é uma operação válida; o fluxo correto é ChangeMessageVisibility seguido de DeleteMessage."
}
},
{
"id": "dva-c02-security-093",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma aplicação que gerencia transações financeiras. Para aumentar a segurança, MFA será exigido como parte do protocolo de login. Que serviço pode ser usado para atender a esse requisito?",
"option_a": "Amazon DynamoDB para armazenar sessões de MFA e Amazon SNS para enviar códigos.",
"option_b": "Amazon Cognito com MFA.",
"option_c": "AWS Directory Service.",
"option_d": "AWS IAM com MFA habilitado.",
"correct_answers": ["B"],
"explanation_detailed": "Amazon Cognito suporta MFA nativamente para usuários de aplicações, incluindo envio de códigos e verificação, facilitando a implementação de autenticação forte em aplicações web e mobile.",
"incorrect_explanations": {
"A": "Implementar toda a lógica de MFA manualmente aumenta muito a complexidade e risco de erros.",
"C": "Directory Service é voltado para integração com diretórios corporativos, não para MFA de usuários finais em apps.",
"D": "IAM com MFA é voltado para usuários administrativos da conta AWS, não para clientes da aplicação."
}
},
{
"id": "dva-c02-development-094",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo transações em uma tabela DynamoDB chamada SystemUpdates com 5 unidades de capacidade de escrita. Qual opção oferece o MAIOR throughput de leitura?",
"option_a": "Leituras eventualmente consistentes com 5 unidades de capacidade de leitura lendo itens de 4 KB.",
"option_b": "Leituras fortemente consistentes com 5 unidades de capacidade de leitura lendo itens de 4 KB.",
"option_c": "Leituras eventualmente consistentes com 15 unidades de capacidade de leitura lendo itens de 1 KB.",
"option_d": "Leituras fortemente consistentes com 15 unidades de capacidade de leitura lendo itens de 1 KB.",
"correct_answers": ["C"],
"explanation_detailed": "Leituras eventualmente consistentes consomem metade da capacidade por leitura. Com 15 RCUs e itens de 1 KB, é possível obter o maior número de leituras por segundo entre as opções listadas.",
"incorrect_explanations": {
"B": "Leituras fortemente consistentes consomem mais capacidade por leitura que as eventualmente consistentes.",
"A": "Embora eventualmente consistente seja mais eficiente, 5 RCUs oferecem bem menos throughput que 15 RCUs.",
"D": "15 RCUs fortemente consistentes oferecem menos leituras por segundo do que 15 RCUs eventualmente consistentes com o mesmo tamanho de item."
}
},
{
"id": "dva-c02-monitoring-095",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor habilitou server access logging em um bucket S3 s3://mycoolapp apontando para s3://mycoolapp/logs. Ele moveu 100 KB de arquivos CSS para s3://mycoolapp/css e, dias depois, o bucket estava com 50 GB. Qual é a causa MAIS provável?",
"option_a": "Os arquivos CSS não foram comprimidos e o versionamento do S3 estava habilitado.",
"option_b": "A replicação do S3 estava habilitada no bucket.",
"option_c": "O logging para o mesmo bucket causou crescimento exponencial de logs.",
"option_d": "Uma lifecycle policy moveu todo o conteúdo CSS para S3 Infrequent Access.",
"correct_answers": ["C"],
"explanation_detailed": "Quando o target de logs é o mesmo bucket, os próprios logs geram novos acessos, que geram novos logs, causando crescimento em cascata do volume de logs.",
"incorrect_explanations": {
"A": "Compressão e versionamento não explicam um crescimento exponencial associado ao diretório de logs.",
"B": "Replicação duplicaria dados, mas não geraria crescimento em cadeia apenas por habilitar logs.",
"D": "Classes de armazenamento afetam custo, não o volume de dados armazenados."
}
},
{
"id": "dva-c02-security-096",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação Docker usa o AWS SDK para interagir com Amazon DynamoDB. No ambiente local de desenvolvimento, a aplicação usava access keys IAM. Agora será implantada em um cluster ECS. Como a aplicação deve se autenticar com serviços AWS em produção?",
"option_a": "Configurar uma IAM role de tarefa (task role) do ECS para a aplicação usar.",
"option_b": "Refatorar a aplicação para chamar STS AssumeRole com base em uma instance role.",
"option_c": "Configurar variáveis de ambiente com novas access keys.",
"option_d": "Configurar o arquivo de credenciais com uma nova access key/secret access key.",
"correct_answers": ["A"],
"explanation_detailed": "No ECS, a forma recomendada é associar uma task role IAM à definição de tarefa. O SDK dentro do contêiner usa essas credenciais temporárias obtidas automaticamente, sem embutir chaves estáticas.",
"incorrect_explanations": {
"B": "Usar instance role + AssumeRole é mais complexo e menos direto do que usar task roles nativas no ECS.",
"C": "Colocar chaves em variáveis de ambiente é inseguro e difícil de gerenciar.",
"D": "Usar arquivo de credenciais com chaves estáticas também viola boas práticas e dificulta rotação."
}
},
{
"id": "dva-c02-monitoring-097",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa usa AWS CodeBuild para compilar um website a partir de código no AWS CodeCommit. Uma mudança recente no código fez com que o projeto CodeBuild não consiga mais compilar. Como o desenvolvedor pode identificar a causa das falhas?",
"option_a": "Modificar o buildspec.yml para enviar a saída dos comandos de build para o Amazon CloudWatch.",
"option_b": "Usar uma imagem Docker customizada com o agente AWS X-Ray no CodeBuild.",
"option_c": "Verificar os logs de build da fase que falhou na última tentativa no histórico do projeto CodeBuild.",
"option_d": "Reexecutar manualmente o processo de build em uma máquina local para visualizar a saída.",
"correct_answers": ["C"],
"explanation_detailed": "O CodeBuild já captura logs detalhados de cada fase do build. Verificar os logs da fase que falhou é a forma mais direta e suportada de entender o erro.",
"incorrect_explanations": {
"A": "Não é necessário alterar o buildspec só para ver logs; o CodeBuild já envia logs para o console e, se configurado, para CloudWatch Logs.",
"B": "X-Ray não é a ferramenta adequada para depurar falhas de compilação.",
"D": "Reproduzir localmente pode ajudar, mas o caminho mais simples e imediato é usar os logs já disponíveis no serviço."
}
},
{
"id": "dva-c02-deployment-098",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Em um deployment in-place usando AWS CodeDeploy, qual é a ordem de execução dos hooks no appspec.yml?",
"option_a": "BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall.",
"option_b": "ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart.",
"option_c": "BeforeInstall -> ApplicationStop -> ValidateService -> ApplicationStart.",
"option_d": "ApplicationStop -> BeforeInstall -> ValidateService -> ApplicationStart.",
"correct_answers": ["B"],
"explanation_detailed": "Para deployments in-place, a ordem de hooks do CodeDeploy começa com ApplicationStop, seguido por BeforeInstall, AfterInstall e, por fim, ApplicationStart, permitindo parar a aplicação, instalar arquivos e então reiniciar.",
"incorrect_explanations": {
"A": "Coloca BeforeInstall antes de ApplicationStop, o que não corresponde ao fluxo padrão.",
"C": "Altera a ordem e não inclui AfterInstall no ponto correto.",
"D": "Inclui ValidateService na posição errada e omite AfterInstall, divergindo do fluxo típico de in-place."
}
},
{
"id": "dva-c02-security-099",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor executou um comando AWS CLI e recebeu um erro com uma mensagem de autorização codificada. Que ação deve ser tomada para tornar essa mensagem legível?",
"option_a": "Chamar o AWS KMS para decodificar a mensagem.",
"option_b": "Usar a API decode-authorization-message do AWS STS para decodificar a mensagem.",
"option_c": "Usar uma biblioteca open source de decodificação.",
"option_d": "Usar a API decode-authorization-message do AWS IAM para decodificar a mensagem.",
"correct_answers": ["B"],
"explanation_detailed": "A API decode-authorization-message é exposta pelo AWS STS e foi criada especificamente para decodificar mensagens de erro de autorização codificadas retornadas por alguns serviços.",
"incorrect_explanations": {
"A": "KMS lida com chaves de criptografia, não com mensagens de autorização codificadas.",
"C": "Bibliotecas genéricas não entendem o formato específico usado para essas mensagens.",
"D": "A API pertence ao serviço STS, não ao IAM."
}
},
{
"id": "dva-c02-security-100",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor usa AWS CodeDeploy para automatizar o deployment de uma aplicação que se conecta a um banco MySQL externo. O desenvolvedor quer acessar segredos criptografados, como chaves de API e senhas de banco, com o MENOR esforço administrativo possível. Qual solução é mais adequada?",
"option_a": "Salvar os segredos em Amazon S3 com criptografia SSE-KMS e usar URLs assinadas a partir da IAM role das instâncias EC2.",
"option_b": "Usar os metadados da instância para armazenar os segredos e acessar programaticamente a partir das instâncias EC2.",
"option_c": "Usar a biblioteca de criptografia client-side do Amazon DynamoDB para salvar os segredos em DynamoDB e acessá-los programaticamente.",
"option_d": "Usar o AWS Systems Manager Parameter Store para armazenar os segredos e acessá-los programaticamente a partir da IAM role das instâncias EC2.",
"correct_answers": ["D"],
"explanation_detailed": "O Parameter Store oferece armazenamento gerenciado de parâmetros e segredos, com integração com KMS, controle de acesso via IAM e fácil acesso a partir de instâncias EC2 e aplicações, com baixo esforço operacional.",
"incorrect_explanations": {
"A": "S3 pode armazenar segredos, mas exige mais lógica de segurança, controle de acesso e manuseio de URLs assinadas.",
"B": "Metadados de instância não são destinados ao armazenamento de segredos persistentes e são difíceis de gerenciar com segurança.",
"C": "Usar DynamoDB com criptografia client-side é possível, porém aumenta a complexidade em comparação ao uso direto do Parameter Store."
}
},

{
"id": "dva-c02-monitoring-101",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor criou uma função AWS Lambda para o backend de uma aplicação web. Ao testar a função Lambda pelo console da AWS, o desenvolvedor vê que a função é executada, mas nenhum dado de log é gerado no Amazon CloudWatch Logs, mesmo após vários minutos. O que poderia causar essa situação?",
"option_a": "A função Lambda não tem nenhuma chamada explícita de log para enviar dados ao CloudWatch Logs.",
"option_b": "A função Lambda está sem o CloudWatch Logs configurado como fonte de evento para enviar dados de log.",
"option_c": "A role de execução da função Lambda está sem permissões para gravar dados de log no CloudWatch Logs.",
"option_d": "A função Lambda está sem um grupo de logs do CloudWatch configurado como destino.",
"correct_answers": ["C"],
"explanation_detailed": "Mesmo que o código use console.log (ou logs equivalentes), a runtime do Lambda só consegue criar o grupo de logs e o stream e enviar eventos se a role de execução tiver permissões para logs:CreateLogGroup, logs:CreateLogStream e logs:PutLogEvents. Sem essas permissões, a função executa, mas nada aparece no CloudWatch Logs.",
"incorrect_explanations": {
"A": "A maioria das runtimes já registra pelo menos logs de inicialização/erros. Mesmo sem logs explícitos do desenvolvedor, ainda deveria haver alguma saída se as permissões estivessem corretas.",
"B": "CloudWatch Logs não é configurado como \"fonte de trigger\"; é um destino de logs gerenciado pela própria integração do Lambda.",
"D": "Não é obrigatório configurar um grupo de logs manualmente. O Lambda cria o grupo e o stream automaticamente, desde que tenha permissões."
}
},
{
"id": "dva-c02-monitoring-102",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor quer usar o AWS X-Ray para rastrear uma requisição de usuário de ponta a ponta na pilha de software. O desenvolvedor fez as alterações necessárias na aplicação, testou e verificou que a aplicação consegue enviar traces para o X-Ray. Porém, quando a aplicação é implantada em uma instância EC2, os traces não aparecem. Quais das seguintes situações podem causar isso? (Selecione DUAS)",
"option_a": "Os traces estão chegando ao X-Ray, mas o desenvolvedor não tem permissão para visualizar os registros.",
"option_b": "O daemon do X-Ray não está instalado na instância EC2.",
"option_c": "O endpoint do X-Ray especificado na configuração da aplicação está incorreto.",
"option_d": "A role da instância não tem permissões xray:BatchGetTraces e xray:GetTraceGraph.",
"option_e": "A role da instância não tem permissões xray:PutTraceSegments e xray:PutTelemetryRecords.",
"correct_answers": ["B", "E"],
"explanation_detailed": "Para que as aplicações em EC2 enviem traces ao X-Ray, é necessário que o daemon do X-Ray esteja em execução na instância e que a role associada à instância tenha permissões para enviar segmentos e telemetria (xray:PutTraceSegments e xray:PutTelemetryRecords). Sem o daemon ou sem essas permissões, os traces não chegam ao serviço.",
"incorrect_explanations": {
"A": "Se o problema fosse apenas de permissão de visualização, ainda haveria traces no serviço; aqui o problema é que eles nem chegam ao X-Ray a partir da instância EC2.",
"C": "Um endpoint incorreto poderia causar falhas, mas é menos provável se em ambiente local com a mesma configuração tudo funciona; o problema clássico em EC2 é ausência de daemon ou de permissões.",
"D": "Essas permissões são usadas para ler traces, não para enviá-los. O problema descrito é de ausência total de traces, não de leitura ou análise."
}
},
{
"id": "dva-c02-security-103",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação tem centenas de usuários, e cada usuário pode usar vários dispositivos para acessá-la. O desenvolvedor quer atribuir identificadores únicos a esses usuários independentemente do dispositivo utilizado. Qual método deve ser usado para obter identificadores únicos?",
"option_a": "Criar uma tabela de usuários no Amazon DynamoDB como pares chave-valor de usuários e seus dispositivos e usar essas chaves como identificadores únicos.",
"option_b": "Usar IDs de access key gerados pelo IAM para os usuários como identificador único, mas sem armazenar as secret keys.",
"option_c": "Implementar identidades autenticadas pelo desenvolvedor usando o Amazon Cognito e obter credenciais para essas identidades.",
"option_d": "Atribuir usuários e roles do IAM para cada usuário e usar o ID de recurso do IAM como identificador único.",
"correct_answers": ["C"],
"explanation_detailed": "As identidades autenticadas pelo desenvolvedor no Amazon Cognito permitem que você associe um identificador lógico a um usuário e receba um ID único que permanece consistente entre dispositivos. Isso resolve o problema de identificar o mesmo usuário em múltiplas plataformas, sem depender de credenciais IAM ou de amarrar diretamente usuários a dispositivos.",
"incorrect_explanations": {
"A": "Manter manualmente uma tabela de dispositivos e usuários complica a lógica e não resolve diretamente o problema de um identificador global único gerenciado pelo serviço de identidade.",
"B": "Access keys do IAM não são um mecanismo recomendado para identificar usuários finais de aplicações. Elas são sensíveis e não devem ser distribuídas ou usadas como IDs lógicos.",
"D": "Criar usuários IAM para cada usuário final não é escalável nem recomendado em aplicações voltadas a clientes. IAM é para identidades de conta, não para milhões de usuários de app."
}
},
{
"id": "dva-c02-deployment-104",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Quais são os passos para usar a AWS CLI para lançar uma aplicação serverless baseada em template?",
"option_a": "Usar aws cloudformation get-template e depois cloudformation execute-change-set.",
"option_b": "Usar aws cloudformation validate-template e depois cloudformation create-change-set.",
"option_c": "Usar aws cloudformation package e depois cloudformation deploy.",
"option_d": "Usar aws cloudformation create-stack e depois cloudformation update-stack.",
"correct_answers": ["C"],
"explanation_detailed": "Para aplicações serverless templadas (inclusive com AWS SAM), o fluxo recomendado com a AWS CLI é usar aws cloudformation package para empacotar o código em um bucket S3 e reescrever o template com os artefatos, e depois aws cloudformation deploy para criar ou atualizar o stack usando o template empacotado.",
"incorrect_explanations": {
"A": "get-template e execute-change-set são usados para outras etapas de gerenciamento, não para empacotar e implantar aplicações serverless.",
"B": "validate-template apenas valida a sintaxe do template, não empacota código nem faz o deploy por si só.",
"D": "create-stack/update-stack funcionam, mas exigem que você mesmo faça o empacotamento dos artefatos; o fluxo package/deploy automatiza essa parte para aplicações serverless."
}
},
{
"id": "dva-c02-security-105",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um pacote de deployment usa a AWS CLI para copiar arquivos para qualquer bucket S3 na conta, usando access keys armazenadas em variáveis de ambiente. O pacote roda em instâncias EC2, e essas instâncias foram modificadas para usar uma role assumida com política mais restrita, permitindo acesso apenas a um bucket específico. Após a mudança, o desenvolvedor acessa a instância e ainda consegue gravar em todos os buckets S3 da conta. Qual é a causa MAIS provável desse cenário?",
"option_a": "Uma inline policy de IAM está sendo usada na role do IAM.",
"option_b": "Uma managed policy de IAM está sendo usada na role do IAM.",
"option_c": "A AWS CLI está corrompida e precisa ser reinstalada.",
"option_d": "O provedor de credenciais da AWS procura credenciais de instance profile por último.",
"correct_answers": ["D"],
"explanation_detailed": "A cadeia de providência de credenciais da AWS prioriza variáveis de ambiente e arquivos de credenciais antes das credenciais do instance profile. Como ainda existem access keys antigas nas variáveis de ambiente, a CLI continua usando essas credenciais, ignorando a role mais restrita da instância.",
"incorrect_explanations": {
"A": "Inline ou managed policy na role não explicam por que credenciais antigas ainda funcionam; o problema é qual fonte de credencial está sendo usada.",
"B": "Mesmo que haja uma managed policy mais permissiva, isso não explicaria o fato de a role ter sido supostamente restringida e, ainda assim, continuar com acesso amplo se a CLI estivesse usando a role de fato.",
"C": "Não há indicação de corrupção da CLI; o comportamento é consistente com a ordem normal de resolução de credenciais."
}
},
{
"id": "dva-c02-development-106",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação sobrescreve um objeto em um bucket Amazon S3 e, em seguida, lê imediatamente o mesmo objeto. Por que a aplicação às vezes recupera a versão antiga do objeto?",
"option_a": "Operações PUT de sobrescrita em S3 são eventualmente consistentes, então a aplicação pode ler o objeto antigo.",
"option_b": "A aplicação precisa adicionar metadados extras para rotular a versão mais recente ao enviar o objeto ao S3.",
"option_c": "Todas as operações PUT no S3 são eventualmente consistentes, então a aplicação pode ler o objeto antigo.",
"option_d": "A aplicação precisa especificar explicitamente a versão mais recente ao recuperar o objeto.",
"correct_answers": ["A"],
"explanation_detailed": "O Amazon S3 oferece consistência read-after-write para novos objetos, mas operações de sobrescrita e deleção são eventualmente consistentes. Logo após uma sobrescrita, é possível que a leitura retorne temporariamente a versão anterior do objeto.",
"incorrect_explanations": {
"B": "Metadados não mudam o modelo de consistência do S3; eles não forçam a leitura da versão mais recente.",
"C": "Novos PUTs de objetos em S3 têm consistência read-after-write, então nem todos os PUTs são eventualmente consistentes.",
"D": "Mesmo com versionamento, o comportamento padrão é retornar a versão atual; o problema está na janela de consistência, não na seleção de versão."
}
},
{
"id": "dva-c02-security-107",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação em desenvolvimento precisa armazenar centenas de arquivos de vídeo. Os dados devem ser criptografados dentro da aplicação antes do armazenamento, com uma chave única para cada arquivo. Como o desenvolvedor deve implementar isso?",
"option_a": "Usar a API KMS Encrypt para criptografar diretamente os dados. Armazenar a data key criptografada e os dados.",
"option_b": "Usar uma biblioteca de criptografia para gerar uma chave única para a aplicação, criptografar os dados e armazenar os dados criptografados.",
"option_c": "Usar a API KMS GenerateDataKey para obter uma data key. Criptografar os dados com essa data key. Armazenar a data key criptografada e os dados.",
"option_d": "Fazer upload dos dados para um bucket S3 usando criptografia no lado do servidor com uma CMK do AWS KMS.",
"correct_answers": ["C"],
"explanation_detailed": "GenerateDataKey retorna uma data key em texto claro e a mesma chave criptografada pela CMK. A aplicação usa a data key em texto claro para criptografar o arquivo localmente e armazena apenas os dados e a data key criptografada. Isso permite chave única por arquivo e delega ao KMS o gerenciamento seguro da CMK.",
"incorrect_explanations": {
"A": "Criptografar o corpo de dados inteiro diretamente com a API Encrypt do KMS não é escalável nem eficiente para grandes arquivos.",
"B": "Usar uma única chave para todos os arquivos aumenta o risco; se a chave vazar, todos os arquivos são comprometidos.",
"D": "SSE-KMS criptografa no lado do servidor depois que o objeto chega ao S3; a exigência é criptografar na própria aplicação antes do envio."
}
},
{
"id": "dva-c02-development-108",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está testando uma aplicação que invoca uma função AWS Lambda de forma assíncrona. Durante os testes, a função Lambda falha ao processar mesmo após duas tentativas de retry. Como o desenvolvedor pode investigar essa falha?",
"option_a": "Configurar o AWS CloudTrail para registrar as falhas de invocação.",
"option_b": "Configurar uma Dead Letter Queue enviando eventos para o Amazon SQS para investigação.",
"option_c": "Configurar o Amazon Simple Workflow Service para processar eventos não processados diretamente.",
"option_d": "Configurar o AWS Config para processar eventos não processados diretamente.",
"correct_answers": ["B"],
"explanation_detailed": "Para invocações assíncronas, o Lambda suporta Dead Letter Queues (DLQ) usando SQS ou SNS. Se a função falhar após as tentativas de retry, o evento pode ser enviado para a fila SQS, onde o desenvolvedor consegue inspecionar os payloads problemáticos e depurar a causa.",
"incorrect_explanations": {
"A": "CloudTrail registra chamadas de API, não o payload detalhado de eventos que falharam no processamento.",
"C": "SWF não é necessário aqui; o problema é inspecionar eventos que falharam em uma invocação assíncrona do Lambda.",
"D": "AWS Config é para configuração de recursos; não é usado para guardar eventos de falha de funções Lambda."
}
},
{
"id": "dva-c02-development-109",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está configurando o Amazon API Gateway para os produtos de sua empresa. A API será usada por desenvolvedores registrados para consultar e atualizar seus ambientes. A empresa quer limitar a quantidade de requisições que os usuários finais podem enviar, tanto por custo quanto por segurança, e quer oferecer \"pacotes\" maiores para quem pagar por mais chamadas. Como o desenvolvedor pode fazer isso com o MENOR esforço operacional?",
"option_a": "Ativar throttling no stage do API Gateway, definir valores de rate e burst e criar um stage separado com valores maiores para cada usuário que comprar um pacote maior.",
"option_b": "Configurar logs de API no CloudWatch, criar filtros por usuário e requestTime, alarmes e uma função Lambda que bloqueia usuários que excedem o limite.",
"option_c": "Ativar métricas do CloudWatch no stage, criar alarmes com ação Deny quando o Count passar do limite e criar alarmes específicos por usuário para pacotes maiores.",
"option_d": "Criar um usage plan padrão com rate e burst definidos e associá-lo a um stage. Para usuários com pacote maior, criar um usage plan customizado e associá-lo ao API key desse usuário.",
"correct_answers": ["D"],
"explanation_detailed": "Usage plans do API Gateway foram feitos exatamente para isso: limitar rate/burst por API key, permitindo diferentes planos para diferentes clientes. Assim, cada desenvolvedor registrado ganha um API key associado a um usage plan que define seus limites.",
"incorrect_explanations": {
"A": "Fazer um stage por usuário não escala e aumenta muito a complexidade operacional.",
"B": "Esse fluxo com CloudWatch + Lambda é muito mais complexo e manual do que usar o recurso nativo de usage plans.",
"C": "CloudWatch alarmes com ação 'Deny' não são uma mecânica real de bloqueio de chamadas pelo API Gateway, e essa solução não faz uso dos recursos nativos da plataforma."
}
},
{
"id": "dva-c02-development-110",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está refatorando uma aplicação monolítica. A aplicação recebe requisições POST e executa várias operações: algumas em paralelo e outras de forma sequencial. Essas operações foram refatoradas em funções AWS Lambda individuais. A requisição POST será recebida pelo Amazon API Gateway. Como o desenvolvedor deve invocar as funções Lambda na mesma sequência usando o API Gateway?",
"option_a": "Usar o Amazon SQS para invocar as funções Lambda.",
"option_b": "Usar uma activity do AWS Step Functions para executar as funções Lambda.",
"option_c": "Usar o Amazon SNS para acionar as funções Lambda.",
"option_d": "Usar uma state machine do AWS Step Functions para orquestrar as funções Lambda.",
"correct_answers": ["D"],
"explanation_detailed": "O AWS Step Functions permite modelar fluxos com etapas sequenciais e paralelas, incluindo retries, condicionais e captura de erros, sendo ideal para orquestrar múltiplas funções Lambda a partir de uma chamada vinda do API Gateway.",
"incorrect_explanations": {
"A": "SQS sozinha não oferece orquestração de passos, apenas fila e consumo de mensagens.",
"B": "Activities são usadas quando há workers externos ao Step Functions; o fluxo aqui pode ser todo Lambda, o que fica melhor modelado em uma state machine Lambda-native.",
"C": "SNS é um sistema de publicação/assinatura e não oferece controle de ordem, paralelismo e dependências entre passos."
}
},
{
"id": "dva-c02-development-111",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma empresa está adicionando saldo pré-pago (gift card) ao seu site de jogos. Usuários podem trocar saldo entre si, o que exige que os registros de ambos sejam atualizados como parte de uma única transação, ou completamente revertidos. Quais opções de banco de dados na AWS oferecem essa capacidade transacional? (Selecione DUAS)",
"option_a": "Amazon DynamoDB com operações feitas com o parâmetro ConsistentRead definido como true.",
"option_b": "Amazon ElastiCache for Memcached com operações dentro de um bloco de transação.",
"option_c": "Amazon Aurora MySQL com operações dentro de um bloco de transação.",
"option_d": "Amazon DynamoDB com leituras e gravações feitas usando operações Transact*.",
"option_e": "Amazon Redshift com operações dentro de um bloco de transação.",
"correct_answers": ["C", "D"],
"explanation_detailed": "Aurora MySQL suporta transações ACID com commit/rollback, permitindo atualizar múltiplos registros de forma atômica. DynamoDB oferece TransactWriteItems e TransactGetItems, que permitem transações entre múltiplos itens e até múltiplas tabelas, mantendo atomicidade.",
"incorrect_explanations": {
"A": "ConsistentRead controla consistência de leitura, não atomicidade entre múltiplas atualizações.",
"B": "Memcached é apenas cache em memória e não oferece transações duráveis com rollback.",
"E": "Redshift é voltado para data warehouse e não é indicado para transações de alta frequência em aplicações OLTP."
}
},
{
"id": "dva-c02-deployment-112",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma função AWS Lambda que gera um novo arquivo a cada execução. Cada novo arquivo deve ser versionado em um repositório AWS CodeCommit no mesmo account. Como o desenvolvedor deve fazer isso?",
"option_a": "Quando a função Lambda iniciar, usar o Git CLI para clonar o repositório, adicionar o arquivo e dar push.",
"option_b": "Depois que o novo arquivo for criado, usar cURL para chamar a API do CodeCommit e enviar o arquivo.",
"option_c": "Usar um SDK da AWS para instanciar um cliente do CodeCommit e invocar o método put_file para adicionar o arquivo ao repositório.",
"option_d": "Fazer upload do novo arquivo para um bucket S3 e usar um AWS Step Functions para adicionar o arquivo ao repositório.",
"correct_answers": ["C"],
"explanation_detailed": "O AWS SDK para CodeCommit oferece a operação PutFile, que permite adicionar ou atualizar arquivos diretamente em um repositório, sem precisar clonar via Git. Isso é mais simples, eficiente e adequado para execução em Lambda.",
"incorrect_explanations": {
"A": "Clonar o repositório dentro da função Lambda é pesado, aumenta o tempo de execução e o tamanho do deployment.",
"B": "Mesmo que cURL pudesse chamar a API, o uso do SDK oficial é mais simples, seguro e idiomático.",
"D": "Introduzir S3 e Step Functions apenas para incluir um arquivo no CodeCommit adiciona complexidade desnecessária."
}
},
{
"id": "dva-c02-security-113",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor deve garantir que as credenciais IAM usadas por uma aplicação em instâncias Amazon EC2 não sejam abusadas ou comprometidas. O que o desenvolvedor deve usar para manter essas credenciais seguras?",
"option_a": "Variáveis de ambiente.",
"option_b": "Arquivo de credenciais da AWS.",
"option_c": "Credenciais de instance profile.",
"option_d": "Parâmetros de linha de comando.",
"correct_answers": ["C"],
"explanation_detailed": "O uso de instance profiles (roles associadas à instância) evita a necessidade de armazenar chaves estáticas em disco, variáveis de ambiente ou código. As credenciais são fornecidas dinamicamente e rotacionadas automaticamente pela AWS.",
"incorrect_explanations": {
"A": "Variáveis de ambiente são facilmente expostas por logs, dumps de erro ou más práticas, e ainda exigem chaves estáticas.",
"B": "Arquivos de credenciais exigem gerenciamento manual e são mais vulneráveis a exposição acidental.",
"D": "Passar credenciais via linha de comando é pouco seguro e nada escalável."
}
},
{
"id": "dva-c02-security-114",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma empresa tem uma aplicação em que a leitura de objetos em um bucket Amazon S3 depende do tipo de usuário: usuário registrado ou convidado. A empresa tem 25.000 usuários e está crescendo. As informações são obtidas de um bucket S3 dependendo do tipo de usuário. Quais abordagens são recomendadas para fornecer acesso aos dois tipos de usuários? (Selecione DUAS)",
"option_a": "Fornecer pares de access key e secret key diferentes no código da aplicação para usuários registrados e convidados, com permissão de leitura aos objetos.",
"option_b": "Usar policies de bucket S3 para restringir leitura a usuários específicos do IAM.",
"option_c": "Usar o Amazon Cognito para fornecer acesso usando roles autenticadas e não autenticadas.",
"option_d": "Criar um novo usuário IAM para cada usuário final e conceder acesso de leitura.",
"option_e": "Usar o serviço AWS IAM e permitir que a aplicação assuma roles diferentes via AWS STS AssumeRole dependendo do tipo de usuário, concedendo acesso de leitura ao S3 pela role assumida.",
"correct_answers": ["C", "E"],
"explanation_detailed": "O uso do Amazon Cognito com identidades autenticadas e não autenticadas é adequado para separar usuários registrados e convidados, escalando para dezenas de milhares de usuários. A aplicação também pode usar STS AssumeRole para obter credenciais temporárias com permissões apropriadas por tipo de usuário.",
"incorrect_explanations": {
"A": "Distribuir access keys fixas em código é uma péssima prática de segurança e não escala.",
"B": "Bucket policies com usuários IAM não escalam bem quando há dezenas de milhares de usuários finais.",
"D": "Criar um usuário IAM por usuário final é inviável e foge das melhores práticas; IAM é para identidades de conta, não para usuários de aplicação."
}
},
{
"id": "dva-c02-security-115",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa tem 25.000 funcionários e está crescendo. A empresa está criando uma aplicação acessível apenas aos funcionários. Um desenvolvedor usa o Amazon S3 para armazenar imagens e o Amazon RDS para dados. A empresa exige que todas as informações de funcionários permaneçam apenas no diretório SAML legado, sem replicar esses dados na AWS. Como o desenvolvedor pode fornecer acesso autorizado para que cada funcionário acesse apenas seus próprios dados na aplicação?",
"option_a": "Usar Amazon VPC, manter todos os recursos dentro da VPC e usar um VPC link para o bucket S3 com policy de bucket.",
"option_b": "Usar Amazon Cognito user pools, federar com o provedor SAML e usar grupos do user pool com uma policy do IAM.",
"option_c": "Usar um Amazon Cognito identity pool, federar com o provedor SAML e usar uma condition key do IAM com o valor da variável cognito-identity.amazonaws.com:sub para conceder acesso aos funcionários.",
"option_d": "Criar uma role IAM única para cada funcionário e fazer com que cada um assuma sua role para acessar a aplicação.",
"correct_answers": ["C"],
"explanation_detailed": "Com um identity pool do Cognito federado a um provedor SAML, cada usuário ganha uma identidade única (sub). Policies do IAM podem usar essa identidade em condition keys para garantir que cada funcionário só acesse seus próprios dados, sem necessidade de espelhar dados de identidade no lado da AWS.",
"incorrect_explanations": {
"A": "Colocar tudo na VPC não resolve o problema de identidade e autorização detalhada por funcionário.",
"B": "User pools exigem gerenciar usuários no Cognito; a exigência é não espelhar informações de funcionários na AWS.",
"D": "Criar uma role por funcionário é pesado de gerenciar e não necessário quando se pode usar identity pools com conditions."
}
},
{
"id": "dva-c02-deployment-116",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa desenvolveu uma nova aplicação serverless usando funções AWS Lambda e vai implantá-la usando a AWS Serverless Application Model (AWS SAM) CLI. Qual passo o desenvolvedor deve completar antes de fazer o deploy?",
"option_a": "Compactar a aplicação em um arquivo .zip e fazer upload diretamente no AWS Lambda.",
"option_b": "Testar a nova função Lambda primeiro com AWS X-Ray.",
"option_c": "Empacotar a aplicação serverless usando o comando SAM package.",
"option_d": "Criar o ambiente da aplicação usando o comando eb create my-env.",
"correct_answers": ["C"],
"explanation_detailed": "Com SAM, o fluxo padrão é usar sam build (quando apropriado) e sam package para empacotar o código em um bucket S3 e reescrever o template com os artefatos; depois, sam deploy efetua a implantação. Empacotar com SAM é o passo necessário antes do deploy.",
"incorrect_explanations": {
"A": "Fazer upload direto no Lambda ignora o fluxo de infraestrutura como código oferecido pelo SAM.",
"B": "Testar com X-Ray pode ser útil, mas não é requisito para o processo de deploy com SAM.",
"D": "eb create é comando do Elastic Beanstalk, não do SAM; não se aplica a essa aplicação serverless."
}
},
{
"id": "dva-c02-security-117",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação precisa criptografar dados gravados no Amazon S3, com as chaves gerenciadas em um data center on-premises, e a criptografia sendo feita pelo S3. Qual tipo de criptografia deve ser usado?",
"option_a": "Criptografia no lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3).",
"option_b": "Criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS (SSE-KMS).",
"option_c": "Criptografia no lado do cliente com customer master keys.",
"option_d": "Criptografia no lado do servidor com chaves fornecidas pelo cliente (SSE-C).",
"correct_answers": ["D"],
"explanation_detailed": "Com SSE-C, o cliente fornece a chave de criptografia a cada requisição, e o S3 realiza a criptografia e descriptografia no lado do servidor. As chaves podem ser gerenciadas on-premises, atendendo ao requisito de gestão local de chaves com criptografia feita pelo S3.",
"incorrect_explanations": {
"A": "SSE-S3 usa chaves gerenciadas pela AWS, não pelo cliente on-premises.",
"B": "SSE-KMS depende de chaves gerenciadas pelo KMS na AWS, não por um HSM ou sistema de chaves local.",
"C": "Criptografia no lado do cliente significa que o S3 apenas armazena dados já criptografados, não “criptografa” em nome da aplicação."
}
},
{
"id": "dva-c02-development-118",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe de desenvolvimento está criando um app mobile que permite aos usuários fazer upload de fotos para um bucket Amazon S3. Espera-se que centenas de milhares de usuários usem o app simultaneamente durante um único evento. Após o upload, um serviço de backend deve analisar e escanear as imagens em busca de conteúdo impróprio. Qual abordagem é a MAIS resiliente e ajuda a suavizar picos temporários de volume para o backend?",
"option_a": "Criar uma função AWS Lambda que verifica periodicamente a pasta de upload no S3 e, ao detectar novas imagens, faz o scan.",
"option_b": "Assim que a imagem for enviada ao S3, publicar o evento em uma fila Amazon SQS e usar a fila como fonte de evento para acionar uma função Lambda que fará o scan.",
"option_c": "Quando o usuário fizer o upload, invocar uma API no Amazon API Gateway que aciona diretamente uma função Lambda para fazer o scan.",
"option_d": "Criar uma state machine no AWS Step Functions que verifica a pasta de upload no S3 e, ao detectar novas imagens, invoca uma função Lambda para fazer o scan.",
"correct_answers": ["B"],
"explanation_detailed": "Usar eventos do S3 para colocar mensagens em uma fila SQS desacopla o upload do processamento e permite absorver picos de tráfego. A Lambda consumindo da SQS escala automaticamente com o volume, reduzindo a pressão imediata sobre o serviço de scan.",
"incorrect_explanations": {
"A": "Polling periódico do bucket S3 é menos eficiente e não lida tão bem com picos súbitos.",
"C": "Acionar o Lambda diretamente via API Gateway acopla a experiência do usuário ao tempo de processamento do scan, tornando mais difícil absorver picos.",
"D": "Step Functions para apenas detectar novas imagens em S3 é excessivamente complexo e ainda não resolve o buffer natural de picos tão bem quanto uma fila."
}
},
{
"id": "dva-c02-development-119",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe de desenvolvimento quer executar workloads de contêiner no Amazon ECS. Cada contêiner de aplicação precisa compartilhar dados com outro contêiner responsável por coletar logs e métricas. O que a equipe deve fazer para atender a esse requisito?",
"option_a": "Criar duas especificações de pod. Colocar a aplicação em um pod e o coletor em outro, e fazer o link entre os pods.",
"option_b": "Criar duas task definitions: uma com o contêiner da aplicação e outra com o contêiner de coleta, e montar um volume compartilhado entre as duas tasks.",
"option_c": "Criar uma única task definition especificando ambos os contêineres e montar um volume compartilhado entre eles.",
"option_d": "Criar uma única especificação de pod com ambos os contêineres e montar um volume persistente para ambos.",
"correct_answers": ["C"],
"explanation_detailed": "No ECS, a forma correta é definir vários contêineres na mesma task definition quando eles precisam compartilhar armazenamento ou ciclo de vida. Um volume pode ser definido na task e montado em ambos os contêineres.",
"incorrect_explanations": {
"A": "Pods são conceitos do Kubernetes; no ECS, o análogo é a task definition com múltiplos contêineres.",
"B": "Tasks distintas não compartilham automaticamente um volume local; seria necessário um backend de armazenamento adicional.",
"D": "Assim como em A, essa terminologia é de Kubernetes. O cenário pergunta explicitamente sobre ECS."
}
},
{
"id": "dva-c02-monitoring-120",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma startup de e-commerce está se preparando para um evento anual de vendas. Conforme o tráfego aumenta, a equipe de desenvolvimento quer ser notificada quando a utilização de CPU da instância Amazon EC2 ultrapassar 80%. Qual solução atende a esse requisito?",
"option_a": "Criar um alarme customizado do Amazon CloudWatch que envie uma notificação para um tópico Amazon SNS quando a CPU ultrapassar 80%.",
"option_b": "Criar um alarme customizado do AWS CloudTrail que envie uma notificação para um tópico Amazon SNS quando a CPU ultrapassar 80%.",
"option_c": "Criar um cron job na instância EC2 que execute o comando describe-instance-information a cada 15 minutos e envie o resultado para um tópico SNS.",
"option_d": "Criar uma função AWS Lambda que consulte logs do AWS CloudTrail para a métrica CPUUtilization a cada 15 minutos e envie notificação via SNS quando passar de 80%.",
"correct_answers": ["A"],
"explanation_detailed": "CloudWatch já monitora a métrica CPUUtilization das instâncias EC2. Criar um alarme que dispara uma notificação SNS quando o valor excede 80% é a abordagem mais simples e nativa.",
"incorrect_explanations": {
"B": "CloudTrail registra chamadas de API, não métricas de CPU.",
"C": "Executar comandos via cron e empurrar manualmente notificações é frágil e desnecessário.",
"D": "Ler logs do CloudTrail para descobrir uso de CPU não faz sentido; CPU é exposta via CloudWatch."
}
},
{
"id": "dva-c02-security-121",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação em execução em instâncias Amazon EC2 abre conexões para um banco de dados SQL Server no Amazon RDS. O desenvolvedor não quer armazenar o usuário e senha no código e deseja rotação automática das credenciais. Qual é a forma MAIS segura de armazenar e acessar essas credenciais?",
"option_a": "Criar uma role IAM com permissões de acesso ao banco e anexá-la às instâncias EC2.",
"option_b": "Usar o AWS Secrets Manager para armazenar as credenciais e recuperá-las conforme necessário.",
"option_c": "Armazenar as credenciais em um arquivo de texto criptografado em um bucket Amazon S3 e baixá-lo no boot via user data.",
"option_d": "Armazenar usuário e senha diretamente no código-fonte, já que o repositório é privado.",
"correct_answers": ["B"],
"explanation_detailed": "O AWS Secrets Manager foi criado para armazenar segredos com rotação automática integrada (inclusive para RDS) e controle de acesso via IAM. A aplicação pode recuperar as credenciais sob demanda usando credenciais temporárias da role da instância.",
"incorrect_explanations": {
"A": "Roles IAM não substituem credenciais específicas do banco; é preciso ainda assim lidar com usuário/senha ou integração nativa de IAM com alguns bancos específicos.",
"C": "Embora seja possível, isso adiciona esforço manual de rotação e aumenta o risco operacional.",
"D": "Mesmo em repositório privado, colocar segredos em código é uma má prática séria de segurança."
}
},
{
"id": "dva-c02-deployment-122",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está atualizando uma aplicação implantada no AWS Elastic Beanstalk. A nova versão é incompatível com a anterior. Para que a atualização seja bem-sucedida, é necessário fazer um cutover completo para a nova versão em todas as instâncias ao mesmo tempo, mantendo a capacidade de rollback em caso de falha, com o mínimo de downtime. Como fazer isso?",
"option_a": "Usar a política de deployment All at once para atualizar todas as instâncias simultaneamente.",
"option_b": "Executar um deployment Rolling with additional batch.",
"option_c": "Implantar a nova versão em um novo ambiente Elastic Beanstalk e fazer swap das URLs dos ambientes.",
"option_d": "Executar um deployment Rolling.",
"correct_answers": ["C"],
"explanation_detailed": "Criar um novo ambiente EB com a nova versão e, quando estiver saudável, fazer swap das URLs implementa um padrão blue/green. Isso permite cutover rápido com rollback simples (swap de volta), minimizando downtime.",
"incorrect_explanations": {
"A": "All at once atualiza todas as instâncias do mesmo ambiente, causando downtime e tornando o rollback mais complicado.",
"B": "Rolling with additional batch mantém duas versões em paralelo por um tempo, o que pode ser problemático se forem incompatíveis.",
"D": "Rolling também mantém versões em paralelo e pode causar erros em sessões de usuários que batem em instâncias com versões diferentes."
}
},
{
"id": "dva-c02-security-123",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação web que precisa compartilhar documentos confidenciais com usuários finais. Os documentos estão em um bucket privado do Amazon S3. A aplicação deve permitir que apenas usuários autenticados façam download de documentos específicos, por no máximo 15 minutos. Como atender a esses requisitos?",
"option_a": "Copiar os documentos para um bucket S3 separado com lifecycle para deletar após 15 minutos.",
"option_b": "Criar URLs pré-assinadas (pre-signed) do S3 usando o AWS SDK com tempo de expiração de 15 minutos.",
"option_c": "Usar criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS (SSE-KMS) e fazer download via HTTPS.",
"option_d": "Modificar a bucket policy para permitir downloads apenas a usuários específicos e reverter a mudança após 15 minutos.",
"correct_answers": ["B"],
"explanation_detailed": "URLs pré-assinadas permitem conceder acesso temporário a objetos privados, com um TTL definido pelo desenvolvedor. A aplicação pode gerar a URL após autenticar o usuário, garantindo acesso apenas ao documento correto e pelo tempo desejado.",
"incorrect_explanations": {
"A": "Criar e deletar cópias em buckets separados é complexo, sujeito a falhas e não necessário.",
"C": "SSE-KMS e HTTPS cuidam da confidencialidade, mas não limitam a duração do acesso a um objeto privado.",
"D": "Alterar bucket policies dinamicamente é arriscado, difícil de sincronizar por objeto e não escalável."
}
},
{
"id": "dva-c02-monitoring-124",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está desenvolvendo um relatório orquestrado por AWS Step Functions. O Amazon CloudWatch mostra erros em um estado de task. Para depuração, o input original do estado precisa ser incluído junto com a mensagem de erro na saída do estado. Qual prática de codificação preserva tanto o input original quanto o erro?",
"option_a": "Usar ResultPath em um bloco Catch para incluir o erro junto com o input original.",
"option_b": "Usar InputPath em um bloco Catch e definir o valor como null.",
"option_c": "Usar ErrorEquals em um bloco Retry para incluir o erro junto com o input original.",
"option_d": "Usar OutputPath em um bloco Retry e definir o valor como $.",
"correct_answers": ["A"],
"explanation_detailed": "Um bloco Catch em Step Functions permite redirecionar a execução em caso de erro. Usando ResultPath, é possível anexar o objeto de erro ao payload existente, preservando o input original e adicionando as informações de exceção em um campo específico.",
"incorrect_explanations": {
"B": "Definir InputPath como null descarta o input em vez de preservá-lo.",
"C": "ErrorEquals em Retry apenas controla quais erros devem ser feitos retry; não combina input e erro.",
"D": "OutputPath em Retry filtra a saída de um estado bem-sucedido, não é o lugar certo para combinar input e erro."
}
},
{
"id": "dva-c02-monitoring-125",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor recebe uma mensagem de erro HTTP 400: ThrottlingException de forma intermitente ao chamar a API do Amazon EC2 via boto3. Quando a chamada falha, nenhum dado é retornado. Qual é a melhor prática que deve ser aplicada primeiro para tratar esse problema?",
"option_a": "Abrir um chamado no suporte da AWS para solicitar aumento de limite.",
"option_b": "Implementar retries com backoff exponencial nas chamadas que falharem.",
"option_c": "Usar a AWS CLI para obter as métricas em vez da aplicação.",
"option_d": "Remover as chamadas à API da aplicação para evitar o erro.",
"correct_answers": ["B"],
"explanation_detailed": "ThrottlingException indica que o cliente está excedendo o limite de taxa de chamadas da API. A recomendação padrão da AWS é implementar retries com backoff exponencial, reduzindo a pressão nos endpoints e aumentando a chance de sucesso nas tentativas subsequentes.",
"incorrect_explanations": {
"A": "Pedir aumento de limite pode ajudar em alguns casos, mas a primeira ação recomendada é tratar o throttling no cliente com backoff.",
"C": "Trocar para a CLI não resolve o problema de limite de taxa; a CLI também está sujeita a throttling.",
"D": "Remover chamadas da aplicação não é uma solução prática; é preciso lidar corretamente com os limites do serviço."
}
},

{
"id": "dva-c02-deployment-126",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Dado um template AWS CloudFormation que cria um novo bucket Amazon S3, qual é a forma MAIS eficiente de referenciar esse bucket a partir de outro template CloudFormation?",
"option_a": "Adicionar uma declaração Export na seção Outputs do template original e usar ImportValue em outros templates.",
"option_b": "Adicionar Exported: true ao recurso ContentBucket no template original e usar ImportResource em outros templates.",
"option_c": "Criar um recurso customizado CloudFormation que busque o nome do bucket a partir do recurso ContentBucket do primeiro stack.",
"option_d": "Usar Fn::Include para incluir o template existente em outros templates e referenciar o recurso ContentBucket diretamente.",
"correct_answers": ["A"],
"explanation_detailed": "A forma recomendada de compartilhar recursos entre stacks CloudFormation é exportar valores na seção Outputs de um stack e usar Fn::ImportValue em outros templates. Isso permite compor stacks de forma desacoplada e reutilizável.",
"incorrect_explanations": {
"B": "Exported: true não é um campo válido em recursos CloudFormation. A exportação é feita via Outputs.",
"C": "Um recurso customizado seria mais complexo sem necessidade, já que Export/ImportValue já resolvem o problema.",
"D": "Fn::Include não é usado para referenciar recursos já criados em outro stack, e sim para reutilizar trechos de template."
}
},
{
"id": "dva-c02-deployment-127",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está usando o AWS CodeDeploy para fazer deploy de uma aplicação em instâncias Amazon EC2. Ele quer alterar as permissões de um arquivo específico durante o deployment. Em qual evento de ciclo de vida isso deve ser feito?",
"option_a": "AfterInstall.",
"option_b": "DownloadBundle.",
"option_c": "BeforeInstall.",
"option_d": "ValidateService.",
"correct_answers": ["C"],
"explanation_detailed": "Alterações de permissões de arquivos normalmente são feitas em BeforeInstall, antes de os arquivos da nova versão serem colocados no local final. Esse hook é o ponto certo para preparar o sistema de arquivos para a instalação.",
"incorrect_explanations": {
"A": "AfterInstall ocorre depois da cópia dos arquivos, e costuma ser usado para passos pós-instalação, não para preparar permissões.",
"B": "DownloadBundle apenas baixa o artifact, não é o local correto para manipular arquivos já instalados.",
"D": "ValidateService é para checagens de saúde, testes e validações finais, não para alterar permissões."
}
},
{
"id": "dva-c02-development-128",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está usando o Amazon DynamoDB para armazenar dados de aplicação e quer reduzir ainda mais a latência de leitura e escrita, melhorando a performance. Qual recurso do DynamoDB deve ser usado?",
"option_a": "Amazon DynamoDB Streams.",
"option_b": "Amazon DynamoDB Accelerator.",
"option_c": "Amazon DynamoDB global tables.",
"option_d": "Transações do Amazon DynamoDB.",
"correct_answers": ["B"],
"explanation_detailed": "O DynamoDB Accelerator (DAX) é um cache in-memory totalmente gerenciado e otimizado para DynamoDB. Ele reduz significativamente a latência de leitura, muitas vezes para microssegundos, sem exigir mudanças complexas na aplicação.",
"incorrect_explanations": {
"A": "Streams servem para captura de mudanças em tempo real, não para reduzir diretamente latência de leitura/escrita.",
"C": "Global tables resolvem replicação multi-região, não latência local de leitura em um único Region.",
"D": "Transações garantem atomicidade e consistência, mas não têm foco em redução de latência."
}
},
{
"id": "dva-c02-deployment-129",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor está criando um script para automatizar o deploy de uma aplicação serverless usando um template AWS Serverless Application Model (AWS SAM). Quais comandos ele deve usar? (Selecione DUAS)",
"option_a": "Executar aws cloudformation package para criar o pacote de deploy e aws cloudformation deploy em seguida.",
"option_b": "Executar sam package para criar o pacote de deploy e sam deploy em seguida.",
"option_c": "Executar aws s3 cp para enviar o template SAM para um bucket S3 e depois aws lambda update-function-code.",
"option_d": "Criar um pacote ZIP localmente e usar aws serverlessrepo create-application para criar a aplicação.",
"option_e": "Criar um pacote ZIP e subir para um bucket S3 e depois usar aws cloudformation create-stack para criar a aplicação.",
"correct_answers": ["A", "B"],
"explanation_detailed": "Tanto a combinação aws cloudformation package/deploy quanto sam package/deploy são padrões suportados para empacotar e implantar aplicações serverless descritas em templates SAM. O SAM CLI é um wrapper conveniente sobre CloudFormation, mas ambos os fluxos são válidos.",
"incorrect_explanations": {
"C": "Atualizar a função Lambda diretamente ignora a infraestrutura como código descrita no template SAM.",
"D": "O Serverless Application Repository é um caso de uso diferente; não é o caminho padrão para deploy do seu próprio template SAM.",
"E": "Criar o stack diretamente com create-stack exige que você mesmo faça o empacotamento dos artefatos e ajustado o template, o que não é o fluxo descrito no enunciado."
}
},
{
"id": "dva-c02-security-130",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma equipe está desenvolvendo um app mobile que exige autenticação multi-fator (MFA). Quais passos devem ser tomados para atender a esse requisito com o mínimo de código extra? (Selecione DUAS)",
"option_a": "Usar o Amazon Cognito para criar um user pool e criar usuários no user pool.",
"option_b": "Enviar códigos de MFA por SMS diretamente a partir do app usando o Amazon SNS Publish.",
"option_c": "Ativar MFA para o user pool do Amazon Cognito.",
"option_d": "Usar o AWS IAM para criar usuários IAM para cada usuário do app.",
"option_e": "Ativar MFA para os usuários criados no AWS IAM.",
"correct_answers": ["A", "C"],
"explanation_detailed": "User pools do Cognito foram feitos para autenticação de usuários de aplicações, incluindo suporte nativo a MFA via SMS ou TOTP. Criar usuários no user pool e ativar MFA ali reduz a quantidade de código customizado necessária.",
"incorrect_explanations": {
"B": "Gerar e enviar códigos de MFA manualmente pelo SNS aumenta muito a complexidade e não é necessário quando o Cognito já provê isso.",
"D": "IAM não é recomendado para gerenciar identidades de usuários finais de aplicações.",
"E": "Mesmo que fosse possível, usar IAM + MFA para cada usuário do app seria um pesadelo de gestão."
}
},
{
"id": "dva-c02-security-131",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Dois microsserviços em contêiner estão hospedados no Amazon ECS em instâncias EC2. O primeiro lê de um banco Amazon Aurora, e o segundo lê de uma tabela Amazon DynamoDB. Como conceder o MÍNIMO privilégio necessário a cada microserviço?",
"option_a": "Definir ECS_ENABLE_TASK_IAM_ROLE como false na inicialização do agente ECS e rodar o primeiro microserviço com uma task role com acesso somente leitura ao Aurora e o segundo com task role com acesso somente leitura ao DynamoDB.",
"option_b": "Definir ECS_ENABLE_TASK_IAM_ROLE como false e dar à instance profile role acesso somente leitura ao Aurora e ao DynamoDB.",
"option_c": "Definir ECS_ENABLE_TASK_IAM_ROLE como true na inicialização do agente ECS e rodar o primeiro microserviço com uma task role com acesso somente leitura ao Aurora e o segundo com task role com acesso somente leitura ao DynamoDB.",
"option_d": "Definir ECS_ENABLE_TASK_IAM_ROLE como true e dar à instance profile role acesso somente leitura ao Aurora e ao DynamoDB.",
"correct_answers": ["C"],
"explanation_detailed": "Com ECS_ENABLE_TASK_IAM_ROLE=true, cada tarefa ECS pode ter sua própria IAM role (task role). Isso permite conceder permissões mínimas por tarefa, isolando o acesso do microsserviço do Aurora do microsserviço do DynamoDB.",
"incorrect_explanations": {
"A": "Com a flag em false, as task roles não serão usadas; as permissões viriam da instance profile role.",
"B": "Dar permissões amplas à instance profile role quebra o princípio de menor privilégio.",
"D": "Mesmo com a flag em true, se a instance profile role tiver todas as permissões e as tasks não tiverem roles específicas, o isolamento não é alcançado."
}
},
{
"id": "dva-c02-monitoring-132",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor escreveu uma função AWS Lambda em Java e quer isolar um gargalo de performance no código. Que abordagem deve ser usada?",
"option_a": "Usar a API do Amazon CloudWatch para gravar timestamps em uma métrica customizada e analisá-la no console do CloudWatch.",
"option_b": "Usar a API do AWS X-Ray para gravar traces em pontos estratégicos do código e analisar os dados no console do CloudWatch.",
"option_c": "Usar a API do AWS X-Ray para gravar traces em pontos estratégicos do código e analisar os dados no console do X-Ray.",
"option_d": "Usar a API do Amazon CloudWatch para gravar timestamps em uma métrica customizada e analisar no console do X-Ray.",
"correct_answers": ["C"],
"explanation_detailed": "O X-Ray foi feito para rastrear chamadas e medir latência em componentes individuais. Instrumentar o código com a SDK do X-Ray e analisar os traces no console do X-Ray é a forma mais eficaz de localizar gargalos na execução de uma função Lambda em Java.",
"incorrect_explanations": {
"A": "Métricas customizadas de CloudWatch ajudam, mas não fornecem o mesmo nível de detalhe de traces distribuídos.",
"B": "Os traces do X-Ray são visualizados no console do próprio X-Ray, não no console do CloudWatch.",
"D": "CloudWatch e X-Ray têm finalidades diferentes; você não analisa métricas de CloudWatch no console do X-Ray."
}

},
{
"id": "dva-c02-development-133",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor adicionou uma nova funcionalidade em uma aplicação que consome mensagens de uma fila Amazon SQS. Após o deploy, os custos do SQS aumentaram bastante. O CloudWatch mostra que, em média, apenas uma mensagem por minuto é publicada na fila. Como reduzir os custos do SQS?",
"option_a": "Aumentar o timeout de polling da fila SQS.",
"option_b": "Reduzir o tamanho da fila SQS para se ajustar à baixa demanda.",
"option_c": "Configurar entrega push via Amazon SNS em vez de polling na fila SQS.",
"option_d": "Usar uma fila FIFO em vez de uma fila padrão.",
"correct_answers": ["A"],
"explanation_detailed": "Com poucas mensagens, fazer polling frequente gera muitas requisições vazias e aumenta o custo. Habilitar long polling (aumentando WaitTimeSeconds) reduz o número de chamadas de ReceiveMessage, diminuindo custos.",
"incorrect_explanations": {
"B": "Não existe “tamanho” configurável da fila que impacte custo; o custo é por requisição e por payload transferido.",
"C": "Migrar para SNS não resolve o padrão de consumo nem o problema de custo de polling.",
"D": "Filas FIFO têm custo maior por operação e não atacam o problema central."
}
},
{
"id": "dva-c02-monitoring-134",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação usa um backend com Amazon API Gateway, AWS Lambda e Amazon DynamoDB. Durante testes, o desenvolvedor observa alta latência nas requisições. Como avaliar a latência de ponta a ponta e identificar gargalos?",
"option_a": "Ativar o AWS CloudTrail e usar os logs para mapear cada latência e gargalo.",
"option_b": "Ativar e configurar o AWS X-Ray no API Gateway e na função Lambda e usar o X-Ray para rastrear e analisar as requisições.",
"option_c": "Ativar o Amazon CloudWatch Logs apenas para a função Lambda e analisar os logs de execução.",
"option_d": "Ativar o VPC Flow Logs e analisar o tráfego de rede dentro da VPC.",
"correct_answers": ["B"],
"explanation_detailed": "O X-Ray integra com API Gateway, Lambda e DynamoDB, fornecendo um trace de ponta a ponta da requisição. Com isso, é possível visualizar exatamente onde está a maior parcela de latência.",
"incorrect_explanations": {
"A": "CloudTrail foca em auditoria de chamadas de API, não em análise detalhada de latência de cada componente.",
"C": "Logs da Lambda ajudam, mas não oferecem visão completa de API Gateway + Lambda + DynamoDB.",
"D": "VPC Flow Logs mostram tráfego de rede, não o tempo gasto em cada serviço gerenciado."
}
},
{
"id": "dva-c02-security-135",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma role IAM anexada a uma instância Amazon EC2 nega explicitamente todas as ações do Amazon S3. Porém, o arquivo de credenciais na instância contém um access key e secret key de um usuário IAM com acesso administrativo total. Considerando esses modos múltiplos de acesso, o que é correto?",
"option_a": "A instância EC2 só conseguirá listar os buckets S3.",
"option_b": "A instância EC2 só conseguirá listar o conteúdo de um bucket S3 por vez.",
"option_c": "A instância EC2 conseguirá executar todas as ações em qualquer bucket S3.",
"option_d": "A instância EC2 não conseguirá executar nenhuma ação S3 em nenhum bucket.",
"correct_answers": ["C"],
"explanation_detailed": "Quando a aplicação usa as chaves do usuário IAM, o principal efetivo é esse usuário, não a role da instância. A policy de deny anexada à role da instância não se aplica ao usuário IAM, então o acesso administrativo total do usuário prevalece.",
"incorrect_explanations": {
"A": "Não existe um motivo para o acesso ficar restrito apenas a listar buckets; o usuário tem permissões administrativas.",
"B": "Não há limitação artificial a um bucket por vez neste cenário.",
"D": "O deny da role da instância não impede o uso de credenciais de outro principal (o usuário IAM)."
}
},
{
"id": "dva-c02-deployment-136",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe usa AWS Elastic Beanstalk e configurou uma política de lifecycle para limitar o número de versões a 25. Mesmo assim, o bundle de código está sendo deletado do bucket S3 de origem. O que o desenvolvedor deve ajustar nas configurações de lifecycle de versões para reter o código no S3?",
"option_a": "Alterar “Set the application versions limit by total count” para zero.",
"option_b": "Desabilitar a configuração de Lifecycle policy.",
"option_c": "Alterar “Set the application version limit by age” para zero.",
"option_d": "Definir Retention como “Retain source bundle in S3”.",
"correct_answers": ["D"],
"explanation_detailed": "No lifecycle de versões do Elastic Beanstalk é possível controlar se o bundle de origem deve ser deletado do S3 ou não. Ajustar a opção para “Retain source bundle in S3” garante que o código permaneça no bucket, mesmo que versões antigas sejam removidas da lista do Beanstalk.",
"incorrect_explanations": {
"A": "Definir limite por contagem como zero causaria comportamento indesejado, não garante retenção do bundle.",
"B": "Desabilitar o lifecycle pode causar acúmulo de versões, mas não explica o comportamento atual nem garante a retenção controlada.",
"C": "O limite por idade não controla diretamente se o bundle de origem é apagado."
}
},
{
"id": "dva-c02-development-137",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação de marketplace armazena preços em uma tabela Amazon DynamoDB com o Amazon ElastiCache na frente. Os preços mudam com frequência. Vendedores reclamam que, após atualizar o preço, o valor exibido na listagem não muda. Qual é a causa MAIS provável?",
"option_a": "O cache não está sendo invalidado quando o preço é alterado.",
"option_b": "O preço está sendo lido usando um cluster ElastiCache de write-through.",
"option_c": "A tabela DynamoDB foi provisionada com pouca capacidade de leitura.",
"option_d": "A tabela DynamoDB foi provisionada com pouca capacidade de escrita.",
"correct_answers": ["A"],
"explanation_detailed": "Quando existe cache na frente do banco, é necessário invalidar ou atualizar o cache depois de uma mudança crítica, como preço. Se isso não é feito, a aplicação continua servindo valores antigos a partir do ElastiCache.",
"incorrect_explanations": {
"B": "Um cache write-through atualizaria o cache na escrita, reduzindo esse problema em vez de causá-lo.",
"C": "Capacidade de leitura insuficiente pode gerar throttling, mas não explica preços desatualizados específicos.",
"D": "Capacidade de escrita insuficiente causaria erros ou throttling, não necessariamente inconsistência persistente em cache."
}
},
{
"id": "dva-c02-security-138",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor recebeu uma URL HTTPS para clonar um repositório AWS CodeCommit. O que precisa ser configurado antes de clonar esse repositório via HTTPS?",
"option_a": "Usar o AWS KMS para criar chaves pública e privada para uso com o CodeCommit.",
"option_b": "Configurar o Git credential helper para usar um perfil de credenciais da AWS e habilitar o helper para enviar o caminho dos repositórios.",
"option_c": "Usar o AWS Certificate Manager para provisionar certificados SSL/TLS públicos e privados.",
"option_d": "Gerar chaves de criptografia usando o AWS CloudHSM e exportar para uso no CodeCommit.",
"correct_answers": ["B"],
"explanation_detailed": "Para acesso HTTPS ao CodeCommit, é comum usar o Git credential helper da AWS, que lê credenciais de um perfil IAM configurado localmente. Isso simplifica autenticação e evita manipular chaves manualmente.",
"incorrect_explanations": {
"A": "KMS não é usado para autenticação Git no CodeCommit.",
"C": "Certificates em ACM são para endpoints TLS de serviços, não para autenticação Git.",
"D": "CloudHSM é voltado para operações criptográficas avançadas, não para login no CodeCommit."
}
},
{
"id": "dva-c02-monitoring-139",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "O que é necessário para rastrear aplicações baseadas em AWS Lambda com o AWS X-Ray?",
"option_a": "Enviar logs da aplicação para um bucket S3 e acionar uma função Lambda a partir do bucket para enviar dados ao X-Ray.",
"option_b": "Acionar uma função Lambda a partir de logs do CloudWatch para enviar dados de trace ao X-Ray.",
"option_c": "Usar uma role de execução do IAM para dar permissões à função Lambda e ativar o tracing.",
"option_d": "Adicionar código do daemon do X-Ray dentro da função Lambda para configurar o trace.",
"correct_answers": ["C"],
"explanation_detailed": "Para Lambda, você apenas habilita o active tracing na configuração da função e garante que a role de execução tenha permissões xray:PutTraceSegments e xray:PutTelemetryRecords. O runtime do Lambda cuida da integração com o X-Ray.",
"incorrect_explanations": {
"A": "Não é necessário usar S3 como intermediário para enviar dados de trace.",
"B": "Logs do CloudWatch não são o canal recomendado para alimentar o X-Ray.",
"D": "O daemon do X-Ray não roda dentro da função Lambda; a integração é gerenciada pelo serviço."
}
},
{
"id": "dva-c02-security-140",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe está criando uma aplicação em EC2 que usa o Amazon DynamoDB como camada de armazenamento. Todos os desenvolvedores estão em um mesmo grupo IAM e já podem lançar instâncias EC2. Eles agora precisam lançar instâncias com uma instance role que permita acesso ao DynamoDB. Quais mudanças de IAM são necessárias ao criar essa instance role?",
"option_a": "Criar uma policy anexada à role permitindo acesso ao DynamoDB, adicionar uma trust policy permitindo que o DynamoDB assuma a role e anexar ao grupo de desenvolvimento uma policy com iam:GetRole e iam:PassRole.",
"option_b": "Criar uma policy anexada à role permitindo acesso ao DynamoDB, adicionar uma trust policy permitindo que o Amazon EC2 assuma a role e anexar ao grupo de desenvolvimento uma policy permitindo iam:PassRole para essa role.",
"option_c": "Criar uma policy anexada à role permitindo acesso ao Amazon EC2, adicionar uma trust policy permitindo que o DynamoDB assuma a role e anexar ao grupo de desenvolvimento uma policy permitindo iam:PassRole.",
"option_d": "Criar uma policy anexada à role permitindo acesso ao DynamoDB, adicionar uma trust policy permitindo que o Amazon EC2 assuma a role e anexar ao grupo de desenvolvimento uma policy permitindo iam:GetRole para essa role.",
"correct_answers": ["B"],
"explanation_detailed": "A role de instância deve confiar no serviço EC2 (trust policy) e ter uma policy de permissões para acessar o DynamoDB. Para que os desenvolvedores possam associar essa role ao lançar instâncias, o grupo deles precisa ter permissão iam:PassRole para essa role.",
"incorrect_explanations": {
"A": "A trust policy deve permitir que o EC2 assuma a role, não o DynamoDB.",
"C": "A policy anexada à role deve conceder acesso ao DynamoDB, não ao EC2.",
"D": "iam:GetRole não é suficiente; é preciso iam:PassRole para anexar a role à instância."
}
},
{
"id": "dva-c02-development-141",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor converteu um programa existente em uma função AWS Lambda no console. O programa roda corretamente localmente, mas mostra o erro “Unable to import module” ao ser testado no console do Lambda. Como corrigir esse problema?",
"option_a": "Instalar o módulo ausente e garantir que ele esteja no diretório atual. Criar um ZIP com todos os arquivos sob o diretório atual e fazer upload para o Lambda.",
"option_b": "Instalar o módulo ausente em um diretório lib, criar um ZIP com os arquivos do diretório lib e fazer upload desse ZIP como arquivo de dependência separado.",
"option_c": "No código da função, chamar um comando Linux para instalar os módulos ausentes em /usr/lib.",
"option_d": "No console do Lambda, criar uma variável de ambiente LB_LIBRARY_PATH apontando para o diretório de libraries.",
"correct_answers": ["A"],
"explanation_detailed": "Para o Lambda encontrar módulos externos, eles devem estar incluídos no pacote de deploy, no mesmo diretório ou em subdiretórios importáveis. Empacotar o código + dependências em um único ZIP e enviá-lo resolve o erro de importação.",
"incorrect_explanations": {
"B": "Apenas subir o diretório lib separado não garante que o Lambda vá carregar esse ZIP como parte do código.",
"C": "Instalar pacotes em tempo de execução é frágil, lento e não é a abordagem recomendada.",
"D": "Definir LB_LIBRARY_PATH não resolve problemas de import de módulos de linguagem (como Python/Node), é para libs nativas."
}
},
{
"id": "dva-c02-security-142",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um front-end web usa Amazon Cognito user pools para autenticação. Um desenvolvedor está integrando o Amazon DynamoDB via AWS SDK for JavaScript e precisa chamar a API de forma segura, sem expor access keys ou secret keys no navegador. Como fazer isso?",
"option_a": "Configurar Amazon Cognito identity pools e trocar o JSON Web Token (JWT) por credenciais temporárias.",
"option_b": "Rodar o front-end dentro de uma instância EC2 com instance profile configurado.",
"option_c": "Colocar as credenciais hardcoded no código hospedado em um bucket S3 com criptografia no lado do servidor.",
"option_d": "Usar diretamente os JSON Web Tokens (JWTs) do user pool para acessar as APIs do DynamoDB.",
"correct_answers": ["A"],
"explanation_detailed": "O fluxo recomendado é: autenticar o usuário no user pool, obter o JWT e depois usar um identity pool para trocar esse token por credenciais temporárias do STS, que o front-end usa para acessar DynamoDB com permissões limitadas.",
"incorrect_explanations": {
"B": "Rodar o front-end dentro de EC2 é completamente fora do padrão de aplicações web modernas e não resolve o problema de credenciais no browser.",
"C": "Hardcode de credenciais é um anti-padrão de segurança, independentemente de S3 estar criptografado.",
"D": "JWTs de user pool não são aceitos diretamente como credenciais para as APIs do DynamoDB."
}
},
{
"id": "dva-c02-deployment-143",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa gerenciar infraestrutura como código, conseguir implantar múltiplas cópias idênticas do ambiente, testar mudanças e reverter versões anteriores. Qual abordagem atende a esses requisitos?",
"option_a": "Usar relatórios de alocação de custos e AWS OpsWorks.",
"option_b": "Usar métricas e alarmes do CloudWatch com tags de recursos.",
"option_c": "Usar AWS Elastic Beanstalk com AWS CodeCommit.",
"option_d": "Usar AWS CloudFormation junto com AWS CodeCommit.",
"correct_answers": ["D"],
"explanation_detailed": "CloudFormation descreve a infraestrutura em templates versionáveis, enquanto o CodeCommit oferece controle de versão do código e dos templates. Juntos, permitem múltiplas cópias, staging e rollbacks de forma controlada.",
"incorrect_explanations": {
"A": "OpsWorks é um serviço de orquestração, mas não substitui CloudFormation para infra como código em geral.",
"B": "CloudWatch + tags não versionam infraestrutura, apenas monitoram.",
"C": "Elastic Beanstalk facilita deploy de aplicações, mas não cobre todo o espectro de infra como código."
}
},
{
"id": "dva-c02-development-144",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa passar variáveis de ambiente para um contêiner em uma aplicação rodando no AWS Fargate usando Amazon ECS. Onde essas variáveis devem ser definidas?",
"option_a": "Em um array under environment dentro da definição do serviço.",
"option_b": "Em um array under environment dentro da task definition.",
"option_c": "Em um array under entryPoint dentro da task definition.",
"option_d": "Em um array under entryPoint dentro da definição do serviço.",
"correct_answers": ["B"],
"explanation_detailed": "No ECS, variáveis de ambiente são configuradas na task definition, dentro da definição do contêiner, usando o campo environment. Essa definição é então usada tanto para Fargate quanto para EC2.",
"incorrect_explanations": {
"A": "O serviço referencia uma task definition; as variáveis de ambiente pertencem à task, não ao serviço.",
"C": "entryPoint define o comando de entrada do contêiner, não as variáveis de ambiente.",
"D": "Da mesma forma, entryPoint no serviço não é o local correto (e nem existe dessa forma)."
}
},
{
"id": "dva-c02-development-145",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Instâncias EC2 recebem dados de milhões de usuários via API e fazem upload de objetos em um bucket S3. Cada objeto possui atributos como Customer ID e TS-Server (timestamp + ID do servidor). Um desenvolvedor quer encontrar todos os objetos de um usuário em um intervalo de tempo específico. Após criar um evento de criação de objeto S3, como atender a esse requisito?",
"option_a": "Acionar uma função Lambda para criar um registro no Amazon DynamoDB para cada objeto, com Customer ID como chave de partição e Server ID como chave de ordenação. Recuperar usando Customer ID e Server ID.",
"option_b": "Acionar uma função Lambda para criar um registro no Amazon Redshift para cada objeto, com Customer ID como chave de partição e TS-Server como chave de ordenação. Recuperar usando Customer ID e TS-Server.",
"option_c": "Acionar uma função Lambda para criar um registro no Amazon DynamoDB para cada objeto, com Customer ID como chave de partição e TS-Server como chave de ordenação. Recuperar usando Customer ID e TS-Server.",
"option_d": "Acionar uma função Lambda para criar um registro no Amazon Redshift para cada objeto, com Customer ID como chave de partição e Server ID como chave de ordenação. Recuperar usando Customer ID e Server ID.",
"correct_answers": ["C"],
"explanation_detailed": "Usar DynamoDB com Customer ID como partition key e TS-Server como sort key permite consultar facilmente por usuário e por intervalo de tempo, usando queries com condições na sort key.",
"incorrect_explanations": {
"A": "Server ID como sort key não ajuda a filtrar por intervalo de tempo.",
"B": "Redshift é orientado a analytics em larga escala, não a consultas OLTP simples por usuário/tempo.",
"D": "Novamente, usar Server ID como sort key não resolve o filtro por intervalo temporal."
}
},
{
"id": "dva-c02-development-146",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está migrando um banco NoSQL on-premises para o Amazon DynamoDB. Eles querem otimizar consultas frequentes, reduzir latência de leitura e planejar queries recorrentes sobre certos atributos-chave. Qual solução ajuda a atingir esses objetivos?",
"option_a": "Criar global secondary indexes nos atributos frequentemente consultados e incluir os atributos necessários no índice.",
"option_b": "Criar local secondary indexes nos atributos frequentemente consultados e deixar que o DynamoDB busque os atributos na tabela.",
"option_c": "Criar global tables do DynamoDB para acelerar respostas e usar scan para buscar os dados.",
"option_d": "Criar uma política de Auto Scaling para a tabela DynamoDB.",
"correct_answers": ["A"],
"explanation_detailed": "Global secondary indexes (GSIs) permitem projetar novos padrões de acesso com partition e sort keys diferentes da tabela principal. Incluir atributos projetados no índice reduz a necessidade de leituras adicionais na tabela, melhorando latência.",
"incorrect_explanations": {
"B": "LSIs compartilham a mesma partition key da tabela base, o que limita o desenho do acesso.",
"C": "Global tables atacam replicação multi-região, e não substituem o uso de índices; ainda mais, usar scan é caro e lento.",
"D": "Auto Scaling ajuda em capacidade, mas não em modelagem de chave para queries frequentes."
}
},
{
"id": "dva-c02-development-147",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação que processa dados entregues em um bucket Amazon S3 aproximadamente 10 vezes por dia, e espera que o processamento de cada entrega leve menos de 1 minuto. Qual é a forma de deploy e invocação com MENOR custo e baixa latência?",
"option_a": "Implantar a aplicação como uma função AWS Lambda e invocá-la via alarme do CloudWatch disparado por upload no S3.",
"option_b": "Implantar a aplicação como uma função AWS Lambda e invocá-la por notificação de evento do S3.",
"option_c": "Implantar a aplicação como uma função AWS Lambda e invocá-la por evento agendado do CloudWatch.",
"option_d": "Implantar a aplicação em uma instância EC2 que fica fazendo polling do bucket S3 em busca de novos objetos.",
"correct_answers": ["B"],
"explanation_detailed": "Usar eventos nativos do S3 para acionar diretamente uma função Lambda combina custo baixo (paga-se apenas por invocação/execução) e baixa latência, já que a função roda assim que o objeto é criado.",
"incorrect_explanations": {
"A": "Não há necessidade de usar alarme do CloudWatch como camada intermediária; o S3 já integra diretamente com o Lambda.",
"C": "Evento agendado pode adicionar atraso desnecessário e polling inútil quando não há arquivos.",
"D": "Manter EC2 ligado só para fazer polling é mais caro e menos eficiente."
}
},
{
"id": "dva-c02-security-148",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está usando o Amazon API Gateway para gerenciar uma API pública. O CISO exige que apenas usuários de uma conta AWS de testes específica consigam usar a API. Qual é a forma MAIS segura de restringir o acesso da API a usuários dessa conta?",
"option_a": "Certificados SSL do lado do cliente para autenticação.",
"option_b": "Policies de recurso do API Gateway.",
"option_c": "Cross-origin resource sharing (CORS).",
"option_d": "Usage plans.",
"correct_answers": ["B"],
"explanation_detailed": "Resource policies do API Gateway permitem restringir quem pode invocar a API com base em IDs de conta, VPCs, endereços IP e outros critérios, o que é ideal para limitar o uso a uma conta AWS específica.",
"incorrect_explanations": {
"A": "Certificados de cliente ajudam em autenticação mútua, mas não são a ferramenta principal para restringir por conta AWS.",
"C": "CORS trata de permissões de navegador entre domínios, não de quais contas AWS podem chamar a API.",
"D": "Usage plans limitam taxa/quotas por API key, mas não amarram acesso a uma conta AWS específica."
}
},
{
"id": "dva-c02-development-149",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe está migrando aplicações existentes que usam MongoDB para a AWS, rodando em instâncias Amazon EC2. A gerência quer minimizar mudanças no código. Qual serviço deve ser usado para hospedar o banco?",
"option_a": "Instalar MongoDB na mesma instância EC2 que a aplicação.",
"option_b": "Implantar o Amazon DocumentDB em modo de compatibilidade com MongoDB.",
"option_c": "Usar o Amazon API Gateway para traduzir chamadas MongoDB para operações do DynamoDB.",
"option_d": "Replicar o workload MongoDB existente para o Amazon DynamoDB.",
"correct_answers": ["B"],
"explanation_detailed": "O Amazon DocumentDB oferece compatibilidade com APIs do MongoDB, permitindo que a maior parte do código que usa drivers Mongo continue funcionando com poucas ou nenhuma modificação, além de trazer os benefícios de um serviço gerenciado.",
"incorrect_explanations": {
"A": "Instalar Mongo em EC2 exige gerenciar backup, escala e alta disponibilidade manualmente.",
"C": "Traduzir protocolos MongoDB via API Gateway seria extremamente complexo e pouco prático.",
"D": "Migrar para DynamoDB exigiria alterações significativas na modelagem de dados e no código."
}
},
{
"id": "dva-c02-monitoring-150",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa exige que funções AWS Lambda escritas pelos desenvolvedores registrem erros para que os administradores possam solucionar problemas mais facilmente. O que os desenvolvedores devem implementar?",
"option_a": "Publicar erros em uma fila dedicada do Amazon SQS.",
"option_b": "Criar um evento do Amazon CloudWatch Events baseado em certos eventos do Lambda.",
"option_c": "Registrar erros com instruções de log no código da função Lambda.",
"option_d": "Configurar um tópico Amazon SNS que envia logs quando ocorre uma falha.",
"correct_answers": ["C"],
"explanation_detailed": "Escrever logs de erro (por exemplo, console.log, print, logger.error) dentro do código da função Lambda faz com que essas mensagens sejam enviadas automaticamente ao CloudWatch Logs, onde administradores podem pesquisar, filtrar e analisar as falhas.",
"incorrect_explanations": {
"A": "Enviar tudo para SQS complica a arquitetura e exige mais componentes para análise.",
"B": "CloudWatch Events pode reagir a falhas, mas não substitui o registro de detalhes de erro no log.",
"D": "SNS é útil para alertas, mas não para armazenar e pesquisar detalhes completos de erro."
}
},
{
"id": "dva-c02-deployment-151",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um time de desenvolvimento adotou CI/CD usando AWS CodePipeline e AWS CodeCommit para uma nova aplicação. A gerência exige que uma pessoa revise e aprove o código antes de o deploy ir para produção. Como adicionar um aprovador manual ao pipeline?",
"option_a": "Usar o Amazon SES para enviar e-mail aos aprovadores quando uma ação for necessária. Criar uma aplicação simples para aceitar ou rejeitar o build e invocar uma função Lambda para avançar o pipeline quando aprovado.",
"option_b": "Se aprovado, adicionar uma tag \"approved\" ao commit no CodeCommit. O CodePipeline continuará o build e deploy apenas para commits com essa tag.",
"option_c": "Adicionar uma etapa de aprovação no CodeCommit. Commits não serão salvos até serem aprovados.",
"option_d": "Adicionar uma action de aprovação ao pipeline. Configurar essa action para publicar em um tópico Amazon SNS quando uma aprovação for necessária. A execução do pipeline irá pausar até a aprovação.",
"correct_answers": ["D"],
"explanation_detailed": "O CodePipeline tem uma ação de aprovação manual nativa. Quando ela é alcançada, o pipeline pausa e pode notificar aprovadores via SNS. Após a aprovação (via console ou API), o pipeline continua. Isso atende ao requisito com mínima complexidade adicional.",
"incorrect_explanations": {
"A": "Funciona, mas recria algo que o CodePipeline já oferece nativamente e adiciona muito código e manutenção desnecessários.",
"B": "CodePipeline não interpreta tags de commit como etapa de aprovação por padrão.",
"C": "CodeCommit não possui um mecanismo de 'aprovação de commit' que bloqueie o salvamento do commit dessa forma."
}
},
{
"id": "dva-c02-development-152",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor está criando uma aplicação serverless com AWS Lambda e precisa disponibilizar uma API REST usando um método HTTP GET. O que precisa ser definido para atender a esse requisito? (Selecione DUAS)",
"option_a": "Uma função Lambda@Edge.",
"option_b": "Um Amazon API Gateway integrado a uma função Lambda.",
"option_c": "Um método GET exposto em um recurso do Amazon API Gateway.",
"option_d": "Um método GET exposto diretamente na função Lambda.",
"option_e": "Um método GET exposto no Amazon Route 53.",
"correct_answers": ["B", "C"],
"explanation_detailed": "Para expor uma API REST com método GET usando Lambda, é necessário criar um endpoint no Amazon API Gateway (recurso + método GET) e integrá-lo a uma função Lambda. O API Gateway cuida da interface HTTP e a Lambda da lógica de negócio.",
"incorrect_explanations": {
"A": "Lambda@Edge é para customização de requisições em CloudFront, não para criar uma API REST padrão.",
"D": "Funções Lambda não expõem diretamente métodos HTTP; quem faz isso é o API Gateway ou outro front.",
"E": "Route 53 é serviço de DNS, não de API."
}
},
{
"id": "dva-c02-security-153",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação em AWS Lambda que acessa um banco de dados. Ele quer que a string de conexão possa ser alterada facilmente sem modificar o código da função. Como atender a esse requisito de forma segura?",
"option_a": "Armazenar a string de conexão como um segredo no AWS Secrets Manager.",
"option_b": "Armazenar a string de conexão em uma conta de usuário do IAM.",
"option_c": "Armazenar a string de conexão no AWS KMS.",
"option_d": "Armazenar a string de conexão em uma Lambda layer.",
"correct_answers": ["A"],
"explanation_detailed": "O AWS Secrets Manager foi projetado especificamente para armazenar segredos como strings de conexão, com rotação e controle de acesso via IAM. A Lambda pode ler o segredo em tempo de execução sem alterar o código quando o valor mudar.",
"incorrect_explanations": {
"B": "Credenciais não devem ser guardadas em contas IAM de usuário; isso complica administração e auditoria.",
"C": "O KMS gerencia chaves, não é um cofre de configuração de aplicação.",
"D": "Lambda layers servem para compartilhar código/bibliotecas, não são um mecanismo apropriado de armazenamento de segredos."
}
},
{
"id": "dva-c02-monitoring-154",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está lançando um site de e-commerce e vai hospedar os arquivos estáticos em um bucket Amazon S3. São esperadas cerca de 1.000 transações por segundo (GET e PUT). O log de acessos deve ser habilitado e mantido para auditoria. Qual é a solução MAIS econômica?",
"option_a": "Habilitar o AWS CloudTrail para ações no bucket S3 e usar uma lifecycle policy para mover os logs para o S3 Glacier após 90 dias.",
"option_b": "Habilitar o S3 server access logging e criar uma lifecycle policy para expirar os logs em 90 dias.",
"option_c": "Habilitar o AWS CloudTrail para ações no bucket S3 e criar uma lifecycle policy para expirar os logs em 90 dias.",
"option_d": "Habilitar o S3 server access logging e criar uma lifecycle policy para mover os logs para o S3 Glacier após 90 dias.",
"correct_answers": ["D"],
"explanation_detailed": "Server access logging do S3 é a forma mais barata de registrar todas as requisições ao bucket. Mover esses logs para o S3 Glacier após 90 dias minimiza ainda mais o custo de armazenamento, mantendo os dados para auditoria de longo prazo.",
"incorrect_explanations": {
"A": "CloudTrail para eventos de data (acesso a objetos) pode sair caro em alto volume e não é necessário para todos os acessos.",
"B": "Expirar os logs elimina a possibilidade de auditoria além de 90 dias, reduzindo a capacidade de investigação histórica.",
"C": "CloudTrail é mais caro do que server access logging para esse cenário de alto volume de chamadas a objetos."
}
},
{
"id": "dva-c02-security-155",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor quer armazenar dados altamente sensíveis no Amazon S3 e precisa de criptografia no lado do servidor, com controle granular sobre quem pode usar a chave mestra. A política da empresa exige que a chave possa ser criada, rotacionada e desativada facilmente. Qual opção deve ser usada?",
"option_a": "SSE com chaves gerenciadas pelo S3 (SSE-S3).",
"option_b": "SSE com chaves gerenciadas pelo AWS KMS (SSE-KMS).",
"option_c": "SSE com o AWS Secrets Manager.",
"option_d": "SSE com chaves de criptografia fornecidas pelo cliente (SSE-C).",
"correct_answers": ["B"],
"explanation_detailed": "SSE-KMS usa customer managed CMKs no AWS KMS, permitindo controle de acesso por IAM, rotação automática, desativação e auditoria de uso da chave. Isso atende diretamente aos requisitos de governança da empresa.",
"incorrect_explanations": {
"A": "SSE-S3 usa chaves totalmente gerenciadas pelo S3, sem o nível de controle e auditoria exigidos.",
"C": "Secrets Manager é um cofre de segredos, não uma solução de criptografia em repouso para S3.",
"D": "SSE-C exige que o cliente forneça a chave em cada requisição e gerencie todo o ciclo de vida da chave por conta própria."
}
},
{
"id": "dva-c02-development-156",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação on-premises aceita uploads de usuários e salva os arquivos em um diretório local do servidor. A aplicação será migrada para instâncias em um Auto Scaling group e todos os uploads devem ficar imediatamente disponíveis para todas as instâncias. Qual abordagem atende a esses requisitos?",
"option_a": "Usar Amazon EBS e configurar a AMI para montar o mesmo volume EBS em todas as instâncias.",
"option_b": "Usar o Amazon S3 e re-arquitetar a aplicação para armazenar todos os uploads no S3.",
"option_c": "Usar armazenamento de instância e compartilhá-lo entre instâncias lançadas a partir da mesma AMI.",
"option_d": "Usar Amazon EBS e software de sincronização de arquivos para manter consistência eventual entre as instâncias.",
"correct_answers": ["B"],
"explanation_detailed": "O S3 é um armazenamento compartilhado, altamente disponível e escalável, acessível por todas as instâncias. Ao salvar os uploads diretamente no S3, todas as instâncias têm acesso imediato aos arquivos sem sincronização extra.",
"incorrect_explanations": {
"A": "Um mesmo volume EBS não pode ser montado em múltiplas instâncias em leitura/gravação simultânea dessa forma.",
"C": "Armazenamento de instância é local à instância, efêmero e não compartilhado.",
"D": "Sincronização entre vários EBS é complexa, frágil e não garante disponibilidade imediata em todos os nós."
}
},
{
"id": "dva-c02-development-157",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um site estático hospedado no Amazon S3 chama uma API hospedada no Amazon API Gateway + AWS Lambda. O navegador exibe o erro: \"No Access-Control-Allow-Origin header is present on the requested resource\". O que o desenvolvedor deve fazer para resolver o problema?",
"option_a": "Habilitar CORS no bucket S3.",
"option_b": "Habilitar CORS no método do API Gateway.",
"option_c": "Adicionar o cabeçalho Access-Control-Request-Method na requisição.",
"option_d": "Adicionar o cabeçalho Access-Control-Request-Headers na requisição.",
"correct_answers": ["B"],
"explanation_detailed": "O erro indica que a resposta da API não inclui o cabeçalho Access-Control-Allow-Origin. Isso é controlado pelo CORS configurado no API Gateway. Habilitar CORS no método faz com que o API Gateway adicione os cabeçalhos apropriados.",
"incorrect_explanations": {
"A": "O problema não é o acesso ao S3, e sim à API; o CORS deve ser configurado na API.",
"C": "Access-Control-Request-Method é um cabeçalho de pré-flight do cliente, não resolve a falta do cabeçalho de resposta.",
"D": "Access-Control-Request-Headers também é usado na requisição de pré-flight e não substitui o cabeçalho de resposta necessário."
}
},
{
"id": "dva-c02-security-158",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está construindo uma aplicação que precisa criptografar dados antes de enviá-los para o Amazon S3. A equipe de Segurança deve gerenciar as chaves de criptografia. Qual abordagem deve ser usada?",
"option_a": "Implementar SSE-C (server-side encryption com chaves fornecidas pelo cliente).",
"option_b": "Implementar SSE usando uma master key no lado do cliente.",
"option_c": "Implementar criptografia no cliente usando uma CMK gerenciada pelo AWS KMS.",
"option_d": "Implementar criptografia no cliente usando chaves gerenciadas pelo S3.",
"correct_answers": ["C"],
"explanation_detailed": "A criptografia no cliente com uma CMK do KMS permite que a equipe de Segurança gerencie o ciclo de vida da chave (permissões, rotação, desativação) enquanto a aplicação cifra os dados localmente antes do upload para o S3.",
"incorrect_explanations": {
"A": "SSE-C é criptografia no servidor, não no cliente, e exige que o cliente envie a chave em cada requisição.",
"B": "Uma master key puramente local não é gerenciada centralmente pelo time de Segurança via AWS.",
"D": "Não existe modelo de \"criação de chaves gerenciadas pelo S3\" para criptografia no cliente; S3 gerencia chaves apenas para SSE-S3."
}
},
{
"id": "dva-c02-development-159",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor escreveu uma aplicação que consome dados de um Amazon Kinesis Data Stream. Com o aumento do uso, a aplicação passa a receber erros ProvisionedThroughputExceededException. Quais ações devem ser tomadas para resolver o problema? (Selecione DUAS)",
"option_a": "Usar Auto Scaling para escalar o stream automaticamente.",
"option_b": "Aumentar o atraso entre as chamadas GetRecords e PutRecords.",
"option_c": "Aumentar o número de shards do data stream.",
"option_d": "Especificar um shard iterator usando o parâmetro ShardIterator.",
"option_e": "Implementar backoff exponencial nas chamadas GetRecords e PutRecords.",
"correct_answers": ["C", "E"],
"explanation_detailed": "ProvisionedThroughputExceededException indica que o limite de capacidade do shard foi excedido. Aumentar o número de shards (shard splitting) aumenta a capacidade do stream. Além disso, implementar backoff exponencial reduz a pressão de requisições concorrentes quando o limite é atingido.",
"incorrect_explanations": {
"A": "Não existe um Auto Scaling nativo para shards de Kinesis Data Streams nesses termos; o dimensionamento é manual ou via scripts.",
"B": "Apenas adicionar atraso fixo não é tão eficaz quanto backoff exponencial e não resolve o problema de capacidade se o throughput for consistentemente alto.",
"D": "ShardIterator é necessário para ler, mas não resolve erros de throughput excedido."
}
},
{
"id": "dva-c02-security-160",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está publicando logs críticos em um log group do Amazon CloudWatch Logs criado há 2 meses. Agora é necessário criptografar os logs com uma CMK do AWS KMS para que os próximos dados estejam em conformidade. Como atender a esse requisito?",
"option_a": "Usar o console do CloudWatch Logs e habilitar o recurso de criptografia no log group.",
"option_b": "Usar o comando AWS CLI create-log-group e especificar o ARN da chave.",
"option_c": "Usar o console do KMS e associar a CMK ao log group.",
"option_d": "Usar o comando AWS CLI associate-kms-key e especificar o ARN da chave.",
"correct_answers": ["D"],
"explanation_detailed": "Para um log group já existente, a forma correta é usar o comando associate-kms-key da AWS CLI (ou chamada equivalente na API) para associar o log group à CMK desejada. A partir daí, novos logs serão criptografados.",
"incorrect_explanations": {
"A": "O console em si por baixo dos panos usa a API associate-kms-key; a alternativa citada não descreve claramente essa ação.",
"B": "create-log-group cria um novo log group; não associa chaves a um já existente.",
"C": "A associação é iniciada do lado do CloudWatch Logs, não do console do KMS."
}
},
{
"id": "dva-c02-security-161",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Código rodando em instâncias Amazon EC2 precisa de acesso somente leitura a uma tabela Amazon DynamoDB. Qual é a abordagem MAIS segura?",
"option_a": "Criar uma access key para cada instância EC2 com permissão de leitura e colocar as chaves no código.",
"option_b": "Usar uma IAM role com a policy AmazonDynamoDBReadOnlyAccess anexada às instâncias EC2.",
"option_c": "Rodar o código usando as chaves root da conta AWS para garantir acesso máximo.",
"option_d": "Usar uma IAM role com permissão AdministratorAccess anexada às instâncias EC2.",
"correct_answers": ["B"],
"explanation_detailed": "A forma segura e recomendada é usar uma IAM role associada à instância (instance profile), com permissões mínimas necessárias, neste caso somente leitura no DynamoDB.",
"incorrect_explanations": {
"A": "Colocar chaves no código é um sério problema de segurança e dificulta rotação.",
"C": "Usar chaves root é um dos piores anti-padrões de segurança possíveis.",
"D": "AdministratorAccess viola o princípio do menor privilégio."
}
},
{
"id": "dva-c02-development-162",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação web foi migrada para AWS usando um processo de CI/CD com blue/green deployment em instâncias EC2 atrás de um Application Load Balancer. Após o deploy de uma nova versão, usuários reclamam que são desconectados do sistema e precisam fazer login novamente a cada novo deploy. Como resolver esses problemas?",
"option_a": "Usar rolling updates em vez de blue/green deployment.",
"option_b": "Externalizar as sessões de usuário para o Amazon ElastiCache.",
"option_c": "Ativar sticky sessions no Application Load Balancer.",
"option_d": "Usar multicast para replicar informações de sessão.",
"correct_answers": ["B"],
"explanation_detailed": "Em blue/green, o tráfego muda de um conjunto de instâncias para outro. Se a sessão está armazenada em memória local, ela se perde na troca. Armazenar a sessão em um datastore compartilhado como ElastiCache (Redis/Memcached) garante persistência das sessões entre versões.",
"incorrect_explanations": {
"A": "Rolling updates reduzem o impacto, mas não resolvem o problema de sessão armazenada localmente.",
"C": "Sticky sessions ajudam enquanto as instâncias são as mesmas, mas não resolvem a perda de sessão quando as instâncias do blue/green são trocadas.",
"D": "Multicast não é uma solução típica nem recomendada para replicar sessão em ambientes de produção na AWS."
}
},
{
"id": "dva-c02-development-163",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor quer inserir um registro em uma tabela Amazon DynamoDB assim que um novo arquivo for adicionado a um bucket Amazon S3. Quais passos são necessários?",
"option_a": "Criar um evento do Amazon CloudWatch Events que monitora o bucket S3 e insere os registros no DynamoDB.",
"option_b": "Configurar um evento do S3 para invocar uma função Lambda que insere os registros no DynamoDB.",
"option_c": "Criar uma função Lambda que faz polling no bucket S3 e insere os registros no DynamoDB.",
"option_d": "Criar um cron job que roda em horários agendados e insere os registros no DynamoDB.",
"correct_answers": ["B"],
"explanation_detailed": "O Amazon S3 pode disparar eventos diretamente para uma função Lambda quando objetos são criados. Essa função pode então gravar os metadados necessários em uma tabela DynamoDB, sem polling nem agendamentos.",
"incorrect_explanations": {
"A": "CloudWatch Events (EventBridge) não é necessário, pois o S3 já possui integração nativa com Lambda.",
"C": "Fazer polling do S3 é ineficiente e aumenta custo e latência.",
"D": "Cron jobs não reagem em tempo real aos uploads e adicionam atrasos desnecessários."
}
},
{
"id": "dva-c02-deployment-164",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa usa AWS CodeDeploy com deploy in-place em instâncias EC2 e habilitou rollbacks automáticos. O deploy de uma nova versão falha por causa de regressão de código. O que acontece?",
"option_a": "A última versão conhecida como boa é restaurada automaticamente usando um snapshot armazenado no Amazon S3.",
"option_b": "O CodeDeploy altera o alias do Route 53 de volta para o green deployment conhecido como bom e termina o blue deployment com falha.",
"option_c": "Uma nova implantação da última versão conhecida como boa é iniciada com um novo deployment ID.",
"option_d": "O AWS CodePipeline promove automaticamente a implantação mais recente com status SUCCEEDED para produção.",
"correct_answers": ["C"],
"explanation_detailed": "Com rollback automático habilitado em deploy in-place, o CodeDeploy inicia uma nova implantação usando a revisão anterior conhecida como boa (última SUCCEEDED), com um novo deployment ID.",
"incorrect_explanations": {
"A": "Não há mecanismo nativo de snapshot em S3 usado dessa forma pelo CodeDeploy.",
"B": "Essa lógica de blue/green + Route 53 aplica-se a blue/green deployments, não ao modo in-place descrito.",
"D": "O rollback é controlado pelo CodeDeploy; o CodePipeline não promove automaticamente um deploy anterior nesse cenário."
}
},
{
"id": "dva-c02-security-165",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor usa dois buckets S3 para um site estático: um bucket para o código e outro para assets (imagens e vídeos). Quando o código tenta acessar arquivos do bucket de assets, recebe erro 403. Como resolver isso?",
"option_a": "Criar uma IAM role e aplicá-la ao bucket de assets para conceder acesso ao bucket de código.",
"option_b": "Editar a bucket policy do bucket de assets para permitir acesso a partir do bucket de código.",
"option_c": "Editar a bucket policy do bucket de assets para abrir acesso a todos os principals.",
"option_d": "Trocar o bucket de código para usar funções Lambda em vez de website estático.",
"correct_answers": ["B"],
"explanation_detailed": "O acesso entre buckets S3 é controlado por bucket policies e/ou IAM. Ajustar a policy do bucket de assets para permitir acesso às requisições originadas do domínio do bucket de código (ou de um principal específico) resolve o 403 sem abrir tudo para o mundo.",
"incorrect_explanations": {
"A": "IAM roles são usadas por identidades (como EC2, Lambda), não para 'ligar' buckets entre si diretamente.",
"C": "Abrir acesso público completo ao bucket de assets é desnecessário e inseguro.",
"D": "Trocar a tecnologia do bucket de código não ataca a raiz do problema, que é a permissão no bucket de assets."
}
},
{
"id": "dva-c02-monitoring-166",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa implementou AWS CodePipeline para automatizar releases. Um desenvolvedor precisa escrever uma função Lambda que envie notificações a cada mudança de estado das actions do pipeline. Que passos são necessários para associar a função ao evento?",
"option_a": "Criar um trigger no console do Lambda, escolhendo CodePipeline como event source.",
"option_b": "Criar um trigger de evento no console do CodePipeline e especificar a função Lambda.",
"option_c": "Criar um alarme do Amazon CloudWatch que monitore mudanças de status no CodePipeline e acione a função Lambda.",
"option_d": "Criar uma regra do Amazon CloudWatch Events (EventBridge) usando CodePipeline como event source.",
"correct_answers": ["D"],
"explanation_detailed": "O CodePipeline publica eventos de mudança de estado no CloudWatch Events / EventBridge. Criar uma regra com CodePipeline como origem e a função Lambda como alvo é a forma correta de reagir a esses eventos.",
"incorrect_explanations": {
"A": "CodePipeline não aparece como event source direto na tela de triggers do Lambda.",
"B": "O console do CodePipeline não oferece a configuração direta desse tipo de evento; isso é feito no EventBridge.",
"C": "CloudWatch Alarms são usados para métricas numéricas, não para eventos de estado de pipeline."
}
},
{
"id": "dva-c02-deployment-167",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor criou uma aplicação serverless com AWS Lambda usando AWS Serverless Application Model (AWS SAM). Qual é a ordem correta para fazer o deploy da aplicação?",
"option_a": "1) Build do template SAM em uma instância EC2; 2) Package em um volume EBS; 3) Deploy a partir do EBS.",
"option_b": "1) Build do template SAM localmente; 2) Package do template em um bucket S3; 3) Deploy do template a partir do S3.",
"option_c": "1) Build do template SAM localmente; 2) Deploy do template a partir do S3; 3) Package do template.",
"option_d": "1) Build do template SAM localmente; 2) Package do template a partir do CodeCommit; 3) Deploy do template para o CodeCommit.",
"correct_answers": ["B"],
"explanation_detailed": "O fluxo recomendado é: sam build (ou equivalente) localmente, sam package (que sobe artefatos para um bucket S3) e, em seguida, sam deploy (que cria/atualiza o stack CloudFormation a partir do template empacotado).",
"incorrect_explanations": {
"A": "Não há necessidade de envolver EC2 e EBS nesse fluxo.",
"C": "Deploy não pode vir antes do package, pois o CloudFormation precisa do template já ajustado com URIs de S3.",
"D": "CodeCommit é para controle de versão, não é o alvo de deploy da aplicação."
}
},
{
"id": "dva-c02-security-168",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está migrando um serviço de processamento de imagens para o Amazon EC2. As imagens são lidas de um bucket S3 privado. Qual é a melhor forma, seguindo boas práticas de segurança, de conceder acesso ao bucket?",
"option_a": "Criar um usuário IAM com acesso somente leitura ao bucket S3 e armazenar as credenciais temporariamente no volume EBS da instância.",
"option_b": "Criar um usuário IAM com acesso somente leitura ao bucket S3 e armazenar as credenciais nos user data da instância.",
"option_c": "Criar uma EC2 service role com acesso somente leitura ao bucket S3 e anexá-la à instância.",
"option_d": "Criar uma S3 service role com acesso somente leitura ao bucket S3 e anexá-la à instância.",
"correct_answers": ["C"],
"explanation_detailed": "A abordagem correta é usar uma IAM role de serviço para EC2 (instance profile), que fornece credenciais temporárias de forma automática com as permissões necessárias, neste caso leitura no bucket S3.",
"incorrect_explanations": {
"A": "Guardar credenciais fixas no disco é um risco grande de segurança.",
"B": "User data não é local seguro para credenciais; ainda assim seriam chaves fixas.",
"D": "Não existe 'S3 service role' anexada diretamente à instância; a role correta é associada ao serviço EC2."
}
},
{
"id": "dva-c02-deployment-169",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma equipe quer que o build e o deploy sejam disparados automaticamente sempre que houver mudança no código-fonte. Quais abordagens podem ser usadas para iniciar o CodePipeline? (Selecione DUAS)",
"option_a": "Armazenar o código-fonte em um bucket S3 e configurar o CodePipeline para iniciar sempre que um arquivo no bucket for alterado.",
"option_b": "Armazenar o código-fonte em um volume EBS criptografado e configurar o CodePipeline para iniciar sempre que um arquivo no volume for alterado.",
"option_c": "Armazenar o código-fonte em um repositório AWS CodeCommit e configurar o CodePipeline para iniciar sempre que houver um commit.",
"option_d": "Armazenar o código-fonte em um bucket S3 e configurar o CodePipeline para iniciar a cada 15 minutos.",
"option_e": "Armazenar o código-fonte no armazenamento efêmero de uma instância EC2 e configurar a instância para iniciar o CodePipeline sempre que houver mudanças.",
"correct_answers": ["A", "C"],
"explanation_detailed": "O CodePipeline pode ser disparado por mudanças em um bucket S3 (novo objeto/alteração) ou por commits em um repositório CodeCommit, ambos suportados nativamente como fontes de pipeline.",
"incorrect_explanations": {
"B": "CodePipeline não monitora mudanças em volumes EBS.",
"D": "Rodar a cada 15 minutos não reage imediatamente às mudanças e gera execuções desnecessárias.",
"E": "Depender de armazenamento efêmero e lógica customizada na EC2 é frágil e fora do fluxo recomendado."
}
},
{
"id": "dva-c02-development-170",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação ingere um grande número de mensagens pequenas e as armazena em um banco de dados. O backend usa AWS Lambda. Durante testes, o processamento de cada mensagem ultrapassa 15 minutos, e há preocupação com timeout. Qual mudança deve ser feita para garantir processamento escalável de cada mensagem?",
"option_a": "Adicionar as mensagens em uma fila Amazon SQS e usar uma única instância EC2 para fazer polling e processar as mensagens.",
"option_b": "Adicionar as mensagens em uma fila Amazon SQS e usar instâncias EC2 em um Auto Scaling group para fazer polling e processá-las conforme chegam.",
"option_c": "Abrir um chamado de suporte para aumentar o timeout máximo da Lambda para 60 minutos.",
"option_d": "Alterar a aplicação para inserir o corpo da mensagem diretamente em um banco de dados Amazon RDS.",
"correct_answers": ["B"],
"explanation_detailed": "Quando o processamento excede o limite de tempo da Lambda, é melhor mover o trabalho para um modelo com EC2 e SQS, onde instâncias em um Auto Scaling group podem processar mensagens pesadas sem limite rígido de 15 minutos.",
"incorrect_explanations": {
"A": "Uma única instância EC2 limita a escalabilidade e vira gargalo facilmente.",
"C": "O timeout máximo da Lambda é 15 minutos; não há aumento para 60 minutos.",
"D": "Mudar para gravação direta em RDS não resolve o problema do tempo de processamento de cada mensagem."
}
},
{
"id": "dva-c02-development-171",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um engenheiro desenvolveu uma função AWS Lambda em Node.js para processamento de dados intensivo em CPU. Com as configurações padrão, a função leva cerca de 5 minutos para concluir. O que deve ser feito para reduzir o tempo médio de execução?",
"option_a": "Reescrever a função Lambda em Python.",
"option_b": "Mover as bibliotecas do pacote ZIP para uma Lambda layer.",
"option_c": "Alocar o máximo de unidades de CPU disponíveis para a função.",
"option_d": "Aumentar a configuração de memória da função.",
"correct_answers": ["D"],
"explanation_detailed": "Na Lambda, CPU é proporcional à memória configurada. Ao aumentar a memória, a função recebe mais CPU e pode terminar o processamento mais rapidamente, reduzindo o tempo total de execução.",
"incorrect_explanations": {
"A": "Trocar de linguagem não garante melhoria de performance e exige reescrita.",
"B": "Lambda layers ajudam na organização e no reuso, mas não afetam diretamente performance de CPU.",
"C": "Não existe configuração direta de 'CPU units' na Lambda; o ajuste é feito via memória."
}
},
{
"id": "dva-c02-deployment-172",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação serverless com Lambda, API Gateway, S3 e DynamoDB foi implantada via CloudFormation. Após uma nova versão com grandes mudanças na função Lambda, a aplicação parou de funcionar. Qual é a forma mais rápida de restaurar o serviço?",
"option_a": "Reimplantar a aplicação em instâncias EC2 para que a função Lambda possa resolver dependências.",
"option_b": "Migrar a tabela DynamoDB para o Amazon RDS e reimplantar a função Lambda.",
"option_c": "Fazer rollback da função Lambda para a versão anterior.",
"option_d": "Implantar a versão mais recente da função Lambda em outra região.",
"correct_answers": ["C"],
"explanation_detailed": "A Lambda mantém versões publicadas. Se a última alteração quebrou a aplicação, reverter para a versão anterior conhecida como boa é o caminho mais rápido para restaurar o serviço.",
"incorrect_explanations": {
"A": "Migrar para EC2 é desnecessário e demorado.",
"B": "Mover dados de DynamoDB para RDS não está relacionado ao problema descrito.",
"D": "Implantar a mesma versão quebrada em outra região apenas reproduziria o erro em outro lugar."
}
},
{
"id": "dva-c02-development-173",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação que roda em instâncias EC2 em um Auto Scaling group e precisa externalizar o estado de sessão para suportar a aplicação. Quais serviços atendem a essa necessidade? (Selecione DUAS)",
"option_a": "Amazon DynamoDB.",
"option_b": "Amazon Cognito.",
"option_c": "Amazon ElastiCache.",
"option_d": "Amazon EBS.",
"option_e": "Amazon SQS.",
"correct_answers": ["A", "C"],
"explanation_detailed": "Sessões podem ser guardadas em um storage compartilhado e de baixa latência como DynamoDB ou ElastiCache (Redis/Memcached). Ambos permitem que múltiplas instâncias num Auto Scaling group compartilhem o mesmo estado de sessão.",
"incorrect_explanations": {
"B": "Cognito é para identidade e autenticação de usuários, não para armazenamento arbitrário de sessão da aplicação.",
"D": "EBS é ligado a uma instância; não é ideal para compartilhamento entre várias instâncias.",
"E": "SQS é fila de mensagens, não um data store para estado de sessão."
}
},
{
"id": "dva-c02-monitoring-174",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação legada roda on-premises, e outras aplicações na AWS dependem dela. O desenvolvedor quer usar o Amazon CloudWatch para monitorar e solucionar problemas de todas as aplicações em um só lugar. Como incluir a aplicação on-premises nessa observabilidade?",
"option_a": "Instalar um AWS SDK no servidor on-premises para enviar logs automaticamente ao CloudWatch.",
"option_b": "Baixar o CloudWatch agent para o servidor on-premises e configurá-lo com credenciais IAM que tenham permissão no CloudWatch.",
"option_c": "Fazer upload periódico dos arquivos de log para um bucket S3 e configurar o CloudWatch para ler esses arquivos.",
"option_d": "Fazer upload dos arquivos de log para uma instância EC2 e usar essa instância para encaminhar os logs ao CloudWatch.",
"correct_answers": ["B"],
"explanation_detailed": "O CloudWatch agent pode ser instalado em servidores on-premises e configurado com um perfil IAM (via credenciais) para enviar métricas e logs diretamente para o CloudWatch, unificando a observabilidade.",
"incorrect_explanations": {
"A": "O SDK permite enviar logs, mas exigiria muito código customizado em vez de usar o agente pronto.",
"C": "CloudWatch não lê arquivos diretamente do S3; seria necessário mais infraestrutura intermediária.",
"D": "Subir logs para EC2 e depois encaminhar é um fluxo desnecessariamente complexo comparado ao uso direto do agente."
}
},
{
"id": "dva-c02-security-175",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está desenvolvendo uma aplicação acessada via Amazon API Gateway REST. Apenas usuários registrados devem acessar certos recursos da API. O token usado deve expirar automaticamente e ser renovado periodicamente. Como o desenvolvedor deve atender a esses requisitos?",
"option_a": "Criar um Amazon Cognito identity pool, configurar o Cognito Authorizer no API Gateway e usar as credenciais temporárias geradas.",
"option_b": "Criar e manter um registro em banco para cada usuário com um token correspondente e usar um Lambda authorizer no API Gateway.",
"option_c": "Criar um Amazon Cognito user pool, configurar o Cognito Authorizer no API Gateway e usar o ID token ou access token.",
"option_d": "Criar um usuário IAM para cada usuário da API, anexar uma policy de invoke e usar um IAM authorizer no API Gateway.",
"correct_answers": ["C"],
"explanation_detailed": "User pools do Cognito gerenciam cadastro, autenticação, expiração e renovação de tokens JWT. O Cognito Authorizer no API Gateway pode validar esses tokens, garantindo que apenas usuários autenticados acessem recursos protegidos.",
"incorrect_explanations": {
"A": "Identity pools fornecem credenciais temporárias de acesso a serviços AWS, mas não gerenciam diretamente autenticação de usuários finais com tokens de app.",
"B": "Manter tokens manualmente em banco aumenta muito a complexidade e reinventa o que o Cognito já faz.",
"D": "IAM não é adequado para gerenciar identidades de usuários finais de uma aplicação pública."
}
},
{
"id": "dva-c02-development-176",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor tem uma aplicação que precisa aceitar um grande volume de fluxos de dados de entrada e processá-los antes de enviá-los para vários consumidores downstream. Qual solução serverless atende melhor a esses requisitos?",
"option_a": "Procedures armazenadas em Amazon RDS MySQL chamadas por funções AWS Lambda.",
"option_b": "AWS Direct Connect com funções AWS Lambda para processar os dados.",
"option_c": "Amazon Kinesis Data Streams integrado com funções AWS Lambda.",
"option_d": "Scripts bash em instâncias Amazon EC2 combinados com funções AWS Lambda.",
"correct_answers": ["C"],
"explanation_detailed": "Kinesis Data Streams + Lambda é o padrão serverless para ingestão contínua de grandes volumes de dados em tempo real. O stream recebe os eventos de forma escalável e as funções Lambda são disparadas para processar os registros conforme chegam, sem gerenciar servidores.",
"incorrect_explanations": {
"A": "Procedures em RDS exigem gerenciar banco relacional e não são ideais para ingestão massiva de eventos em streaming.",
"B": "Direct Connect é um link de rede dedicado, não um mecanismo de ingestão e processamento de stream.",
"D": "Scripts em EC2 quebram o modelo totalmente serverless e adicionam gerenciamento de infraestrutura."
}
},
{
"id": "dva-c02-development-177",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação está enfrentando problemas de performance com aumento de demanda. As leituras são de registros históricos, somente leitura, a partir de um banco Amazon RDS com views e queries customizadas. É preciso melhorar a performance sem mudar a estrutura do banco. Qual abordagem atende melhor esse requisito com o mínimo de overhead de gestão?",
"option_a": "Migrar todos os dados para o Amazon DynamoDB e apontar a aplicação para a nova tabela.",
"option_b": "Implantar o Amazon ElastiCache for Redis e cachear os dados acessados pela aplicação.",
"option_c": "Instalar o Memcached em instâncias Amazon EC2 e cachear os dados localmente.",
"option_d": "Implantar o Amazon DynamoDB Accelerator (DAX) sobre o banco RDS para melhorar a performance de cache.",
"correct_answers": ["B"],
"explanation_detailed": "Colocar um cache na frente do RDS com ElastiCache (Redis) permite armazenar em memória consultas frequentes, reduzindo carga no banco e melhorando a latência, sem alterar o esquema nem reescrever a aplicação por completo.",
"incorrect_explanations": {
"A": "Migrar para DynamoDB exigiria re-modelagem de dados e mudanças grandes na aplicação.",
"C": "Gerenciar Memcached em EC2 adiciona bastante overhead operacional em comparação ao serviço gerenciado do ElastiCache.",
"D": "DAX é especificamente para DynamoDB, não pode ser colocado na frente de um banco RDS."
}
},
{
"id": "dva-c02-development-178",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma tabela Amazon DynamoDB precisa ficar em modo provisionado para cumprir requisitos de compliance. A aplicação deve suportar: tamanho médio de item de 10 KB, 10 leituras fortemente consistentes por segundo e 2 gravações transacionais por segundo. Qual configuração de capacidade atende a esses requisitos com melhor relação custo-benefício?",
"option_a": "Read Capacity: 10; Write Capacity: 2.",
"option_b": "Read Capacity: 30; Write Capacity: 40.",
"option_c": "Usar on-demand capacity.",
"option_d": "Read Capacity: 300; Write Capacity: 400.",
"correct_answers": ["B"],
"explanation_detailed": "Cada leitura fortemente consistente de 10 KB consome 3 RCUs (10 / 4 KB arredondado para cima). Para 10 leituras/seg, são 30 RCUs. Cada gravação transacional de 10 KB consome o dobro de WCUs: 10 WCUs pelo tamanho e x2 pela transação, ou seja, 20 WCUs por gravação. Para 2 gravações/seg, são 40 WCUs. Portanto, 30 RCUs e 40 WCUs são suficientes e mais econômicos.",
"incorrect_explanations": {
"A": "10 RCUs e 2 WCUs não suportam o volume descrito; resultaria em throttling.",
"C": "On-demand funciona, mas o enunciado exige explicitamente modo provisionado.",
"D": "300/400 é superdimensionado e aumenta o custo sem necessidade."
}
},
{
"id": "dva-c02-development-179",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa quer conteinerizar uma aplicação web de três camadas existente e implantá-la no Amazon ECS Fargate. A aplicação usa dados de sessão para rastrear a atividade dos usuários. Qual abordagem fornece a MELHOR experiência para o usuário?",
"option_a": "Provisionar um cluster Redis no Amazon ElastiCache e guardar os dados de sessão no cluster.",
"option_b": "Criar uma tabela de sessão no Amazon Redshift e guardar os dados de sessão na tabela.",
"option_c": "Habilitar stickiness de sessão no Network Load Balancer e manter as sessões na memória do container.",
"option_d": "Usar um bucket Amazon S3 como data store e guardar os dados de sessão no bucket.",
"correct_answers": ["A"],
"explanation_detailed": "Sessões devem ficar em um data store compartilhado e de baixa latência. Redis no ElastiCache é uma escolha clássica para dados de sessão em ambientes distribuídos, permitindo que qualquer container recupere o estado do usuário.",
"incorrect_explanations": {
"B": "Redshift é um data warehouse analítico, não é ideal para acessos frequentes e latência baixa de sessão.",
"C": "Stickiness não resolve o problema quando tarefas sobem e descem; e não escala bem em cenários de falha ou reimplantação.",
"D": "S3 é armazenamento de objetos, com latência maior e sem semântica de leitura/escrita de sessão em tempo real."
}
},
{
"id": "dva-c02-development-180",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação está usando uma instância única do Amazon ElastiCache for Redis para melhorar leituras. A demanda aumentou muito, elevando a carga nessa instância. É crítico que a camada de cache suporte a carga e seja resiliente a falhas de nó. O que o desenvolvedor deve fazer?",
"option_a": "Adicionar uma instância read replica ao cluster Redis.",
"option_b": "Migrar para um cluster Memcached.",
"option_c": "Migrar para um cluster Amazon Elasticsearch Service (OpenSearch Service).",
"option_d": "Escalar verticalmente a instância do ElastiCache para um tipo maior.",
"correct_answers": ["A"],
"explanation_detailed": "Adicionar réplicas de leitura em um replication group Redis permite distribuir tráfego, aumentar disponibilidade e configurar failover automático, atendendo a requisitos de carga e resiliência.",
"incorrect_explanations": {
"B": "Migrar para Memcached troca de engine sem resolver diretamente a resiliência e pode exigir mudanças na aplicação.",
"C": "OpenSearch é voltado para busca e análise, não cache de sessão/chave-valor de alta frequência.",
"D": "Escalar verticalmente ajuda na capacidade, mas não melhora a resiliência em caso de falha do nó."
}
},
{
"id": "dva-c02-monitoring-181",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está investigando problemas de performance em uma aplicação composta por centenas de microsserviços, onde uma única chamada de API pode ter uma cadeia profunda de chamadas. O desenvolvedor precisa isolar qual componente está causando o problema. Qual serviço deve ser usado?",
"option_a": "AWS X-Ray.",
"option_b": "VPC Flow Logs.",
"option_c": "Amazon GuardDuty.",
"option_d": "Amazon Macie.",
"correct_answers": ["A"],
"explanation_detailed": "O AWS X-Ray foi projetado para rastreamento distribuído, permitindo seguir uma requisição ponta a ponta pelos microsserviços e identificar onde estão as maiores latências e falhas.",
"incorrect_explanations": {
"B": "VPC Flow Logs ajudam em troubleshooting de rede, não em rastreamento de aplicações.",
"C": "GuardDuty é para detecção de ameaças, não para debug de performance.",
"D": "Macie é para descoberta e proteção de dados sensíveis, não para rastreamento de chamadas."
}
},
{
"id": "dva-c02-deployment-182",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa usa AWS CodePipeline para seus pipelines de CI/CD. Um desenvolvedor precisa escrever testes de unidade e executá-los como parte do pipeline antes de disponibilizar artefatos para testes. Como incorporar os testes ao pipeline?",
"option_a": "Criar um pipeline CodePipeline separado apenas para executar testes de unidade.",
"option_b": "Atualizar o buildspec do AWS CodeBuild para incluir uma fase de execução dos testes de unidade.",
"option_c": "Instalar o agente do AWS CodeDeploy em uma instância EC2 para rodar os testes de unidade.",
"option_d": "Criar um branch de testes no AWS CodeCommit para rodar os testes de unidade.",
"correct_answers": ["B"],
"explanation_detailed": "O CodeBuild é a etapa de build/testes do CodePipeline. Incluir uma fase de testes de unidade no buildspec.yml garante que os testes rodem automaticamente durante o pipeline, falhando o pipeline se os testes falharem.",
"incorrect_explanations": {
"A": "Criar um pipeline separado aumenta complexidade sem necessidade; o ideal é integrar os testes ao pipeline principal.",
"C": "CodeDeploy não é responsável por rodar testes de unidade.",
"D": "Criar um branch separado não garante integração automática dos testes no pipeline principal."
}
},
{
"id": "dva-c02-development-183",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação tem os seguintes requisitos: desempenho de segundos, tolerando até 1 minuto de latência; armazenamento podendo crescer para milhares de terabytes; mensagens entre 100 KB e 100 MB; dados armazenados como chave/valor com consistência eventual. Qual serviço AWS é o MAIS econômico para atender a esses requisitos?",
"option_a": "Amazon DynamoDB.",
"option_b": "Amazon S3.",
"option_c": "Amazon RDS (MySQL).",
"option_d": "Amazon ElastiCache.",
"correct_answers": ["B"],
"explanation_detailed": "O Amazon S3 é otimizado para armazenar grandes volumes de dados (escala de petabytes), com objetos grandes e consistência eventual para alguns padrões de acesso, com custo muito baixo por GB, atendendo bem ao cenário descrito.",
"incorrect_explanations": {
"A": "DynamoDB suporta chave/valor, mas armazenar milhares de TB com objetos grandes fica bem mais caro que S3.",
"C": "RDS não é ideal para objetos grandes e volumes de dados nessa ordem, além de ser mais caro.",
"D": "ElastiCache é memória volátil, não foi feito para armazenar milhares de TB de dados persistentes."
}
},
{
"id": "dva-c02-security-184",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa permitir que usuários convidados, sem login, acessem um site habilitado com Amazon Cognito para visualizar arquivos em um bucket Amazon S3. Como atender a esse requisito?",
"option_a": "Criar um usuário em branco no user pool, adicioná-lo a um grupo e conceder acesso aos recursos AWS.",
"option_b": "Criar um identity pool, habilitar acesso a identidades não autenticadas e conceder acesso aos recursos AWS.",
"option_c": "Criar um user pool, habilitar acesso autenticado e conceder acesso aos recursos AWS.",
"option_d": "Criar um user pool, desabilitar autenticação e conceder acesso aos recursos AWS.",
"correct_answers": ["B"],
"explanation_detailed": "Identity pools do Cognito permitem conceder credenciais temporárias da AWS tanto para identidades autenticadas quanto não autenticadas (convidados), que então podem receber permissões para ler objetos em S3.",
"incorrect_explanations": {
"A": "Criar um usuário 'fake' e compartilhar seria um anti-padrão de segurança.",
"C": "User pools tratam autenticação; para convidados, é necessário identity pool com acesso não autenticado.",
"D": "User pools não funcionam com 'autenticação desabilitada'; isso não configura acesso convidado a recursos AWS."
}
},
{
"id": "dva-c02-development-185",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor escreveu o código de uma aplicação e quer compartilhá-lo com outros desenvolvedores do time para feedback. O código precisa ser armazenado de forma duradoura com múltiplas versões e rastreamento de alterações em lote. Qual serviço deve ser usado?",
"option_a": "AWS CodeBuild.",
"option_b": "Amazon S3.",
"option_c": "AWS CodeCommit.",
"option_d": "AWS Cloud9.",
"correct_answers": ["C"],
"explanation_detailed": "O AWS CodeCommit é um serviço de controle de versão gerenciado e compatível com Git, mantendo histórico de commits, branches e diffs, ideal para colaboração em código.",
"incorrect_explanations": {
"A": "CodeBuild executa builds e testes, não é um repositório de código-fonte.",
"B": "S3 armazena arquivos, mas não oferece controle de versão no estilo Git com commits e branches.",
"D": "Cloud9 é um ambiente de desenvolvimento, não um sistema de versionamento por si só."
}
},
{
"id": "dva-c02-development-186",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor percebeu que a aplicação responsável por processar mensagens de uma fila Amazon SQS está ficando para trás. A aplicação consegue processar múltiplas mensagens por execução, mas só recebe uma mensagem por vez. O que deve ser feito para aumentar o número de mensagens recebidas por chamada?",
"option_a": "Chamar a API ChangeMessageVisibility na fila e definir MaxNumberOfMessages maior que 1.",
"option_b": "Chamar a API AddPermission e definir MaxNumberOfMessages maior que 1 para a ação ReceiveMessage.",
"option_c": "Chamar a API ReceiveMessage definindo MaxNumberOfMessages maior que 1.",
"option_d": "Chamar a API SetQueueAttributes na fila e definir MaxNumberOfMessages maior que 1.",
"correct_answers": ["C"],
"explanation_detailed": "O parâmetro MaxNumberOfMessages é configurado diretamente na chamada ReceiveMessage, permitindo receber até 10 mensagens por requisição e aumentando o throughput de processamento.",
"incorrect_explanations": {
"A": "ChangeMessageVisibility ajusta o visibility timeout, não a quantidade de mensagens retornadas.",
"B": "AddPermission trata permissões, não a quantidade de mensagens por chamada.",
"D": "MaxNumberOfMessages não é um atributo da fila; é parâmetro da operação ReceiveMessage."
}
},
{
"id": "dva-c02-deployment-187",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"active": true,
"question_text": "Um desenvolvedor registrou uma função AWS Lambda como target de um Application Load Balancer (ALB) via CLI. Porém, a função não está sendo invocada quando os clientes enviam requisições pelo ALB. Qual é a causa mais provável?",
"option_a": "Uma função Lambda não pode ser registrada como target de um ALB.",
"option_b": "Uma função Lambda só pode ser registrada com um ALB via console, não por CLI.",
"option_c": "As permissões para invocar a função Lambda estão ausentes.",
"option_d": "O cross-zone load balancing não está habilitado no ALB.",
"correct_answers": ["C"],
"explanation_detailed": "Ao usar Lambda como target de ALB é necessário conceder permissão explícita para que o ALB invoque a função (via AWS::Lambda::Permission ou comando equivalente). Sem essa permissão, o ALB não consegue chamar a função.",
"incorrect_explanations": {
"A": "Lambda é suportado como target de ALB.",
"B": "O registro pode ser feito por CLI ou API normalmente.",
"D": "Cross-zone não afeta a capacidade do ALB de invocar a Lambda."
}
},
{
"id": "dva-c02-security-188",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa fornece APIs como serviço e tem SLAs com seus usuários. Para cumprir os SLAs, é necessário limitar o uso por usuário. O que a empresa deve fazer?",
"option_a": "Habilitar limites de throttling em cada método do Amazon API Gateway.",
"option_b": "Criar um usage plan para cada usuário e exigir API keys para acessar as APIs.",
"option_c": "Habilitar rate limiting em cada usuário no Amazon Cognito.",
"option_d": "Habilitar limites de throttling padrão em cada stage após fazer o deploy das APIs.",
"correct_answers": ["B"],
"explanation_detailed": "Usage plans com API keys permitem controlar quotas e limites de requisições por consumidor da API, sendo o mecanismo recomendado para cumprir SLAs diferenciados.",
"incorrect_explanations": {
"A": "Throttling em nível de método é global para o stage, não por usuário.",
"C": "Cognito não é responsável por rate limiting de APIs desse modo.",
"D": "Throttling padrão por stage também é global, não individual por cliente."
}
},
{
"id": "dva-c02-deployment-189",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está preparando um pacote de implantação usando AWS CloudFormation. Há dois templates: um de infraestrutura, que cria uma VPC, e outro de aplicação, que precisa rodar dentro dessa VPC. Como o stack da aplicação pode referenciar a VPC criada pelo stack de infraestrutura?",
"option_a": "Usar a função Ref para importar a VPC diretamente a partir do template de infraestrutura.",
"option_b": "Usar uma saída Export no template de infraestrutura e a função Fn::ImportValue no template de aplicação.",
"option_c": "Usar o atributo DependsOn no template de aplicação apontando para o recurso VPC.",
"option_d": "Usar a função Fn::GetAtt para puxar o atributo da VPC diretamente no template de aplicação.",
"correct_answers": ["B"],
"explanation_detailed": "O mecanismo recomendado entre stacks é exportar um valor em Outputs com Export e, em outro template, usar Fn::ImportValue. Assim a aplicação pode referenciar o ID da VPC criada pelo stack de infraestrutura.",
"incorrect_explanations": {
"A": "Ref sozinho não permite referenciar recursos de outro stack sem Export/ImportValue.",
"C": "DependsOn controla ordem de criação dentro de um mesmo stack, não entre stacks diferentes.",
"D": "Fn::GetAtt não funciona entre stacks sem o uso de exportação/importação de valores."
}
},
{
"id": "dva-c02-security-190",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa criar uma aplicação que suporte autenticação via SAML e Facebook, e que também permita acesso a serviços AWS como o Amazon DynamoDB. Qual serviço atende a esses requisitos com o MENOR esforço de código adicional?",
"option_a": "AWS AppSync.",
"option_b": "Amazon Cognito identity pools.",
"option_c": "Amazon Cognito user pools.",
"option_d": "AWS Lambda@Edge.",
"correct_answers": ["B"],
"explanation_detailed": "Identity pools do Cognito permitem federar identidades de provedores SAML e de redes sociais (como Facebook) e trocar essas identidades por credenciais temporárias para acessar serviços AWS, como DynamoDB.",
"incorrect_explanations": {
"A": "AppSync é para APIs GraphQL, não é o foco principal de autenticação federada com acesso direto a serviços AWS.",
"C": "User pools tratam autenticação de usuários, mas para conceder credenciais AWS o padrão é integrar com identity pools.",
"D": "Lambda@Edge é usado para customizar requisições em CloudFront, não para orquestrar autenticação SAML + social + acesso AWS."
}
},
{
"id": "dva-c02-monitoring-191",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor executa um cron job que retorna 1 se um serviço está de pé e 0 se estiver fora. Ele escreveu código que usa o comando AWS CLI put-metric-alarm para publicar métricas customizadas no Amazon CloudWatch e criar um alarme, mas as métricas não aparecem no console. Qual é a causa?",
"option_a": "Não é suportado enviar métricas customizadas usando a CLI.",
"option_b": "É necessário usar o comando put-metric-data para enviar métricas customizadas.",
"option_c": "É obrigatório usar o CloudWatch Agent unificado para publicar métricas customizadas.",
"option_d": "O código não está rodando em uma instância Amazon EC2.",
"correct_answers": ["B"],
"explanation_detailed": "Para criar métricas customizadas é preciso usar put-metric-data. O comando put-metric-alarm apenas cria/atualiza alarmes baseados em métricas que já existem.",
"incorrect_explanations": {
"A": "A CLI suporta publicar métricas customizadas normalmente.",
"C": "O CloudWatch Agent é opcional; não é o único meio de enviar métricas.",
"D": "O envio de métricas não depende de estar em EC2; pode ser feito de qualquer lugar com credenciais válidas."
}
},
{
"id": "dva-c02-monitoring-192",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação rodando em instâncias Amazon EC2 gera um valor a cada minuto. O desenvolvedor quer monitorar e visualizar esses valores ao longo do tempo sem precisar logar nas instâncias. Qual abordagem deve ser usada?",
"option_a": "Usar somente as métricas padrão do Amazon CloudWatch para EC2.",
"option_b": "Gravar o valor em um arquivo no Amazon S3 por minuto com o timestamp no nome.",
"option_c": "Publicar cada valor como métrica customizada no Amazon CloudWatch usando os SDKs da AWS.",
"option_d": "Armazenar o valor em uma variável e adicioná-la à lista de métricas padrão da instância EC2.",
"correct_answers": ["C"],
"explanation_detailed": "Publicar o valor como métrica customizada permite usar gráficos, alarmes e dashboards do CloudWatch sem acessar as instâncias, mantendo todo o histórico de forma centralizada.",
"incorrect_explanations": {
"A": "As métricas padrão não incluem o valor customizado gerado pela aplicação.",
"B": "Salvar em S3 até funciona, mas dificulta análise em tempo real e visualização direta.",
"D": "Não existe mecanismo para 'adicionar' variáveis arbitrárias à lista de métricas padrão da EC2."
}
},
{
"id": "dva-c02-development-193",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Você lançou uma instância para atuar como dispositivo NAT em uma subnet pública. Ajustou a tabela de rotas para enviar o tráfego de saída da subnet privada para essa instância. Porém, as instâncias da subnet privada ainda não conseguem acessar a Internet. O que pode resolver o problema?",
"option_a": "Anexar uma segunda interface de rede (ENI) à instância NAT e colocá-la na subnet privada.",
"option_b": "Anexar uma segunda interface de rede (ENI) à instância na subnet privada e colocá-la na subnet pública.",
"option_c": "Desabilitar o atributo Source/Destination Check na instância NAT.",
"option_d": "Anexar um Elastic IP à instância na subnet privada.",
"correct_answers": ["C"],
"explanation_detailed": "Uma instância NAT precisa ter o Source/Destination Check desabilitado, pois irá encaminhar tráfego que não é originado nela. Com esse check habilitado, a instância descarta o tráfego roteado através dela.",
"incorrect_explanations": {
"A": "Um NAT instance padrão usa uma ENI na subnet pública com rota para a Internet; a segunda ENI na privada não resolve o problema principal.",
"B": "Adicionar ENI extra na instância privada não a transforma em NAT funcional.",
"D": "O Elastic IP deve estar na instância NAT pública, não nas instâncias da subnet privada."
}
},
{
"id": "dva-c02-development-194",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Você faz upload de um objeto para um bucket Amazon S3 na região US-STANDARD e recebe confirmação de sucesso. Em seguida, faz uma leitura imediata do objeto e recebe erro informando que ele não existe. O que explica esse comportamento em termos de modelo de consistência legado?",
"option_a": "US-STANDARD usa consistência eventual para alguns PUTs, podendo demorar até o objeto ficar legível.",
"option_b": "Objetos no S3 só ficam visíveis após replicação para uma segunda região.",
"option_c": "US-STANDARD impõe um delay de 1 segundo antes de tornar novos objetos legíveis.",
"option_d": "Você excedeu o limite de objetos no bucket; assim que o limite for aumentado, o objeto ficará visível.",
"correct_answers": ["A"],
"explanation_detailed": "No modelo mais antigo, a região US-Standard podia apresentar consistência eventual em algumas operações, causando janelas curtas em que a leitura não encontra o objeto recém-criado.",
"incorrect_explanations": {
"B": "S3 não exige replicação entre regiões para tornar o objeto legível.",
"C": "Não há delay fixo artificial de 1 segundo.",
"D": "Limite de objetos por bucket não é o fator para visibilidade imediata do objeto."
}
},
{
"id": "dva-c02-development-195",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Qual é o número máximo padrão de buckets Amazon S3 permitidos por conta AWS?",
"option_a": "100 por região.",
"option_b": "Não há limite.",
"option_c": "1.000.000 por conta.",
"option_d": "500 por conta.",
"option_e": "100 por conta.",
"correct_answers": ["E"],
"explanation_detailed": "Por padrão, cada conta AWS pode criar até 100 buckets S3. Esse limite pode ser aumentado via solicitação ao suporte, mas o default é 100 por conta.",
"incorrect_explanations": {
"A": "O limite padrão é por conta, não por região.",
"B": "Há sim um limite padrão de buckets.",
"C": "1.000.000 de buckets está muito acima do limite padrão.",
"D": "500 não é o limite padrão."
}
},
{
"id": "dva-c02-security-196",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais itens são necessários para permitir que uma aplicação em uma instância EC2 escreva dados em uma tabela DynamoDB sem armazenar chaves de acesso na instância? (Selecione DUAS)",
"option_a": "Criar um usuário IAM com permissão de escrita na tabela DynamoDB.",
"option_b": "Adicionar uma IAM Role a uma instância EC2 já em execução.",
"option_c": "Adicionar um usuário IAM a uma instância EC2 já em execução.",
"option_d": "Lançar uma instância EC2 com a IAM Role incluída na configuração de lançamento.",
"option_e": "Criar uma IAM Role com permissão de escrita na tabela DynamoDB.",
"option_f": "Lançar uma instância EC2 com o usuário IAM incluído na configuração de lançamento.",
"correct_answers": ["D", "E"],
"explanation_detailed": "O padrão é criar uma IAM Role com as permissões necessárias (E) e lançar a instância EC2 com essa role associada (D). Assim, a instância obtém credenciais temporárias automaticamente via instance profile, sem armazenar chaves.",
"incorrect_explanations": {
"A": "Usuário IAM exigiria chaves estáticas, o que o enunciado quer evitar.",
"B": "Não é possível anexar uma role nova a uma instância já em execução em todos os cenários mais antigos; a forma correta é associar a role no lançamento (ou usar mecanismos específicos posteriores).",
"C": "Usuário IAM não é anexado à instância; apenas suas chaves seriam usadas.",
"F": "Instância EC2 não é lançada com 'usuário IAM' embutido; isso não é um recurso da plataforma."
}
},
{
"id": "dva-c02-security-197",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais afirmações sobre a lógica de avaliação de políticas no AWS IAM são corretas? (Selecione DUAS)",
"option_a": "Por padrão, todas as requisições são negadas.",
"option_b": "Um allow explícito sobrescreve um deny explícito.",
"option_c": "Um allow explícito sobrescreve o deny padrão.",
"option_d": "Um deny explícito não sobrescreve um allow explícito.",
"option_e": "Por padrão, todas as requisições são permitidas.",
"correct_answers": ["A", "C"],
"explanation_detailed": "No IAM, tudo começa como deny implícito (A). Um allow explícito pode sobrescrever esse deny padrão (C). Porém, um deny explícito sempre tem precedência sobre qualquer allow.",
"incorrect_explanations": {
"B": "Deny explícito sempre vence; allow explícito não o sobrescreve.",
"D": "O contrário é verdadeiro: um deny explícito sobrescreve allow.",
"E": "O padrão não é permitir tudo; é negar tudo até que haja allow."
}
},
{
"id": "dva-c02-deployment-198",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Você tem uma VPC com uma subnet pública e três instâncias nela que conseguem acessar a Internet normalmente. Uma quarta instância é lançada na mesma subnet com o mesmo AMI e mesmo security group, mas não consegue ser acessada da Internet. O que deve ser feito?",
"option_a": "Implantar uma instância NAT na subnet pública.",
"option_b": "Modificar a tabela de rotas da subnet pública.",
"option_c": "Configurar um IP roteável publicamente no sistema operacional da quarta instância.",
"option_d": "Associar um Elastic IP à quarta instância.",
"correct_answers": ["D"],
"explanation_detailed": "Para que a instância em subnet pública seja acessível da Internet, ela precisa de um endereço IP público, normalmente via Elastic IP. As outras instâncias provavelmente já têm EIPs ou IPs públicos auto-atribuídos.",
"incorrect_explanations": {
"A": "NAT é usado para acesso de saída de subnets privadas, não para acesso de entrada à instância.",
"B": "A tabela de rotas já funciona para as outras instâncias; o problema é o IP público da nova instância.",
"C": "O IP público precisa ser atribuído no nível da AWS (EIP), não apenas no sistema operacional."
}
},
{
"id": "dva-c02-development-199",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Se uma mensagem é recuperada de uma fila Amazon SQS, por quanto tempo, por padrão, essa mensagem fica invisível para outros consumidores?",
"option_a": "0 segundos.",
"option_b": "1 hora.",
"option_c": "1 dia.",
"option_d": "Para sempre.",
"option_e": "30 segundos.",
"correct_answers": ["E"],
"explanation_detailed": "O visibility timeout padrão de uma fila SQS é 30 segundos. Durante esse período, a mensagem não é entregue a outros consumidores, a menos que o timeout seja alterado.",
"incorrect_explanations": {
"A": "Com 0 segundos, a mensagem poderia ser entregue repetidamente a múltiplos consumidores.",
"B": "1 hora não é o valor padrão.",
"C": "1 dia também não é o default.",
"D": "Mensagens não ficam invisíveis para sempre; isso quebraria a reentrega em caso de falha no processamento."
}
},
{
"id": "dva-c02-development-200",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Qual é o formato das mensagens de notificação estruturadas enviadas pelo Amazon SNS?",
"option_a": "Um objeto XML contendo Messageld, UnsubscribeURL, Subject, Message e outros valores.",
"option_b": "Um objeto JSON contendo Messageld, DuplicateFlag, Message e outros valores.",
"option_c": "Um objeto XML contendo Messageld, DuplicateFlag, Message e outros valores.",
"option_d": "Um objeto JSON contendo Messageld, UnsubscribeURL, Subject, Message e outros valores.",
"correct_answers": ["D"],
"explanation_detailed": "Quando o formato estruturado é usado, o SNS envia uma mensagem em JSON com campos como MessageId, UnsubscribeURL, Subject, Message e outros metadados.",
"incorrect_explanations": {
"A": "O formato padrão estruturado é JSON, não XML.",
"B": "DuplicateFlag não é parte do conjunto de campos padrão; além disso, o formato principal é JSON, mas com outros campos importantes.",
"C": "Combina XML com campos incorretos para o formato estruturado típico do SNS."
}
},
{
"id": "dva-c02-security-201",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Ao enviar um objeto para o Amazon S3, qual cabeçalho de requisição pode ser especificado explicitamente para criptografar os dados do objeto no lado do servidor?",
"option_a": "x-amz-storage-class.",
"option_b": "Content-MD5.",
"option_c": "x-amz-security-token.",
"option_d": "x-amz-server-side-encryption.",
"correct_answers": ["D"],
"explanation_detailed": "O cabeçalho x-amz-server-side-encryption indica ao S3 que o objeto deve ser criptografado no lado do servidor (SSE), usando o modo configurado, como SSE-S3 ou SSE-KMS.",
"incorrect_explanations": {
"A": "x-amz-storage-class define a classe de armazenamento (STANDARD, IA etc.), não a criptografia.",
"B": "Content-MD5 serve para integridade de dados, não para criptografia em repouso.",
"C": "x-amz-security-token é usado em credenciais temporárias do STS, não para ativar SSE."
}
},
{
"id": "dva-c02-deployment-202",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais das seguintes plataformas são suportadas pelo AWS Elastic Beanstalk? (Selecione DUAS)",
"option_a": "Apache Tomcat.",
"option_b": ".NET.",
"option_c": "IBM WebSphere.",
"option_d": "Oracle JBoss.",
"option_e": "Jetty.",
"correct_answers": ["A", "B"],
"explanation_detailed": "Elastic Beanstalk suporta nativamente plataformas como Apache Tomcat para aplicações Java e .NET para aplicações Microsoft, entre outras.",
"incorrect_explanations": {
"C": "IBM WebSphere não é uma plataforma gerenciada padrão do Elastic Beanstalk.",
"D": "JBoss (agora WildFly/EAP) não é oferecido como plataforma gerenciada nativa no Beanstalk.",
"E": "Jetty não está disponível como plataforma gerenciada padrão no Elastic Beanstalk."
}
},
{
"id": "dva-c02-deployment-203",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Qual trecho de código CloudFormation retorna a URL de um site balanceado por carga, criado com um recurso AWS::ElasticLoadBalancing::LoadBalancer chamado ElasticLoadBalancer?",
"option_a": "\"Fn::Join\": [ \"\", [ \"http://\", { \"Fn::GetAtt\": [ \"ElasticLoadBalancer\", \"DNSName\" ] } ] ].",
"option_b": "\"Fn::Join\": [ \"\", [ \"http://\", { \"Fn::GetAtt\": [ \"ElasticLoadBalancer\", \"Url\" ] } ] ].",
"option_c": "\"Fn::Join\": [ \"\", [ \"http://\", { \"Ref\": \"ElasticLoadBalancerUrl\" } ] ].",
"option_d": "\"Fn::Join\": [ \"\", [ \"http://\", { \"Ref\": \"ElasticLoadBalancer\", \"DNSName\" } ] ].",
"correct_answers": ["A"],
"explanation_detailed": "A propriedade correta para obter o endereço do Load Balancer é DNSName via Fn::GetAtt. Em seguida, Fn::Join concatena \"http://\" com esse DNS para formar a URL.",
"incorrect_explanations": {
"B": "\"Url\" não é um atributo válido do recurso ElasticLoadBalancing::LoadBalancer.",
"C": "Ref retorna o nome lógico ou o identificador do recurso, não o DNSName diretamente.",
"D": "Ref não aceita um segundo parâmetro como \"DNSName\"; atributos são obtidos via Fn::GetAtt."
}
},
{
"id": "dva-c02-security-204",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais recursos podem ser usados para restringir o acesso a dados em um bucket S3? (Selecione DUAS)",
"option_a": "Usar S3 Virtual Hosting.",
"option_b": "Definir uma bucket policy no S3.",
"option_c": "Habilitar IAM Identity Federation.",
"option_d": "Definir ACLs de S3 no bucket ou no objeto.",
"option_e": "Criar uma distribuição CloudFront para o bucket.",
"correct_answers": ["B", "D"],
"explanation_detailed": "Policies de bucket e ACLs de bucket/objeto são os mecanismos nativos do S3 para controlar quem pode acessar quais recursos, permitindo regras granulares de permissão.",
"incorrect_explanations": {
"A": "Virtual hosting altera o formato do endpoint, não controla autorização.",
"C": "Identity Federation ajuda a autenticar identidades, mas não é o mecanismo direto de restrição no S3.",
"E": "CloudFront pode restringir via signed URLs/headers, mas a pergunta foca em recursos de controle diretamente no S3."
}
},
{
"id": "dva-c02-deployment-205",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Por padrão, o que acontece quando um dos recursos em um stack AWS CloudFormation não pode ser criado?",
"option_a": "Os recursos já criados são mantidos, mas a criação do stack é encerrada.",
"option_b": "Os recursos já criados são excluídos e a criação do stack é encerrada.",
"option_c": "A criação do stack continua e o resultado final indica quais etapas falharam.",
"option_d": "Os templates são analisados antecipadamente, então a criação do stack é sempre bem-sucedida.",
"correct_answers": ["B"],
"explanation_detailed": "Por padrão, o CloudFormation realiza rollback: se algum recurso falhar, ele exclui os recursos já criados e marca o stack como ROLLBACK_COMPLETE ou ROLLBACK_FAILED.",
"incorrect_explanations": {
"A": "Manter recursos parcialmente criados pode deixar o ambiente inconsistente; não é o comportamento padrão.",
"C": "A criação não prossegue ignorando falhas; o stack entra em rollback.",
"D": "Templates podem ter erros de tempo de execução e dependências; não há garantia de sucesso automático."
}
},
{
"id": "dva-c02-development-206",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 3,
"active": true,
"question_text": "Quais dos seguintes são argumentos válidos em uma chamada Publish do Amazon SNS? (Selecione TRÊS)",
"option_a": "TopicArn.",
"option_b": "Subject.",
"option_c": "Destination.",
"option_d": "Format.",
"option_e": "Message.",
"option_f": "Language.",
"correct_answers": ["A", "B", "E"],
"explanation_detailed": "A API Publish do SNS utiliza parâmetros como TopicArn (ou TargetArn), Message (conteúdo) e Subject (título) para publicar notificações em tópicos ou endpoints.",
"incorrect_explanations": {
"C": "\"Destination\" não é um parâmetro da chamada Publish; o destino é indicado por TopicArn/TargetArn/PhoneNumber.",
"D": "Não existe parâmetro \"Format\" na API Publish.",
"F": "A chamada Publish não define idioma com um parâmetro Language."
}
},
{
"id": "dva-c02-development-207",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Como um software pode descobrir os endereços IP público e privado da instância Amazon EC2 em que está sendo executado?",
"option_a": "Consultando a métrica apropriada no Amazon CloudWatch.",
"option_b": "Usando os comandos ipconfig ou ifconfig no sistema operacional.",
"option_c": "Consultando a userdata local da instância.",
"option_d": "Consultando a metadata local da instância.",
"correct_answers": ["D"],
"explanation_detailed": "A instância EC2 expõe um endpoint de metadata (http://169.254.169.254/latest/meta-data/) que permite obter programaticamente IP privado e público, entre outras informações.",
"incorrect_explanations": {
"A": "CloudWatch não é a forma recomendada para que a própria instância descubra seus IPs.",
"B": "Comandos de SO funcionam, mas não são a abordagem programática padronizada da AWS para scripts e apps.",
"C": "Userdata é conteúdo definido pelo usuário, não um repositório de informações de rede da instância."
}
},
{
"id": "dva-c02-development-208",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Instâncias EC2 são lançadas a partir de Amazon Machine Images (AMIs). Uma AMI pública pode:",
"option_a": "Ser usada para lançar instâncias em qualquer região AWS.",
"option_b": "Ser usada apenas na mesma país em que a AMI está armazenada.",
"option_c": "Ser usada apenas na mesma região AWS em que a AMI está armazenada.",
"option_d": "Ser usada apenas na mesma Availability Zone em que a AMI está armazenada.",
"correct_answers": ["C"],
"explanation_detailed": "AMIs são recursos regionais; uma AMI pública só pode ser usada para lançar instâncias dentro da mesma região em que foi criada ou copiada.",
"incorrect_explanations": {
"A": "Para usar em outra região, é preciso copiar a AMI explicitamente para lá.",
"B": "A AWS não segmenta uso de AMI por país, e sim por região.",
"D": "A AMI não é restrita a uma única AZ; ela é visível em todas as AZs da região."
}
},
{
"id": "dva-c02-development-209",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Qual chamada de API do EC2 é usada para recuperar uma lista de Amazon Machine Images (AMIs)?",
"option_a": "DescribeInstances.",
"option_b": "DescribeAMIs.",
"option_c": "DescribeImages.",
"option_d": "GetAMIs.",
"option_e": "Não é possível recuperar a lista de AMIs porque existem muitas.",
"correct_answers": ["C"],
"explanation_detailed": "A chamada DescribeImages é a API correta para listar e filtrar AMIs na conta ou AMIs públicas disponíveis.",
"incorrect_explanations": {
"A": "DescribeInstances retorna informações de instâncias em execução ou encerradas, não de AMIs.",
"B": "DescribeAMIs não é um nome de API válido.",
"D": "GetAMIs não é uma chamada de API do EC2.",
"E": "É possível sim listar AMIs com filtros usando DescribeImages."
}
},
{
"id": "dva-c02-security-210",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 4,
"active": true,
"question_text": "Na AWS, quais aspectos de segurança são responsabilidade do cliente? (Selecione QUATRO)",
"option_a": "Gerenciar o ciclo de vida das credenciais IAM.",
"option_b": "Descomissionar dispositivos de armazenamento físicos.",
"option_c": "Configurar Security Groups e ACLs (listas de controle de acesso).",
"option_d": "Criptografar volumes EBS.",
"option_e": "Controlar o acesso físico aos recursos de computação.",
"option_f": "Fazer patch management do sistema operacional das instâncias EC2.",
"correct_answers": ["A", "C", "D", "F"],
"explanation_detailed": "Pelo modelo de responsabilidade compartilhada, o cliente gerencia identidades IAM, configura SGs/ACLs, decide e implementa criptografia de EBS e aplica patches no SO das instâncias. A AWS cuida da segurança da infraestrutura física e do descarte de mídia.",
"incorrect_explanations": {
"B": "O descomissionamento seguro dos dispositivos físicos é responsabilidade da AWS.",
"E": "O controle de acesso físico aos datacenters é responsabilidade da AWS, não do cliente."
}
},
{
"id": "dva-c02-development-211",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Ao usar uma operação Scan grande em uma tabela DynamoDB, qual técnica pode minimizar o impacto no throughput provisionado da tabela?",
"option_a": "Definir um page size menor para o Scan.",
"option_b": "Usar parallel scans.",
"option_c": "Definir um range index na tabela.",
"option_d": "Preaquecer a tabela atualizando todos os itens.",
"correct_answers": ["A"],
"explanation_detailed": "Reduzir o tamanho da página limita a quantidade de itens retornados por chamada, espalhando o consumo de RCUs ao longo do tempo e diminuindo o impacto de cada requisição de Scan.",
"incorrect_explanations": {
"B": "Parallel scans aumentam o consumo de throughput, não o reduzem.",
"C": "Criar índices não garante redução de impacto em um Scan grande na tabela base.",
"D": "Atualizar todos os itens só aumentaria ainda mais o consumo de throughput de gravação."
}
},
{
"id": "dva-c02-security-212",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Como você pode proteger dados em repouso em um volume Amazon EBS?",
"option_a": "Anexando o volume à instância usando a interface SSL do EC2.",
"option_b": "Gravando os dados de forma aleatória em vez de sequencial.",
"option_c": "Usando um sistema de arquivos criptografado sobre o volume EBS.",
"option_d": "Criptografando o volume usando o serviço de criptografia do S3.",
"option_e": "Criando uma IAM policy que restringe acesso de leitura/escrita ao volume.",
"correct_answers": ["C"],
"explanation_detailed": "Uma abordagem clássica é usar um sistema de arquivos criptografado (como LUKS, BitLocker etc.) sobre o EBS, garantindo que os dados em repouso sejam armazenados criptografados no volume.",
"incorrect_explanations": {
"A": "SSL protege o tráfego de rede, não os dados armazenados em disco.",
"B": "Escrever aleatoriamente não garante confidencialidade dos dados.",
"D": "A criptografia do S3 não se aplica diretamente a volumes EBS.",
"E": "Políticas IAM controlam quem gerencia o recurso, não criptografam fisicamente os dados."
}
},
{
"id": "dva-c02-development-213",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Qual região é escolhida por padrão ao fazer uma chamada de API com um AWS SDK, caso nenhuma região seja explicitamente configurada?",
"option_a": "ap-northeast-1.",
"option_b": "us-west-2.",
"option_c": "us-east-1.",
"option_d": "eu-west-1.",
"option_e": "us-central-1.",
"correct_answers": ["C"],
"explanation_detailed": "Historicamente, muitos SDKs da AWS usam us-east-1 como região padrão quando nenhuma outra é especificada na configuração.",
"incorrect_explanations": {
"A": "ap-northeast-1 não é o default padrão dos SDKs.",
"B": "us-west-2 não é, em geral, a região implícita padrão.",
"D": "eu-west-1 não é usada como default pelos SDKs.",
"E": "us-central-1 nem é uma região válida na nomenclatura da AWS."
}
},
{
"id": "dva-c02-development-214",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 3,
"active": true,
"question_text": "Quais das seguintes afirmações sobre o Amazon SWF são verdadeiras? (Selecione TRÊS)",
"option_a": "Tarefas SWF são atribuídas uma vez e nunca duplicadas.",
"option_b": "SWF requer um bucket S3 para armazenar workflows.",
"option_c": "Execuções de workflow SWF podem durar até um ano.",
"option_d": "SWF aciona notificações SNS automaticamente ao atribuir tarefas.",
"option_e": "SWF usa deciders e workers para completar tarefas.",
"option_f": "SWF requer pelo menos uma instância EC2 por domínio.",
"correct_answers": ["A", "C", "E"],
"explanation_detailed": "SWF garante que uma tarefa seja entregue para um worker de cada vez (A), permite workflows de longa duração de até 1 ano (C) e segue o padrão de deciders e workers para orquestrar e executar tarefas (E).",
"incorrect_explanations": {
"B": "SWF não exige um bucket S3 dedicado para armazenamento de workflows.",
"D": "SWF pode ser integrado ao SNS, mas não dispara notificações SNS automaticamente em toda atribuição de tarefa.",
"F": "Não há exigência de uma instância EC2 por domínio; workers podem ser executados onde for adequado."
}
},
{
"id": "dva-c02-monitoring-215",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma startup tem um site de compartilhamento de fotos em uma VPC. Um ELB distribui tráfego web por duas subnets, com stickiness usando cookie do próprio ELB. Um teste de carga é feito a partir de uma única instância EC2 em us-west-2. Após 60 minutos, os logs indicam que o tráfego não está sendo distribuído igualmente entre os servidores. Quais recomendações ajudam a garantir que as requisições HTTP de teste sejam distribuídas de forma mais uniforme? (Selecione DUAS)",
"option_a": "Lançar e executar a instância de teste de carga a partir de us-east-1.",
"option_b": "Reconfigurar o software de teste de carga para resolver novamente o DNS a cada requisição web.",
"option_c": "Usar um serviço de teste de carga de terceiros com clientes de teste distribuídos globalmente.",
"option_d": "Configurar o ELB e o Auto Scaling para distribuir entre us-west-2a e us-west-2c.",
"option_e": "Configurar a stickiness do ELB para usar o cookie de sessão específico da aplicação.",
"correct_answers": ["B", "C"],
"explanation_detailed": "Re-resolver o DNS do ELB a cada requisição evita que o load tester fique preso a um único IP de backend (B). Usar clientes de teste distribuídos globalmente (C) também ajuda a simular distribuição real de tráfego e explorar melhor o balanceamento.",
"incorrect_explanations": {
"A": "Mover a instância de teste para outra região não resolve o problema de resolução de DNS e stickiness.",
"D": "Distribuição entre AZs já é prática recomendada, mas o gargalo aqui é o padrão de requisições do teste, não as AZs.",
"E": "Mais stickiness ainda agrava o problema de ficar colado em poucos servidores."
}
},
{
"id": "dva-c02-development-216",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Quais dos seguintes são transports de entrega válidos para o Amazon SNS? (Selecione DUAS)",
"option_a": "HTTP.",
"option_b": "UDP.",
"option_c": "SMS.",
"option_d": "DynamoDB.",
"option_e": "Named Pipes.",
"correct_answers": ["A", "C"],
"explanation_detailed": "O SNS suporta entrega de notificações para endpoints HTTP/HTTPS, e também para SMS, entre outros (como e-mail e SQS).",
"incorrect_explanations": {
"B": "UDP não é um transport suportado pelo SNS.",
"D": "DynamoDB não é um transport de entrega de mensagens SNS.",
"E": "Named Pipes não são suportadas como destino de entrega SNS."
}
},
{
"id": "dva-c02-development-217",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "A empresa C lançou um site de comércio eletrônico de bicicletas usando uma tabela DynamoDB Product com atributos como fabricante, cor, preço, quantidade e tamanho. Agora deseja incluir uma imagem para cada bicicleta com o menor impacto possível no throughput provisionado da tabela. Qual abordagem é mais adequada?",
"option_a": "Serializar a imagem e armazená-la em várias tabelas DynamoDB.",
"option_b": "Criar uma tabela DynamoDB Images para armazenar a imagem, com chave estrangeira para Product.",
"option_c": "Adicionar um atributo de imagem binária à tabela Product e armazenar a imagem em formato binário.",
"option_d": "Armazenar as imagens no Amazon S3 e adicionar à tabela Product um atributo com a URL do objeto S3.",
"correct_answers": ["D"],
"explanation_detailed": "Guardar as imagens no S3 e apenas referenciar a URL na tabela Product mantém os itens DynamoDB leves e reduz o consumo de throughput, aproveitando o S3 para armazenar objetos binários grandes de forma escalável e barata.",
"incorrect_explanations": {
"A": "Replicar imagens em múltiplas tabelas aumentaria o consumo de throughput e a complexidade.",
"B": "Outra tabela DynamoDB ainda teria que armazenar binários grandes, impactando throughput de forma semelhante.",
"C": "Armazenar a imagem binária diretamente na tabela Product aumentaria o tamanho dos itens e o custo de leitura/gravação."
}
},
{
"id": "dva-c02-monitoring-218",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor criou uma função AWS Lambda para o backend de um aplicativo web. Ao testar a função no console do Lambda, o desenvolvedor vê que a função está sendo executada, mas nenhum log aparece no Amazon CloudWatch Logs, mesmo após vários minutos. O que poderia estar causando essa situação?",
"option_a": "A função Lambda não possui instruções de log explícitas no código para enviar dados ao CloudWatch Logs.",
"option_b": "A função Lambda está sem o CloudWatch Logs configurado como gatilho de origem para enviar os logs.",
"option_c": "A função de execução (execution role) da função Lambda não tem permissões para gravar logs no CloudWatch Logs.",
"option_d": "A função Lambda está sem um grupo de logs de destino configurado no CloudWatch Logs.",
"correct_answers": ["C"],
"explanation_detailed": "Para que uma função Lambda grave logs no CloudWatch Logs, a IAM role de execução precisa ter a política que permite criar grupos e streams de log e chamar logs:PutLogEvents. Se essas permissões estiverem ausentes, a função será executada, mas nenhum log será enviado ao CloudWatch Logs.",
"incorrect_explanations": {
"A": "Mesmo sem chamadas explícitas de log do desenvolvedor, o runtime do Lambda ainda gera logs mínimos (por exemplo, erros) se tiver permissão.",
"B": "CloudWatch Logs não é configurado como \"fonte de trigger\"; é um destino de logs gerenciado pela própria integração do Lambda.",
"D": "O grupo de logs é criado automaticamente pelo próprio serviço quando a função tem permissões adequadas."
}
},
{
"id": "dva-c02-monitoring-219",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor quer usar o AWS X-Ray para rastrear uma requisição de usuário de ponta a ponta em toda a stack. O desenvolvedor ajustou o código e verificou que a aplicação consegue enviar traces para o X-Ray em ambiente local. Entretanto, quando a aplicação é implantada em uma instância Amazon EC2, os traces não aparecem no X-Ray. Quais das seguintes situações podem estar causando esse problema? (Selecione DUAS opções)",
"option_a": "Os traces estão chegando ao X-Ray, mas o desenvolvedor não tem permissão para visualizá-los.",
"option_b": "O daemon do X-Ray não está instalado na instância EC2.",
"option_c": "O endpoint do X-Ray configurado na aplicação está incorreto.",
"option_d": "A role da instância não tem permissões xray:BatchGetTraces e xray:GetTraceGraph.",
"option_e": "A role da instância não tem permissões xray:PutTraceSegments e xray:PutTelemetryRecords.",
"correct_answers": ["B", "E"],
"explanation_detailed": "Para que uma aplicação em EC2 envie traces ao X-Ray, é necessário que o daemon do X-Ray esteja em execução na instância e que a IAM role anexada tenha permissões para enviar segmentos e telemetria (xray:PutTraceSegments e xray:PutTelemetryRecords). Sem o daemon ou essas permissões, nenhum trace chegará ao serviço.",
"incorrect_explanations": {
"A": "Se fosse apenas falta de permissão de leitura, os traces estariam no serviço, mas invisíveis. O cenário descreve ausência completa de traces.",
"C": "Um endpoint incorreto é possível, mas não é o motivo mais comum nesse tipo de cenário em EC2; o problema clássico é daemon ausente e permissões de envio.",
"D": "Essas permissões controlam leitura de traces já armazenados no X-Ray, não o envio inicial a partir da instância."
}
},
{
"id": "dva-c02-security-220",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação tem centenas de usuários, e cada usuário pode acessar o aplicativo a partir de vários dispositivos diferentes. O desenvolvedor quer atribuir identificadores únicos a esses usuários, independentemente do dispositivo usado. Qual método deve ser utilizado para obter identificadores únicos por usuário?",
"option_a": "Criar uma tabela de usuários no Amazon DynamoDB com pares de chave-valor de usuários e seus dispositivos e usar essas chaves como identificadores únicos.",
"option_b": "Usar IDs de access keys geradas pelo IAM como identificador único, mas sem armazenar as secret keys.",
"option_c": "Implementar identidades autenticadas pelo desenvolvedor com o Amazon Cognito e obter credenciais para essas identidades.",
"option_d": "Criar usuários e roles IAM para cada usuário da aplicação e usar o ID de recurso do IAM como identificador.",
"correct_answers": ["C"],
"explanation_detailed": "As identidades autenticadas pelo desenvolvedor no Amazon Cognito permitem mapear usuários finais para identidades únicas, independentes do dispositivo, e emitir credenciais temporárias seguras. Isso resolve o problema de identificar o usuário de forma consistente em todos os dispositivos.",
"incorrect_explanations": {
"A": "Gerenciar IDs manualmente em uma tabela DynamoDB aumenta a complexidade e não aproveita os recursos nativos de identidade da AWS.",
"B": "Access keys IAM são credenciais de longa duração e não devem ser usadas como IDs de usuário de aplicação.",
"D": "IAM é destinado a identities de conta AWS (admins, serviços), não para milhões de usuários finais de aplicativo."
}
},
{
"id": "dva-c02-deployment-221",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Quais são os passos corretos para usar a AWS CLI para empacotar e fazer deploy de uma aplicação serverless baseada em template do AWS CloudFormation (como um template AWS SAM)?",
"option_a": "Usar o comando aws cloudformation get-template e depois cloudformation execute-change-set.",
"option_b": "Usar o comando aws cloudformation validate-template e depois cloudformation create-change-set.",
"option_c": "Usar o comando aws cloudformation package e depois cloudformation deploy.",
"option_d": "Usar o comando aws cloudformation create-stack e depois cloudformation update-stack diretamente com o código local.",
"correct_answers": ["C"],
"explanation_detailed": "O fluxo recomendado é usar aws cloudformation package para empacotar o código (fazendo upload para o S3 e reescrevendo o template com URIs) e, em seguida, aws cloudformation deploy para criar ou atualizar a stack baseada nesse template empacotado.",
"incorrect_explanations": {
"A": "get-template e execute-change-set não empacotam artefatos locais; são usados em fluxos diferentes.",
"B": "validate-template apenas valida sintaxe, sem empacotar nem implantar recursos.",
"D": "create-stack e update-stack exigem que os artefatos já estejam acessíveis no S3; não fazem o empacotamento automático."
}
},
{
"id": "dva-c02-security-222",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um pacote de deployment usa a AWS CLI para copiar arquivos para qualquer bucket S3 na conta, usando access keys armazenadas em variáveis de ambiente. As instâncias EC2 que executam o pacote foram modificadas para usar uma IAM role assumida com uma política mais restritiva, permitindo acesso apenas a um bucket específico. Após a mudança, o desenvolvedor faz login na instância e ainda consegue gravar em todos os buckets S3 da conta. Qual é a causa MAIS provável disso?",
"option_a": "Está sendo usada uma política inline na IAM role.",
"option_b": "Está sendo usada uma política gerenciada na IAM role.",
"option_c": "A instalação da AWS CLI está corrompida e precisa ser reinstalada.",
"option_d": "O AWS credential provider ainda está encontrando as credenciais de ambiente antes das credenciais da instance profile role.",
"correct_answers": ["D"],
"explanation_detailed": "A cadeia de providers de credenciais da AWS verifica variáveis de ambiente antes de usar credenciais de profile de instância. Como as access keys antigas ainda estão definidas nas variáveis de ambiente, a CLI continua usando essa credencial ampla, ignorando a IAM role mais restritiva.",
"incorrect_explanations": {
"A": "Políticas inline não explicam por que credenciais antigas ainda estão sendo usadas.",
"B": "Políticas gerenciadas também não interferem na ordem de resolução de credenciais.",
"C": "Não há indicação de problema na instalação da CLI, e sim na origem das credenciais utilizadas."
}
},
{
"id": "dva-c02-development-223",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação sobrescreve um objeto em um bucket Amazon S3 e, em seguida, lê o mesmo objeto imediatamente. Por que a aplicação às vezes recupera a versão antiga do objeto?",
"option_a": "Operações de sobrescrita (overwrite PUT) em S3 são eventualmente consistentes, então a aplicação pode ler o objeto antigo por algum tempo.",
"option_b": "A aplicação precisa adicionar metadados extras para marcar a versão mais recente antes de fazer o upload no S3.",
"option_c": "Todas as operações PUT no S3 são eventualmente consistentes, então a aplicação sempre pode ler versões antigas.",
"option_d": "A aplicação precisa especificar explicitamente a versão mais recente ao recuperar o objeto.",
"correct_answers": ["A"],
"explanation_detailed": "Para operações de sobrescrita e delete, o Amazon S3 oferece consistência eventual na leitura. Isso significa que, logo após uma sobrescrita, algumas leituras ainda podem retornar a versão anterior do objeto até que a atualização se propague.",
"incorrect_explanations": {
"B": "Metadados não controlam o mecanismo de consistência do S3.",
"C": "Criação de novos objetos (PUT de novas chaves) é fortemente consistente; o comportamento eventual está ligado a sobrescritas e deletes.",
"D": "Versões são gerenciadas pelo próprio S3; não é obrigatório usar versionamento ou especificar versão para ter o comportamento esperado."
}
},
{
"id": "dva-c02-security-224",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação em desenvolvimento precisa armazenar centenas de arquivos de vídeo. Os dados devem ser criptografados dentro da aplicação antes do armazenamento, com uma chave única para cada arquivo. Como o desenvolvedor deve implementar essa criptografia usando AWS KMS?",
"option_a": "Usar a API KMS Encrypt diretamente para criptografar os dados e armazenar os dados criptografados.",
"option_b": "Usar uma biblioteca de criptografia para gerar uma chave única para a aplicação, criptografar os dados e armazenar os dados criptografados.",
"option_c": "Usar a API KMS GenerateDataKey para obter uma data key, criptografar os dados com essa chave e armazenar juntos o dado criptografado e a data key criptografada.",
"option_d": "Fazer upload dos dados para um bucket S3 usando criptografia no lado do servidor com uma CMK do KMS.",
"correct_answers": ["C"],
"explanation_detailed": "O padrão de envelope encryption com KMS é usar GenerateDataKey para obter uma data key em texto claro e a mesma chave criptografada pela CMK. A aplicação usa a chave em texto claro para criptografar o arquivo localmente e armazena o arquivo criptografado junto com a data key criptografada, permitindo descriptografia posterior usando o KMS.",
"incorrect_explanations": {
"A": "Encrypt espera payloads relativamente pequenos; não é eficiente nem recomendado para criptografar arquivos grandes diretamente.",
"B": "Gerar e gerenciar chaves mestres na aplicação aumenta responsabilidade de segurança e não aproveita os controles e auditoria do KMS.",
"D": "SSE com KMS criptografa no lado do servidor; o requisito diz que os dados devem ser criptografados na aplicação, antes do envio."
}
},
{
"id": "dva-c02-development-225",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está testando uma aplicação que invoca uma função AWS Lambda de forma assíncrona. Durante os testes, a função Lambda falha ao processar mesmo após duas tentativas de retry. Como o desenvolvedor pode investigar e solucionar essas falhas de forma mais eficaz?",
"option_a": "Configurar o AWS CloudTrail para registrar detalhes das falhas de invocação e usá-lo para investigar o problema.",
"option_b": "Configurar uma Dead Letter Queue (DLQ) enviando os eventos para uma fila Amazon SQS para análise posterior.",
"option_c": "Configurar o Amazon Simple Workflow Service (SWF) para processar eventos que não foram processados diretamente.",
"option_d": "Configurar o AWS Config para capturar quaisquer eventos não processados diretamente.",
"correct_answers": ["B"],
"explanation_detailed": "Para invocações assíncronas, o Lambda suporta Dead Letter Queues (DLQ) usando SQS ou SNS. Se a função falhar após as tentativas de retry, o evento pode ser enviado para a fila SQS, onde o desenvolvedor consegue inspecionar os payloads problemáticos e depurar a causa.",
"incorrect_explanations": {
"A": "CloudTrail registra chamadas de API, não o conteúdo de eventos nem o payload que falhou dentro da função Lambda.",
"C": "SWF é um orquestrador de workflows, não o mecanismo padrão para tratar eventos que falharam em uma invocação assíncrona do Lambda.",
"D": "AWS Config monitora configuração de recursos, não eventos de falha de execução de funções."
}
},
{
"id": "dva-c02-development-226",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está configurando o Amazon API Gateway para APIs que serão usadas por desenvolvedores registrados. A empresa quer limitar a quantidade de requisições que cada usuário pode enviar, por motivos de custo e segurança, e também vender planos com cotas maiores. Como o desenvolvedor pode implementar isso com o MENOR esforço operacional?",
"option_a": "Habilitar throttling no stage do API Gateway, definir taxa e burst para cada usuário e criar um stage separado por plano.",
"option_b": "Habilitar logs do API Gateway no Amazon CloudWatch, criar filtros por usuário e acionar uma função Lambda quando o limite for atingido.",
"option_c": "Criar alarmes no Amazon CloudWatch baseados na métrica Count do API Gateway e negar o acesso quando o limite for atingido.",
"option_d": "Criar um usage plan padrão com limites de taxa e burst e associá-lo a um stage. Para usuários com planos maiores, criar usage plans específicos e associá-los aos API keys desses usuários.",
"correct_answers": ["D"],
"explanation_detailed": "Usage plans do API Gateway foram feitos exatamente para isso: vincular API keys a limites de consumo (throttling e quotas). É simples gerenciar diferentes planos e associar usuários a planos diferentes sem criar múltiplos stages ou lógica manual.",
"incorrect_explanations": {
"A": "Criar stages separados por usuário ou plano escala muito mal e adiciona complexidade desnecessária.",
"B": "Montar lógica manual com logs e Lambda é mais complexo e menos confiável que usar usage plans nativos.",
"C": "CloudWatch Alarms não são feitos para impor limites em tempo real, e negar acesso via alarme não é uma mecânica real de bloqueio de chamadas pelo API Gateway."
}
},
{
"id": "dva-c02-development-227",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está refatorando uma aplicação monolítica. O endpoint HTTP de POST executa várias operações, algumas em paralelo e outras sequenciais. Essas operações foram convertidas em funções AWS Lambda individuais. O POST continuará exposto via Amazon API Gateway. Como o desenvolvedor deve orquestrar essas funções Lambda na mesma sequência de forma gerenciável?",
"option_a": "Usar o Amazon SQS para invocar as funções Lambda em cadeia.",
"option_b": "Usar uma activity do AWS Step Functions para executar as funções Lambda.",
"option_c": "Usar o Amazon SNS para disparar as funções Lambda.",
"option_d": "Usar uma state machine do AWS Step Functions para orquestrar as funções Lambda.",
"correct_answers": ["D"],
"explanation_detailed": "O AWS Step Functions permite modelar fluxos complexos com execução sequencial, paralela, tratamento de erros e timeouts, tudo por meio de uma state machine declarativa. É a opção ideal para orquestrar múltiplas funções Lambda que substituem um fluxo monolítico.",
"incorrect_explanations": {
"A": "SQS é ótimo para desacoplamento assíncrono, mas não oferece orquestração declarativa nem controles de fluxo complexos por si só.",
"B": "Activities são usadas para workers externos; aqui o objetivo é orquestrar Lambdas diretamente.",
"C": "SNS é fan-out de eventos, não um orquestrador que cuide de ordem, paralelismo e retries estruturados."
}
},
{
"id": "dva-c02-development-228",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma empresa está adicionando funcionalidade de créditos (gift cards) a um jogo online. Usuários podem trocar créditos entre si, exigindo que a atualização do saldo de ambos ocorra como uma única transação (tudo ou nada). Quais opções de banco de dados AWS podem fornecer essa capacidade transacional para essa funcionalidade? (Selecione DUAS opções)",
"option_a": "Amazon DynamoDB com operações usando o parâmetro ConsistentRead configurado como true.",
"option_b": "Amazon ElastiCache for Memcached com operações dentro de um bloco transacional.",
"option_c": "Amazon Aurora MySQL com operações executadas dentro de um bloco de transação.",
"option_d": "Amazon DynamoDB com operações de leitura e escrita usando as operações Transact*.",
"option_e": "Amazon Redshift com operações dentro de um bloco de transação.",
"correct_answers": ["C", "D"],
"explanation_detailed": "Amazon Aurora MySQL oferece transações ACID tradicionais, permitindo atualizar várias linhas de forma atômica. Já o DynamoDB fornece transações nativas por meio das operações TransactGetItems e TransactWriteItems, garantindo all-or-nothing entre múltiplos itens.",
"incorrect_explanations": {
"A": "ConsistentRead garante consistência de leitura, não atomicidade entre múltiplas atualizações de itens.",
"B": "ElastiCache Memcached não oferece transações ACID entre múltiplas chaves de forma nativa.",
"E": "Redshift é voltado para data warehousing e não é a escolha ideal para workloads transacionais de alta frequência em aplicações OLTP."
}
},
{
"id": "dva-c02-development-229",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está criando uma função AWS Lambda que gera um novo arquivo toda vez que é executada. Cada novo arquivo deve ser versionado em um repositório AWS CodeCommit no mesmo account. Como o desenvolvedor deve fazer isso a partir da função Lambda?",
"option_a": "No início da função, usar o Git CLI para clonar o repositório, adicionar o arquivo e fazer push das alterações.",
"option_b": "Após criar o arquivo, usar cURL para chamar diretamente a API do CodeCommit e enviar o arquivo.",
"option_c": "Usar um SDK da AWS para instanciar um cliente do CodeCommit e chamar o método put_file para adicionar o arquivo ao repositório.",
"option_d": "Fazer upload do arquivo para um bucket S3 e usar uma Step Function para adicionar o arquivo ao repositório.",
"correct_answers": ["C"],
"explanation_detailed": "O método put_file da API do CodeCommit foi projetado justamente para adicionar ou atualizar arquivos em um repositório de forma programática. Usá-lo por meio de um SDK dentro da função Lambda é o caminho mais simples e suportado.",
"incorrect_explanations": {
"A": "Executar Git CLI dentro do Lambda adiciona complexidade, requer binários extras e não é a abordagem recomendada.",
"B": "Fazer cURL manual para a API do CodeCommit é possível, mas muito mais sujeito a erros do que usar o SDK oficial.",
"D": "Introduzir S3 e Step Functions nesse fluxo é desnecessário e aumenta a complexidade sem benefício real."
}
},
{
"id": "dva-c02-security-230",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor precisa garantir que as credenciais IAM usadas por uma aplicação em instâncias Amazon EC2 não sejam abusadas ou comprometidas. Qual é a abordagem MAIS segura para fornecer essas credenciais à aplicação?",
"option_a": "Armazenar as credenciais em variáveis de ambiente na instância EC2.",
"option_b": "Armazenar as credenciais em um arquivo de credenciais na instância EC2.",
"option_c": "Usar credenciais de profile de instância por meio de uma IAM role anexada às instâncias (instance profile credentials).",
"option_d": "Passar as credenciais como parâmetros de linha de comando para o processo da aplicação.",
"correct_answers": ["C"],
"explanation_detailed": "A prática recomendada é anexar uma IAM role às instâncias (instance profile). O código então obtém credenciais temporárias automaticamente através do metadata service, sem necessidade de armazenar chaves estáticas em disco ou em variáveis de ambiente.",
"incorrect_explanations": {
"A": "Variáveis de ambiente são fáceis de vazar em logs ou dumps de processo e são consideradas armazenamento de credencial em texto claro.",
"B": "Arquivos de credenciais exigem rotação manual e proteção rigorosa de disco; é mais frágil do que usar roles.",
"D": "Passar credenciais na linha de comando é inseguro, pois podem aparecer em históricos ou ferramentas de monitoramento de processos."
}
},
{
"id": "dva-c02-security-231",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma aplicação lê objetos de um bucket Amazon S3 com base no tipo de usuário: usuário registrado e usuário convidado. A empresa tem 25.000 usuários e esse número está crescendo. Os objetos são os mesmos, mas o nível de acesso varia por tipo. Quais abordagens são recomendadas para fornecer acesso a ambos os tipos de usuário de forma escalável? (Selecione DUAS opções)",
"option_a": "Fornecer pares de access key e secret para usuários registrados e convidados no código da aplicação.",
"option_b": "Usar políticas de bucket S3 para restringir leitura a usuários IAM específicos.",
"option_c": "Usar o Amazon Cognito para fornecer acesso com roles autenticadas e não autenticadas.",
"option_d": "Criar um usuário IAM para cada usuário final e conceder acesso de leitura.",
"option_e": "Usar o AWS IAM e permitir que a aplicação assuma roles diferentes usando AWS STS AssumeRole, com acesso de leitura ao S3 de acordo com o tipo de usuário.",
"correct_answers": ["C", "E"],
"explanation_detailed": "O Amazon Cognito permite mapear usuários autenticados e convidados para roles diferentes, com políticas específicas. Alternativamente, a aplicação pode usar STS AssumeRole para assumir roles com diferentes permissões de leitura, dependendo do tipo de usuário, sem expor credenciais fixas.",
"incorrect_explanations": {
"A": "Embutir access keys no código é uma péssima prática de segurança e não escala para dezenas de milhares de usuários.",
"B": "Políticas de bucket baseadas em usuários IAM não escalam bem quando se trata de muitos usuários finais.",
"D": "Criar um usuário IAM por usuário final viola as melhores práticas e gera grande sobrecarga operacional."
}
},
{
"id": "dva-c02-security-232",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "hard",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa possui 25.000 funcionários e está criando uma aplicação cujo back-end usa Amazon S3 para imagens e Amazon RDS para dados. A empresa exige que todas as informações de funcionários permaneçam apenas no diretório corporativo SAML legado, sem replicar identidades na AWS. Como o desenvolvedor pode fornecer acesso autorizado para que cada funcionário acesse apenas seus próprios dados na aplicação?",
"option_a": "Usar uma VPC e manter todos os recursos dentro dela, usando um VPC endpoint para o S3 com política de bucket.",
"option_b": "Usar Amazon Cognito user pools federado com o provedor SAML e usar grupos do user pool com políticas IAM.",
"option_c": "Usar um Amazon Cognito identity pool federado com o provedor SAML e uma condição de IAM com a chave cognito-identity.amazonaws.com:sub para limitar o acesso a dados do próprio usuário.",
"option_d": "Criar uma IAM role única para cada funcionário e fazer com que cada um a assuma para acessar a aplicação.",
"correct_answers": ["C"],
"explanation_detailed": "Um identity pool do Amazon Cognito pode federar com o provedor SAML corporativo e emitir identidades temporárias para cada funcionário. Em seguida, é possível usar condições de IAM com cognito-identity.amazonaws.com:sub para restringir o acesso a recursos (como pastas em S3 ou linhas em RDS expostas via API) associados apenas àquele usuário.",
"incorrect_explanations": {
"A": "Usar apenas VPC e endpoints não resolve o problema de autorização por usuário com o diretório SAML.",
"B": "User pools armazenam usuários no Cognito; o requisito é não espelhar identidades na AWS.",
"D": "Criar uma IAM role por funcionário não é escalável e ainda implica gerenciar identidades diretamente na AWS."
}
},
{
"id": "dva-c02-deployment-233",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe desenvolveu uma nova aplicação serverless usando funções AWS Lambda e vai fazer o deploy usando a AWS Serverless Application Model (AWS SAM) CLI. Qual passo deve ser executado antes de implantar a aplicação?",
"option_a": "Compactar a aplicação em um arquivo .zip e fazer upload diretamente na função Lambda.",
"option_b": "Testar a função Lambda rastreando-a primeiro com AWS X-Ray.",
"option_c": "Empacotar a aplicação serverless usando o comando sam package.",
"option_d": "Criar o ambiente da aplicação com o comando eb create my-env.",
"correct_answers": ["C"],
"explanation_detailed": "Com o AWS SAM, o fluxo padrão é usar sam build (quando necessário) e depois sam package para empacotar o código e atualizar os apontamentos para S3 no template. Após isso, sam deploy é usado para criar ou atualizar a stack.",
"incorrect_explanations": {
"A": "Fazer zip manual e subir direto ignora o fluxo automatizado e a integração com CloudFormation do SAM.",
"B": "Testar com X-Ray é útil, mas não é pré-requisito obrigatório para deployment.",
"D": "eb create é usado com Elastic Beanstalk, não com aplicações SAM."
}
},
{
"id": "dva-c02-security-234",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação precisa criptografar dados escritos em um bucket Amazon S3, usando chaves gerenciadas em um data center on-premises, mas a criptografia deve ser executada pelo próprio S3. Qual opção de criptografia atende a esses requisitos?",
"option_a": "Criptografia no lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3).",
"option_b": "Criptografia no lado do servidor com chaves gerenciadas pelo AWS KMS (SSE-KMS).",
"option_c": "Criptografia no lado do cliente com chaves-mestras gerenciadas pelo cliente.",
"option_d": "Criptografia no lado do servidor com chaves fornecidas pelo cliente (SSE-C).",
"correct_answers": ["D"],
"explanation_detailed": "Com SSE-C, o cliente fornece a chave de criptografia a cada operação de upload/download, e o S3 faz a criptografia no lado do servidor. Isso permite que as chaves sejam gerenciadas on-premises, enquanto o S3 executa a criptografia em repouso.",
"incorrect_explanations": {
"A": "SSE-S3 usa chaves gerenciadas pela AWS, não pelo cliente on-premises.",
"B": "SSE-KMS também mantém as chaves no KMS, sob controle da AWS (ainda que com CMKs do cliente), não inteiramente on-premises.",
"C": "Criptografia no lado do cliente faz com que o S3 apenas armazene blobs opacos; o enunciado exige que o S3 realize a criptografia, usando chaves externas."
}
},
{
"id": "dva-c02-development-235",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe está desenvolvendo um aplicativo móvel que permite que usuários façam upload de fotos para um bucket Amazon S3. Centenas de milhares de usuários devem enviar fotos ao mesmo tempo durante um único evento. Depois do upload, um serviço de backend irá inspecionar e processar as fotos em busca de conteúdo inadequado. Qual abordagem é a MAIS resiliente e ajuda a suavizar picos temporários de volume para o serviço de backend?",
"option_a": "Criar uma função AWS Lambda que periodicamente verifica a pasta de uploads no S3 e processa novas imagens.",
"option_b": "Ao fazer upload da foto no S3, publicar o evento em uma fila Amazon SQS e usar essa fila como gatilho de evento para uma função Lambda que faz a análise.",
"option_c": "Quando o usuário faz upload da foto, invocar uma API no Amazon API Gateway que chama diretamente uma função Lambda para analisar a imagem.",
"option_d": "Criar uma state machine do AWS Step Functions para monitorar o bucket e invocar Lambda quando detectar nova imagem.",
"correct_answers": ["B"],
"explanation_detailed": "O uso de S3 + SQS + Lambda cria um buffer durável: eventos de upload geram mensagens em SQS, que absorve picos de tráfego e permite que o processamento pelo Lambda aconteça em ritmo controlado. Isso aumenta a resiliência e reduz risco de sobrecarga do backend.",
"incorrect_explanations": {
"A": "Varreduras periódicas do bucket são ineficientes, podem perder eventos recentes e não tratam bem picos repentinos.",
"C": "Invocar Lambda diretamente no momento do upload acopla fortemente o fluxo de upload ao processamento, o que pode causar timeouts e problemas durante picos.",
"D": "Step Functions é útil para orquestração de etapas, não para buffering e nivelamento de picos de eventos de upload."
}
},
{
"id": "dva-c02-development-236",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma equipe de desenvolvimento quer executar workloads em contêineres no Amazon ECS. Cada contêiner de aplicação precisa compartilhar dados com outro contêiner responsável por coletar logs e métricas. O que a equipe deve fazer para atender a esse requisito?",
"option_a": "Criar duas definições de pod separadas, uma para a aplicação e outra para o coletor, e vinculá-las.",
"option_b": "Criar duas task definitions separadas e usar um volume compartilhado entre as tasks.",
"option_c": "Criar uma única task definition, especificar ambos os contêineres e montar um volume compartilhado entre eles.",
"option_d": "Criar um único pod com ambos os contêineres e montar um volume persistente para os dois.",
"correct_answers": ["C"],
"explanation_detailed": "No ECS, dois contêineres que precisam compartilhar dados normalmente são definidos na mesma task definition, com um volume declarado e montado por ambos. Assim, eles compartilham o sistema de arquivos daquele volume como se estivessem lado a lado.",
"incorrect_explanations": {
"A": "O conceito de pod é de Kubernetes, não de ECS puro.",
"B": "Volumes não podem ser compartilhados diretamente entre tasks distintas da forma descrita.",
"D": "Novamente, pod e volumes persistentes são conceitos de Kubernetes, não de ECS nativo."
}
},
{
"id": "dva-c02-monitoring-237",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma startup de e-commerce está se preparando para um grande evento de vendas. Conforme o tráfego e a carga aumentam, a equipe quer ser notificada sempre que a utilização de CPU de uma instância Amazon EC2 ultrapassar 80%. Qual solução atende a esse requisito?",
"option_a": "Criar um alarme customizado no Amazon CloudWatch que envia uma notificação para um tópico Amazon SNS quando a métrica de CPU ultrapassar 80%.",
"option_b": "Criar um alarme no AWS CloudTrail que monitora a métrica de CPU e envia notificações via SNS.",
"option_c": "Criar um cron job na instância EC2 que chama periodicamente describe-instance-information e publica o resultado em um tópico SNS.",
"option_d": "Criar uma função Lambda que consulta logs do CloudTrail a cada 15 minutos e envia notificação via SNS quando a CPU ultrapassar 80%.",
"correct_answers": ["A"],
"explanation_detailed": "O CloudWatch coleta métricas de CPU das instâncias EC2 automaticamente. Criar um alarme com limite de 80% e associá-lo a um tópico SNS é a forma mais simples e recomendada para notificação automática.",
"incorrect_explanations": {
"B": "CloudTrail registra chamadas de API, não métricas de utilização de CPU.",
"C": "Manter cron jobs e scripts próprios para monitorar CPU é desnecessário e menos confiável do que usar CloudWatch.",
"D": "Não há motivo para consultar CloudTrail para dados de CPU; as métricas já estão disponíveis diretamente no CloudWatch."
}
},
{
"id": "dva-c02-security-238",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma aplicação em instâncias Amazon EC2 abre conexões para um banco Amazon RDS SQL Server. O desenvolvedor não quer armazenar usuário e senha do banco no código e também quer rotação automática das credenciais. Qual é a forma MAIS segura de armazenar e acessar essas credenciais?",
"option_a": "Criar uma IAM role com permissão de acesso direto ao banco e anexá-la à instância EC2.",
"option_b": "Usar o AWS Secrets Manager para armazenar as credenciais e recuperá-las sob demanda na aplicação.",
"option_c": "Armazenar as credenciais em um arquivo criptografado no S3 e baixar o arquivo no boot da instância.",
"option_d": "Armazenar usuário e senha diretamente no código-fonte já que o repositório é privado.",
"correct_answers": ["B"],
"explanation_detailed": "O AWS Secrets Manager permite armazenar segredos de forma segura, com rotação automática integrada a diversos bancos RDS. A aplicação pode buscar as credenciais em tempo de execução usando a IAM role da instância, sem embutir segredos no código.",
"incorrect_explanations": {
"A": "IAM roles não substituem credenciais de banco; o RDS SQL Server ainda espera usuário e senha próprios.",
"C": "Gerenciar arquivos criptografados no S3 e lógica de rotação traz mais complexidade do que usar Secrets Manager.",
"D": "Colocar senhas no código é uma das piores práticas de segurança, independentemente do repositório ser privado."
}
},
{
"id": "dva-c02-deployment-239",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está atualizando uma aplicação implantada no AWS Elastic Beanstalk. A nova versão é incompatível com a antiga e requer um cutover completo para a nova versão de uma só vez, com possibilidade de rollback rápido em caso de falha. Qual abordagem atende a esses requisitos com o MENOR downtime?",
"option_a": "Usar a política de deployment All at once no ambiente existente para atualizar todas as instâncias de uma vez.",
"option_b": "Executar um deployment Rolling with additional batch no ambiente atual.",
"option_c": "Criar um novo ambiente Elastic Beanstalk com a nova versão e, em seguida, usar swap environment URLs.",
"option_d": "Executar um deployment Rolling no ambiente atual.",
"correct_answers": ["C"],
"explanation_detailed": "Criar um novo ambiente com a nova versão e fazer swap de URLs é o padrão de blue/green deployment no Beanstalk. O tráfego muda rapidamente de um ambiente para o outro e, em caso de problemas, o rollback é simplesmente outro swap.",
"incorrect_explanations": {
"A": "All at once atualiza as instâncias em produção, causando downtime considerável e dificultando rollback.",
"B": "Rolling with additional batch mantém parte do tráfego rodando na versão antiga enquanto atualiza, mas não resolve a incompatibilidade forte exigida.",
"D": "Rolling substitui instâncias gradualmente, o que não é ideal quando as versões são incompatíveis entre si."
}
},
{
"id": "dva-c02-security-240",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está escrevendo uma aplicação web que precisa compartilhar documentos sensíveis com usuários finais. Os documentos estão em um bucket Amazon S3 privado. A aplicação deve permitir que apenas usuários autenticados façam download de documentos específicos, e o acesso deve expirar em 15 minutos. Como atender a esses requisitos?",
"option_a": "Copiar os documentos para um bucket S3 temporário com política de expiração de 15 minutos.",
"option_b": "Gerar uma URL pré-assinada (pre-signed URL) do S3 com tempo de expiração de 15 minutos usando o SDK da AWS.",
"option_c": "Usar criptografia no lado do servidor com SSE-KMS e fazer download dos documentos sempre via HTTPS.",
"option_d": "Modificar a bucket policy para permitir downloads apenas a usuários específicos e reverter a mudança após 15 minutos.",
"correct_answers": ["B"],
"explanation_detailed": "Pre-signed URLs permitem conceder acesso temporário a um objeto específico em um bucket privado. O servidor pode gerar a URL somente para usuários autenticados e definir uma expiração de 15 minutos, atendendo ao requisito de tempo limitado.",
"incorrect_explanations": {
"A": "Copiar arquivos para outro bucket e gerenciar expiração é mais complexo e sujeito a falhas.",
"C": "Criptografia e HTTPS são importantes, mas não controlam janelas de acesso por usuário com expiração curta.",
"D": "Alterar a bucket policy dinamicamente é pesado, arriscado e não escalável para controlar acesso por arquivo."
}
},
{
"id": "dva-c02-monitoring-241",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Uma empresa está desenvolvendo um relatório executado via AWS Step Functions. O CloudWatch mostra erros em um estado de tarefa da state machine. Para depuração, é necessário que o input original do estado seja preservado junto com a mensagem de erro no output do estado. Qual prática de modelagem na definição da state machine permite preservar tanto o input quanto o erro?",
"option_a": "Usar ResultPath em um bloco Catch para incluir o erro junto com o input original.",
"option_b": "Usar InputPath em um bloco Catch definindo o valor como null.",
"option_c": "Usar ErrorEquals em um bloco Retry para incluir o erro com o input original.",
"option_d": "Usar OutputPath em um bloco Retry definindo o valor como $.",
"correct_answers": ["A"],
"explanation_detailed": "Em Step Functions, um bloco Catch pode usar ResultPath para mesclar a informação de erro no JSON do estado, preservando o input original e adicionando o campo de erro em uma chave específica. Isso permite que o output contenha tanto os dados de entrada quanto os detalhes da falha.",
"incorrect_explanations": {
"B": "InputPath controla quais partes do input são passadas adiante, e colocá-lo como null descarta os dados.",
"C": "ErrorEquals em Retry serve para definir quais erros serão re-tentados, não para preservar input e erro juntos.",
"D": "OutputPath filtra o output, mas não mescla automaticamente informações de erro com o input."
}
},
{
"id": "dva-c02-monitoring-242",
"certification_id": "DVA-C02",
"domain": "MONITORING",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor recebe erros ao tentar lançar ou encerrar instâncias Amazon EC2 usando um script com boto3. O erro indica throttling nas chamadas de API. O que o desenvolvedor deve fazer para lidar corretamente com esse tipo de erro?",
"option_a": "Anexar uma IAM role à instância EC2 para permitir mais chamadas de API em nome do cliente.",
"option_b": "Implementar um algoritmo de backoff exponencial para otimizar o número de chamadas de API para o Amazon EC2.",
"option_c": "Aumentar a largura de banda de rede para suportar taxas mais altas de chamadas de API.",
"option_d": "Atualizar a versão da AWS CLI para que o boto3 possa lidar com taxas maiores automaticamente.",
"correct_answers": ["B"],
"explanation_detailed": "Quando a API retorna erros de throttling, a prática recomendada é implementar retries com backoff exponencial. Isso reduz a pressão sobre o serviço e aumenta a probabilidade de sucesso das requisições subsequentes.",
"incorrect_explanations": {
"A": "IAM roles controlam permissões, não limites de taxa de API.",
"C": "Largura de banda de rede não altera limites de taxa impostos pelo serviço.",
"D": "Atualizar a CLI não resolve o problema de throttling se o padrão de chamadas continuar agressivo demais."
}
},
{
"id": "dva-c02-deployment-243",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Dado um template AWS CloudFormation que cria um novo bucket Amazon S3, qual é a forma MAIS eficiente de referenciar esse bucket a partir de outro template CloudFormation em outra stack?",
"option_a": "Adicionar uma declaração Export na seção Outputs do template original e usar ImportValue nos outros templates.",
"option_b": "Adicionar Exported: true ao recurso do bucket no template original e usar ImportResource nos outros templates.",
"option_c": "Criar um custom resource que busque o nome do bucket da primeira stack.",
"option_d": "Usar Fn::Include para incluir o template existente nos outros templates e referenciar o recurso diretamente.",
"correct_answers": ["A"],
"explanation_detailed": "CloudFormation permite exportar valores em Outputs com um nome lógico e, em seguida, importá-los em outras stacks com Fn::ImportValue. Esse é o mecanismo suportado para compartilhar, por exemplo, nomes de buckets entre stacks.",
"incorrect_explanations": {
"B": "Exported: true não é um atributo válido em recursos CloudFormation.",
"C": "Custom resources funcionariam, mas adicionam complexidade desnecessária quando Export/ImportValue já resolvem o problema.",
"D": "Fn::Include não é um mecanismo padrão para referenciar recursos criados em outra stack."
}
},
{
"id": "dva-c02-deployment-244",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "easy",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está usando o AWS CodeDeploy para implantar uma aplicação em instâncias Amazon EC2. O desenvolvedor precisa alterar as permissões de arquivo de um artefato específico logo após ser copiado para o destino. Em qual lifecycle event ele deve colocar esse passo?",
"option_a": "AfterInstall.",
"option_b": "DownloadBundle.",
"option_c": "BeforeInstall.",
"option_d": "ValidateService.",
"correct_answers": ["A"],
"explanation_detailed": "O hook AfterInstall é executado depois que os arquivos de aplicação foram copiados para o destino (após o Install). Esse é o momento ideal para ajustar permissões ou fazer outras configurações sobre os arquivos já presentes no sistema.",
"incorrect_explanations": {
"B": "DownloadBundle ocorre antes de o pacote ser extraído e instalado.",
"C": "BeforeInstall acontece antes da cópia/instalação dos arquivos, então o arquivo ainda não existe no destino.",
"D": "ValidateService é usado para verificar se o serviço está funcionando corretamente após o deployment."
}
},
{
"id": "dva-c02-development-245",
"certification_id": "DVA-C02",
"domain": "DEVELOPMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 1,
"active": true,
"question_text": "Um desenvolvedor está usando o Amazon DynamoDB para armazenar dados de aplicação e quer reduzir ainda mais a latência de leitura e escrita, melhorando o tempo de resposta. Qual recurso do DynamoDB deve ser usado?",
"option_a": "Amazon DynamoDB Streams.",
"option_b": "Amazon DynamoDB Accelerator (DAX).",
"option_c": "Amazon DynamoDB global tables.",
"option_d": "Transações do Amazon DynamoDB.",
"correct_answers": ["B"],
"explanation_detailed": "O DynamoDB Accelerator (DAX) é um cache em memória na frente do DynamoDB que fornece leituras de microssegundos para workloads que exigem alta performance, reduzindo significativamente latência de leitura e, em alguns casos, melhorando o padrão de escrita também.",
"incorrect_explanations": {
"A": "Streams são usados para capturar mudanças na tabela, não para acelerar leituras e escritas diretamente.",
"C": "Global tables são voltadas para replicação multi-região e alta disponibilidade geográfica.",
"D": "Transações aumentam garantias de consistência, mas não necessariamente reduzem latência."
}
},
{
"id": "dva-c02-deployment-246",
"certification_id": "DVA-C02",
"domain": "DEPLOYMENT",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Um desenvolvedor está escrevendo um script para automatizar o deployment de uma aplicação serverless usando um template existente do AWS Serverless Application Model (AWS SAM). Quais comandos devem ser usados para empacotar e implantar a aplicação? (Selecione DUAS opções)",
"option_a": "Executar aws cloudformation package para criar o pacote de deployment e depois aws cloudformation deploy.",
"option_b": "Executar sam package para criar o pacote de deployment e depois sam deploy para implantar.",
"option_c": "Executar aws s3 cp para fazer upload do template SAM para o S3 e depois aws lambda update-function-code.",
"option_d": "Criar um pacote .zip localmente e chamar aws serverlessrepo create-application.",
"option_e": "Criar um pacote .zip, fazer upload para o S3 e chamar aws cloudformation create-stack diretamente.",
"correct_answers": ["B", "A"],
"explanation_detailed": "Os fluxos suportados são: usando o SAM CLI (sam package e sam deploy) ou usando diretamente aws cloudformation package e aws cloudformation deploy. Ambos cuidam de empacotar artefatos e atualizar os templates para apontar para S3 antes da criação ou atualização da stack.",
"incorrect_explanations": {
"C": "Atualizar a função Lambda diretamente ignora todo o modelo declarativo da aplicação serverless.",
"D": "serverlessrepo é usado para o Serverless Application Repository, não para deploy genérico de aplicações SAM.",
"E": "Criar a stack manualmente sem o passo de package torna trabalhoso gerenciar artefatos locais e URIs de S3."
}
},
{
"id": "dva-c02-security-247",
"certification_id": "DVA-C02",
"domain": "SECURITY",
"difficulty": "medium",
"tier": "FREE",
"required_selection_count": 2,
"active": true,
"question_text": "Uma equipe está projetando um aplicativo móvel que requer autenticação com múltiplos fatores (MFA). Quais passos devem ser realizados para atender a esse requisito usando serviços gerenciados da AWS? (Selecione DUAS opções)",
"option_a": "Usar o Amazon Cognito para criar um user pool e registrar os usuários nele.",
"option_b": "Enviar códigos de MFA via SMS diretamente a partir do código do app usando Amazon SNS Publish.",
"option_c": "Habilitar MFA para o user pool do Amazon Cognito.",
"option_d": "Criar usuários IAM para todos os usuários finais do aplicativo.",
"option_e": "Habilitar MFA para os usuários criados no IAM.",
"correct_answers": ["A", "C"],
"explanation_detailed": "Para aplicativos móveis, o padrão é usar um user pool do Amazon Cognito como provedor de identidade de usuários finais. O Cognito suporta MFA nativamente; basta habilitá-lo no user pool, o que cuida da geração, envio e validação dos códigos de MFA.",
"incorrect_explanations": {
"B": "Gerenciar SMS manualmente no código do app com SNS aumenta complexidade e não utiliza os fluxos prontos do Cognito.",
"D": "IAM não é destinado a milhões de usuários finais de aplicativo, mas a identidades de administração/serviço.",
"E": "Mesmo que se habilitasse MFA em IAM, isso seria para administradores da conta, não para usuários de um app móvel."
}
}
]