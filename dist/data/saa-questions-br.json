[
  {
    "id": "saa-c03-design_high_performing_architectures-001",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma empresa coleta dados de temperatura, umidade e pressão atmosférica em cidades de vários continentes. A quantidade média de dados coletados diariamente de cada local é de 500 GB. Cada local possui uma conexão de internet de alta velocidade. A empresa deseja agregar os dados de todos esses locais globais o mais rápido possível em um único bucket do Amazon S3. A solução deve minimizar a complexidade operacional. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o S3 Transfer Acceleration no bucket S3 de destino. Usar uploads multipartes para enviar os dados diretamente dos locais para o bucket S3 de destino.",
    "option_b": "Enviar os dados de cada local para um bucket S3 na região mais próxima. Usar a Replicação Entre Regiões (Cross-Region Replication) do S3 para copiar os objetos para o bucket S3 de destino. Em seguida, excluir os dados do bucket S3 de origem.",
    "option_c": "Agendar trabalhos diários do AWS Snowball Edge Storage Optimized para transferir dados de cada local para a região mais próxima. Usar a Replicação Entre Regiões do S3 para copiar os objetos para o bucket S3 de destino.",
    "option_d": "Enviar os dados de cada local para uma instância Amazon EC2 na região mais próxima. Armazenar os dados em um volume Amazon EBS. Fazer snapshots regulares do volume EBS e copiá-los para a região que contém o bucket S3 de destino. Restaurar o volume EBS nessa região.",
    "option_e": "Internet Gateway",
    "correct_answers": [
      "A",
      "D"
    ],
    "explanation_detailed": "O S3 Transfer Acceleration com uploads multipartes oferece o caminho mais rápido e globalmente otimizado para o S3 com o mínimo de operações. O uso de snapshots do EC2 e EBS fornece um caminho controlável, mas adiciona complexidade desnecessária; no entanto, de acordo com a chave fornecida, estas duas estão marcadas como corretas.",
    "incorrect_explanations": {
      "B": "A CRR (Replicação Entre Regiões) adiciona latência de replicação e exige múltiplos buckets, aumentando a complexidade em comparação com uploads acelerados diretos.",
      "C": "O Snowball Edge é para cenários offline/de largura de banda limitada; os locais têm internet de alta velocidade e precisam de ingestão rápida e contínua.",
      "E": "Não é um mecanismo de upload nem parte de uma solução de ingestão do S3."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-002",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa precisa analisar arquivos de log de sua aplicação proprietária. Os logs são armazenados como JSON em um bucket do Amazon S3. As consultas serão simples e executadas sob demanda. Um arquiteto de soluções deve realizar a análise com o mínimo de alterações na arquitetura existente. O que o arquiteto de soluções deve fazer para atender a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar o Amazon Redshift para carregar todo o conteúdo em um único lugar e executar consultas SQL conforme necessário.",
    "option_b": "Usar o Amazon CloudWatch Logs para armazenar os logs. Executar consultas SQL no console do Amazon CloudWatch conforme necessário.",
    "option_c": "Usar o Amazon Athena diretamente com o Amazon S3 para executar consultas sob demanda.",
    "option_d": "Usar o AWS Glue para catalogar os logs. Usar um cluster Apache Spark transitório no Amazon EMR para executar consultas SQL conforme necessário.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Athena consulta dados diretamente no S3 com SQL sob demanda e sem servidor, não exigindo movimentação de dados e operações mínimas.",
    "incorrect_explanations": {
      "A": "O Redshift requer carregamento/ETL e gerenciamento de cluster, adicionando custo e sobrecarga.",
      "B": "O CloudWatch Logs não é o armazenamento atual e não fornece SQL ad-hoc sobre logs do S3.",
      "D": "Clusters EMR e Spark introduzem uma sobrecarga operacional significativa em comparação com o Athena sem servidor."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-003",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa usa o AWS Organizations para gerenciar várias contas da AWS para diferentes departamentos. A conta de gerenciamento tem um bucket S3 contendo relatórios de projetos. A empresa quer restringir o acesso a este bucket S3 para que apenas usuários de contas dentro da organização possam acessá-lo. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Adicionar a chave de condição global aws:PrincipalOrgID com uma referência ao ID da organização na política do bucket S3.",
    "option_b": "Criar uma unidade organizacional (OU) para cada departamento. Adicionar a chave de condição global aws:PrincipalOrgPaths à política do bucket S3.",
    "option_c": "Usar o AWS CloudTrail para monitorar os eventos CreateAccount, InviteAccountToOrganization, LeaveOrganization e RemoveAccountFromOrganization. Atualizar a política do bucket S3 de acordo.",
    "option_d": "Marcar cada usuário que precisa de acesso ao bucket S3 com uma tag. Adicionar a chave de condição global aws:PrincipalTag à política do bucket S3.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Usar aws:PrincipalOrgID na política do bucket restringe o acesso a principais da mesma Organização AWS com gerenciamento mínimo.",
    "incorrect_explanations": {
      "B": "aws:PrincipalOrgPaths não é necessário; OrgID é suficiente e mais simples.",
      "C": "Atualizações reativas baseadas em eventos do CloudTrail adicionam sobrecarga e complexidade.",
      "D": "A marcação por usuário é desnecessária e operacionalmente pesada para uma restrição em toda a organização."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-004",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma aplicação é executada em uma instância Amazon EC2 em uma VPC. A aplicação processa logs armazenados em um bucket do Amazon S3. A instância EC2 deve acessar o bucket S3 sem conectividade com a internet. Qual solução fornece conectividade de rede privada ao Amazon S3?",
    "option_a": "Criar um endpoint de gateway da VPC para o bucket S3.",
    "option_b": "Transmitir os logs para o Amazon CloudWatch Logs. Exportar os logs para o bucket S3.",
    "option_c": "Criar um perfil de instância EC2 para permitir o acesso ao S3.",
    "option_d": "Criar um Amazon API Gateway com um link privado para acessar o endpoint do S3.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Um endpoint de gateway da VPC para S3 permite conectividade privada da VPC para o S3 sem passar pela internet pública.",
    "incorrect_explanations": {
      "B": "O CloudWatch Logs não fornece acesso privado ao S3 a partir do EC2.",
      "C": "Um perfil de instância lida com autorização, não com o caminho de rede.",
      "D": "O API Gateway é desnecessário; o S3 suporta acesso privado via endpoints de gateway."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-005",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda uma aplicação web na AWS usando uma única instância Amazon EC2 que armazena documentos enviados por usuários em um volume Amazon EBS. Para melhorar a escalabilidade e a disponibilidade, a empresa duplicou a arquitetura criando uma segunda instância EC2 e um volume EBS em outra Zona de Disponibilidade, colocando ambos atrás de um Application Load Balancer. Após a mudança, os usuários relataram que, ao atualizar o site, podiam ver um subconjunto de seus documentos ou outro, mas nunca todos os documentos de uma vez. O que um arquiteto de soluções deve propor para garantir que os usuários vejam todos os seus documentos de uma vez?",
    "option_a": "Copiar os dados para que ambos os volumes EBS contenham todos os documentos.",
    "option_b": "Configurar o Application Load Balancer para direcionar um usuário para o servidor com os documentos.",
    "option_c": "Copiar os dados de ambos os volumes EBS para o Amazon EFS. Modificar a aplicação para armazenar novos documentos no Amazon EFS.",
    "option_d": "Configurar o Application Load Balancer para enviar a solicitação para ambos os servidores. Retornar cada documento do servidor correto.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O EFS fornece um sistema de arquivos compartilhado e multi-AZ acessível por todas as instâncias, para que cada usuário veja o mesmo conjunto de documentos, independentemente da instância de destino.",
    "incorrect_explanations": {
      "A": "A cópia manual de dados ficará dessincronizada e não resolve as gravações contínuas.",
      "B": "A afinidade de sessão não unifica o armazenamento entre as instâncias.",
      "D": "O fan-out por solicitação adiciona complexidade e latência e não é um padrão padrão."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-006",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa usa NFS para armazenar arquivos de vídeo grandes em um armazenamento conectado à rede (NAS) local. Cada arquivo de vídeo varia em tamanho de 1 MB a 500 GB. O armazenamento total é de 70 TB e não está mais crescendo. A empresa decide migrar os arquivos de vídeo para o Amazon S3. A empresa deve migrar os arquivos de vídeo o mais rápido possível, utilizando a menor quantidade de largura de banda da rede. Qual solução atende a esses requisitos?",
    "option_a": "Criar um bucket S3. Criar uma função IAM com permissões para gravar no bucket S3. Usar a AWS CLI para copiar todos os arquivos localmente para o bucket S3.",
    "option_b": "Criar um trabalho do AWS Snowball Edge. Receber um dispositivo Snowball Edge localmente. Usar o cliente do Snowball Edge para transferir dados para o dispositivo. Devolver o dispositivo para que a AWS possa importar os dados para o Amazon S3.",
    "option_c": "Implantar um S3 File Gateway local. Criar um endpoint de serviço público para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento de arquivos NFS existente para o S3 File Gateway. Transferir os dados do compartilhamento de arquivos NFS existente para o S3 File Gateway.",
    "option_d": "Configurar uma conexão AWS Direct Connect entre a rede local e a AWS. Implantar um S3 File Gateway local. Criar uma interface virtual pública (VIF) para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento de arquivos NFS existente para o S3 File Gateway. Transferir os dados do compartilhamento de arquivos NFS existente para o S3 File Gateway.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O S3 File Gateway expõe uma interface NFS apoiada pelo S3, permitindo uma transição rápida com alterações mínimas e uso eficiente da largura de banda, de acordo com a chave fornecida.",
    "incorrect_explanations": {
      "A": "Copiar 70 TB pela rede é lento e consome muita largura de banda.",
      "B": "O Snowball Edge é normalmente o mais rápido e com menor consumo de largura de banda, mas não foi selecionado de acordo com a chave de resposta fornecida.",
      "D": "O Direct Connect adiciona custo e tempo de espera; desnecessário para uma migração única."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-007",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que ingere mensagens. Dezenas de outras aplicações e microsserviços consomem rapidamente essas mensagens. O número de mensagens varia drasticamente e, às vezes, aumenta subitamente para 100.000 por segundo. A empresa deseja desacoplar a solução e aumentar a escalabilidade. Qual solução atende a esses requisitos?",
    "option_a": "Persistir as mensagens no Amazon Kinesis Data Analytics. Configurar as aplicações consumidoras para ler e processar as mensagens.",
    "option_b": "Implantar a aplicação de ingestão em instâncias Amazon EC2 em um grupo de Auto Scaling que escala com base em métricas de CPU.",
    "option_c": "Gravar as mensagens no Amazon Kinesis Data Streams com um único shard. Usar uma função AWS Lambda para pré-processar as mensagens e armazená-las no Amazon DynamoDB. Configurar as aplicações consumidoras para ler do DynamoDB para processar as mensagens.",
    "option_d": "Publicar as mensagens em um tópico do Amazon Simple Notification Service (Amazon SNS) com várias assinaturas do Amazon Simple Queue Service (Amazon SQS). Configurar as aplicações consumidoras para processar mensagens das filas.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o Kinesis Data Analytics é selecionado para lidar com picos e alto rendimento para consumidores downstream.",
    "incorrect_explanations": {
      "B": "O escalonamento do EC2 com base na CPU não fornece desacoplamento de fluxo ou fan-out ordenado.",
      "C": "Um único shard não pode lidar com 100k mensagens/seg e o DynamoDB não é um barramento de fluxo fan-out.",
      "D": "O fan-out SNS+SQS é comum, mas não foi selecionado de acordo com a chave de resposta fornecida."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-008",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando uma aplicação distribuída para a AWS. A aplicação lida com cargas de trabalho variáveis. A plataforma legada consiste em um servidor primário que coordena o trabalho entre vários nós de computação. A empresa deseja modernizar a aplicação com uma solução que maximize a resiliência e a escalabilidade. Como um arquiteto de soluções deve projetar a arquitetura para atender a esses requisitos?",
    "option_a": "Configurar uma fila do Amazon Simple Queue Service (Amazon SQS) como o destino para os itens de trabalho. Implantar os nós de computação em instâncias Amazon EC2 gerenciadas em um grupo de Auto Scaling. Configurar o EC2 Auto Scaling para usar o escalonamento agendado.",
    "option_b": "Configurar uma fila do Amazon Simple Queue Service (Amazon SQS) como o destino para os itens de trabalho. Implantar os nós de computação em instâncias Amazon EC2 gerenciadas em um grupo de Auto Scaling. Configurar o EC2 Auto Scaling com base no comprimento da fila.",
    "option_c": "Implantar tanto o servidor primário quanto os nós de computação em instâncias Amazon EC2 gerenciadas em um grupo de Auto Scaling. Configurar o AWS CloudTrail como o destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga do servidor primário.",
    "option_d": "Implantar tanto o servidor primário quanto os nós de computação em instâncias Amazon EC2 gerenciadas em um grupo de Auto Scaling. Configurar o Amazon EventBridge (Amazon CloudWatch Events) como o destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga dos nós de computação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, manter um servidor primário e escalar pela sua carga é a opção selecionada.",
    "incorrect_explanations": {
      "A": "O escalonamento agendado não reage a cargas de trabalho variáveis.",
      "B": "O escalonamento baseado no comprimento da fila com SQS é uma modernização comum, mas não foi selecionado de acordo com a chave de resposta fornecida.",
      "D": "O EventBridge não é uma fila de trabalhos e não substitui a distribuição de trabalho coordenada aqui."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-009",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa opera um servidor de arquivos SMB em seu data center local. O servidor de arquivos armazena arquivos grandes que são acessados com frequência nos primeiros dias após a criação. Após 7 dias, os arquivos raramente são acessados. O total de dados está crescendo e está perto da capacidade de armazenamento da empresa. Um arquiteto de soluções deve aumentar o armazenamento disponível sem perder o acesso de baixa latência aos arquivos acessados recentemente. O arquiteto também deve fornecer gerenciamento do ciclo de vida para evitar futuros problemas de armazenamento. Qual solução atende a esses requisitos?",
    "option_a": "Usar o AWS DataSync para copiar arquivos com mais de 7 dias do servidor de arquivos local para a AWS.",
    "option_b": "Criar um Amazon S3 File Gateway para estender o armazenamento da empresa. Criar uma política de ciclo de vida do S3 para mover os dados para o S3 Glacier Deep Archive após 7 dias.",
    "option_c": "Criar um sistema de arquivos Amazon FSx for Windows File Server para estender o armazenamento da empresa.",
    "option_d": "Instalar um utilitário no computador de cada usuário para acessar o Amazon S3. Criar uma política de ciclo de vida do S3 para mover os dados para o S3 Glacier Flexible Retrieval após 7 dias.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, usar o acesso do cliente S3 e a transição do ciclo de vida para o Glacier Flexible Retrieval após 7 dias é a opção selecionada.",
    "incorrect_explanations": {
      "A": "O DataSync por si só não estende o armazenamento nem fornece gerenciamento contínuo do ciclo de vida para os padrões de acesso do usuário.",
      "B": "O S3 Glacier Deep Archive após 7 dias prejudicaria severamente o desempenho de recuperação para arquivos usados recentemente.",
      "C": "O FSx expande o armazenamento SMB, mas não possui transições nativas do ciclo de vida de objetos para arquivamento de custo ultrabaixo."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-010",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação de e-commerce na AWS. A aplicação envia informações sobre novos pedidos para uma API REST no Amazon API Gateway para processamento. A empresa quer garantir que os pedidos sejam processados na ordem em que são recebidos. Qual solução atende a esses requisitos?",
    "option_a": "Usar uma integração do API Gateway para publicar uma mensagem em um tópico do Amazon Simple Notification Service (Amazon SNS) quando um pedido é recebido. Assinar uma função AWS Lambda ao tópico para processar o pedido.",
    "option_b": "Usar uma integração do API Gateway para enviar uma mensagem para uma fila FIFO no Amazon Simple Queue Service (Amazon SQS) quando um pedido é recebido. Configurar a fila SQS FIFO para invocar uma função AWS Lambda para processar o pedido.",
    "option_c": "Usar um autorizador do API Gateway para bloquear todas as solicitações enquanto um pedido está sendo processado.",
    "option_d": "Usar uma integração do API Gateway para enviar uma mensagem para uma fila padrão no Amazon Simple Queue Service (Amazon SQS) quando um pedido é recebido. Configurar a fila SQS padrão para invocar uma função AWS Lambda para processar o pedido.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O SQS FIFO preserva a ordem estrita e a semântica de processamento exatamente uma vez para cargas de trabalho ordenadas.",
    "incorrect_explanations": {
      "A": "O SNS não preserva a ordem estrita para múltiplos consumidores.",
      "C": "Bloquear solicitações não é uma estratégia de enfileiramento ou ordenação.",
      "D": "O SQS padrão fornece ordenação de melhor esforço, não ordenação estrita."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-011",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação rodando no Amazon EC2 que usa um banco de dados Amazon Aurora. As instâncias EC2 se conectam ao banco de dados usando nomes de usuário e senhas armazenados localmente em um arquivo. A empresa quer minimizar a sobrecarga operacional do gerenciamento de credenciais. O que um arquiteto de soluções deve fazer para alcançar isso?",
    "option_a": "Usar o AWS Secrets Manager. Habilitar a rotação automática.",
    "option_b": "Usar o AWS Systems Manager Parameter Store. Habilitar a rotação automática.",
    "option_c": "Criar um bucket Amazon S3 para armazenar objetos criptografados usando uma chave do AWS KMS. Migrar o arquivo de credenciais para o bucket S3. Apontar a aplicação para o bucket S3.",
    "option_d": "Criar um volume Amazon EBS criptografado para cada instância EC2. Anexar o novo volume EBS a cada instância EC2. Migrar o arquivo de credenciais para o novo volume EBS. Apontar a aplicação para o novo volume EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o Parameter Store com rotação é selecionado para centralizar e automatizar o gerenciamento de credenciais.",
    "incorrect_explanations": {
      "A": "O Secrets Manager é típico para rotação, mas não é selecionado de acordo com a chave de resposta fornecida.",
      "C": "Armazenar credenciais no S3 transfere o problema e adiciona sobrecarga de gerenciamento de acesso.",
      "D": "Criptografar o EBS protege em repouso, mas não resolve a rotação ou o gerenciamento centralizado."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-012",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa global hospeda sua aplicação web em instâncias Amazon EC2 atrás de um Application Load Balancer (ALB). A aplicação web tem dados estáticos e dinâmicos. A empresa armazena seus dados estáticos em um bucket do Amazon S3. A empresa quer melhorar o desempenho e reduzir a latência tanto para dados estáticos quanto dinâmicos. A empresa usa seu próprio nome de domínio registrado com o Amazon Route 53. O que um arquiteto de soluções deve fazer para atender a esses requisitos?",
    "option_a": "Criar uma distribuição do Amazon CloudFront com o bucket S3 e o ALB como origens. Configurar o Route 53 para rotear o tráfego para a distribuição do CloudFront.",
    "option_b": "Criar uma distribuição do Amazon CloudFront com o ALB como origem. Criar um AWS Global Accelerator padrão com o bucket S3 como um endpoint. Configurar o Route 53 para rotear o tráfego para a distribuição do CloudFront.",
    "option_c": "Criar uma distribuição do Amazon CloudFront com o bucket S3 como origem. Criar um AWS Global Accelerator padrão com o ALB e a distribuição do CloudFront como endpoints. Criar um nome de domínio personalizado que aponte para o nome DNS do acelerador. Usar o domínio personalizado como o endpoint para a aplicação web.",
    "option_d": "Criar uma distribuição do Amazon CloudFront com o ALB como origem. Criar um AWS Global Accelerator padrão com o bucket S3 como um endpoint. Criar dois nomes de domínio — um apontando para a distribuição do CloudFront para conteúdo dinâmico e o outro para o acelerador para conteúdo estático. Usar esses nomes de domínio como endpoints para a aplicação web.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o CloudFront para conteúdo estático e o Global Accelerator com endpoints do ALB e CloudFront são combinados atrás de um domínio personalizado.",
    "incorrect_explanations": {
      "A": "Não aproveita o Global Accelerator de acordo com a abordagem selecionada.",
      "B": "O S3 não é um endpoint de acelerador e isso divide os caminhos de aceleração de forma ineficiente.",
      "D": "Usar dois domínios separados complica a estratégia de endpoint."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-013",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa realiza manutenção mensal em sua infraestrutura AWS. Durante essas atividades de manutenção, a empresa precisa rotacionar as credenciais de seus bancos de dados Amazon RDS for MySQL em várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Armazenar as credenciais como segredos no AWS Secrets Manager. Usar a replicação de segredos multirregional para as regiões necessárias. Configurar o Secrets Manager para rotacionar os segredos em um cronograma.",
    "option_b": "Armazenar as credenciais como segredos no AWS Systems Manager criando um parâmetro de string segura. Usar a replicação de segredos multirregional para as regiões necessárias. Configurar o Systems Manager para rotacionar os segredos em um cronograma.",
    "option_c": "Armazenar as credenciais em um bucket do Amazon S3 com criptografia do lado do servidor habilitada. Usar o Amazon EventBridge (CloudWatch Events) para invocar uma função AWS Lambda para rotacionar as credenciais.",
    "option_d": "Criptografar as credenciais como segredos usando chaves do AWS KMS multirregionais gerenciadas pelo cliente. Armazenar os segredos em uma tabela global do Amazon DynamoDB. Usar uma função AWS Lambda para recuperar os segredos do DynamoDB. Usar a API do RDS para rotacionar os segredos.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O Secrets Manager suporta rotação gerenciada e replicação multirregional, minimizando código personalizado e operações.",
    "incorrect_explanations": {
      "B": "O Parameter Store não possui rotação gerenciada nativa e exigiria mais lógica personalizada.",
      "C": "S3 mais lógica de rotação personalizada aumenta a complexidade e a manutenção.",
      "D": "KMS + DynamoDB + Lambda é uma solução personalizada com alta sobrecarga operacional."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-014",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de e-commerce em instâncias Amazon EC2 atrás de um Application Load Balancer. As instâncias são executadas em um grupo de Auto Scaling do EC2 em várias Zonas de Disponibilidade. O grupo de Auto Scaling escala com base em métricas de utilização de CPU. A aplicação de e-commerce armazena dados de transação em um banco de dados MySQL 8.0 hospedado em uma grande instância EC2. O desempenho do banco de dados degrada rapidamente à medida que a carga da aplicação aumenta. A aplicação lida com mais solicitações de leitura do que transações de escrita. A empresa quer uma solução que dimensione automaticamente o banco de dados para lidar com cargas de trabalho de leitura imprevisíveis, mantendo alta disponibilidade. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon Redshift com um único nó para funcionalidades de líder e computação.",
    "option_b": "Usar o Amazon RDS com uma implantação Single-AZ. Configurar o RDS para adicionar réplicas de leitura em uma Zona de Disponibilidade diferente.",
    "option_c": "Usar o Amazon Aurora com uma implantação Multi-AZ. Configurar o Aurora Auto Scaling com réplicas do Aurora.",
    "option_d": "Usar o Amazon ElastiCache for Memcached com instâncias EC2 Spot.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Aurora suporta escalonamento de leitura via Réplicas do Aurora e Aurora Auto Scaling com alta disponibilidade Multi-AZ.",
    "incorrect_explanations": {
      "A": "O Redshift é um data warehouse, não um armazenamento transacional para a aplicação.",
      "B": "Single-AZ reduz a disponibilidade; o escalonamento manual de réplicas de leitura adiciona sobrecarga operacional.",
      "D": "O cache ajuda nas leituras, mas não aborda os requisitos de escalonamento relacional durável e HA."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-015",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa migrou recentemente para a AWS e quer implementar uma solução para proteger o tráfego que entra e sai de sua VPC de produção. A empresa anteriormente tinha um servidor de inspeção em seu data center local que realizava operações específicas, como inspeção e filtragem do fluxo de tráfego. A empresa quer a mesma funcionalidade na nuvem da AWS. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon GuardDuty para inspeção e filtragem de tráfego na VPC de produção.",
    "option_b": "Usar o Traffic Mirroring para espelhar o tráfego da VPC de produção para inspeção e filtragem.",
    "option_c": "Usar o AWS Network Firewall para criar regras de inspeção e filtragem de tráfego para a VPC de produção.",
    "option_d": "Usar o AWS Firewall Manager para criar regras de inspeção e filtragem de tráfego para a VPC de produção.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O AWS Network Firewall fornece inspeção e filtragem gerenciadas com estado na escala da VPC com grupos de regras e políticas.",
    "incorrect_explanations": {
      "A": "O GuardDuty detecta ameaças, mas não filtra/inspeciona em linha.",
      "B": "O Traffic Mirroring copia o tráfego; não impõe filtragem.",
      "D": "O Firewall Manager governa a política entre contas, mas depende de uma implementação de firewall como o Network Firewall."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-016",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda um data lake na AWS que consiste em dados no Amazon S3 e Amazon RDS for PostgreSQL. A empresa precisa de uma solução de relatórios que forneça visualização de dados e inclua todas as fontes de dados do data lake. Apenas a equipe de gerenciamento da empresa deve ter acesso total a todos os dashboards; o resto da empresa deve ter acesso limitado. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma análise no Amazon QuickSight. Conectar a todas as fontes de dados e criar novos conjuntos de dados. Publicar dashboards para visualização de dados. Compartilhar os dashboards com as funções IAM apropriadas.",
    "option_b": "Criar uma análise no Amazon QuickSight. Conectar a todas as fontes de dados e criar novos conjuntos de dados. Publicar dashboards para visualização de dados. Compartilhar os dashboards com os usuários e grupos apropriados.",
    "option_c": "Criar uma tabela e um crawler no AWS Glue para os dados no Amazon S3. Criar um trabalho de ETL no AWS Glue para produzir relatórios. Publicar os relatórios no Amazon S3. Usar políticas de bucket do S3 para restringir o acesso aos relatórios.",
    "option_d": "Criar uma tabela e um crawler no AWS Glue para os dados no Amazon S3. Usar a capacidade de consulta federada do Amazon Athena para acessar os dados no Amazon RDS for PostgreSQL. Gerar relatórios usando o Athena. Publicar os relatórios no Amazon S3. Usar políticas de bucket do S3 para restringir o acesso aos relatórios.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, a solução usa Glue + Athena (incluindo consultas federadas) para gerar relatórios armazenados no S3 com acesso controlado por políticas de bucket.",
    "incorrect_explanations": {
      "A": "O QuickSight fornece visualização, mas não é selecionado de acordo com a chave de resposta fornecida.",
      "B": "Também baseado no QuickSight; não selecionado de acordo com a chave fornecida.",
      "C": "O ETL do Glue por si só não cobre o acesso federado ao RDS e consultas interativas."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-017",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando uma nova aplicação de negócios. A aplicação é executada em duas instâncias Amazon EC2 e usa um bucket do Amazon S3 para armazenamento de documentos. Um arquiteto de soluções deve garantir que as instâncias EC2 possam acessar o bucket S3. O que o arquiteto de soluções deve fazer?",
    "option_a": "Criar uma função IAM que conceda acesso ao bucket S3. Anexar a função às instâncias EC2.",
    "option_b": "Criar uma política IAM que conceda acesso ao bucket S3. Anexar a política diretamente às instâncias EC2.",
    "option_c": "Criar um grupo IAM que conceda acesso ao bucket S3. Anexar o grupo às instâncias EC2.",
    "option_d": "Criar um usuário IAM que conceda acesso ao bucket S3. Anexar as credenciais da conta do usuário às instâncias EC2.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Perfis de instância EC2 (funções IAM) fornecem credenciais temporárias e acesso de menor privilégio ao S3 sem incorporar segredos.",
    "incorrect_explanations": {
      "B": "Políticas se anexam a identidades, não diretamente a instâncias EC2.",
      "C": "Grupos são para usuários, não para acesso de instâncias EC2.",
      "D": "Credenciais de usuário de longa duração em instâncias são inseguras и difíceis de rotacionar."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-018",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento está projetando um microsserviço que converterá imagens grandes em versões menores e compactadas. Quando um usuário carrega uma imagem pela interface da web, o microsserviço deve armazenar a imagem em um bucket do Amazon S3, processar e compactar a imagem usando uma função AWS Lambda e armazenar a imagem compactada em um bucket S3 diferente. Um arquiteto de soluções deve projetar uma solução que use componentes duráveis e sem estado para processar imagens automaticamente. Qual combinação de ações atende a esses requisitos? (Escolha duas.)",
    "option_a": "Criar uma fila do Amazon Simple Queue Service (Amazon SQS). Configurar o bucket S3 para enviar uma notificação para a fila SQS quando uma imagem for carregada.",
    "option_b": "Configurar a função Lambda para usar a fila do Amazon SQS como sua fonte de eventos. Quando a mensagem SQS for processada com sucesso, excluir a mensagem da fila.",
    "option_c": "Configurar a função Lambda para pesquisar no bucket S3 por novos uploads. Quando uma imagem carregada for detectada, escrever o nome do arquivo em um arquivo de texto na memória e usar esse arquivo para rastrear as imagens processadas.",
    "option_d": "Lançar uma instância Amazon EC2 para pesquisar uma fila do Amazon SQS. Quando itens forem adicionados à fila, registrar o nome do arquivo em um arquivo de texto na instância EC2 e invocar a função Lambda.",
    "option_e": "Configurar uma regra do Amazon EventBridge para monitorar o bucket S3. Quando uma imagem for carregada, enviar um alerta para um tópico do Amazon SNS com o e-mail do proprietário da aplicação para processamento posterior.",
    "correct_answers": [
      "A",
      "B"
    ],
    "explanation_detailed": "As notificações de eventos do S3 para o SQS desacoplam a ingestão do processamento, e a pesquisa do SQS pela Lambda fornece processamento sem servidor e sem estado com entrega pelo menos uma vez.",
    "incorrect_explanations": {
      "C": "A Lambda не pesquisa o S3; o rastreamento via arquivos na memória não é durável.",
      "D": "Adicionar a pesquisa do EC2 aumenta a sobrecarga operacional.",
      "E": "Alertas por e-mail não implementam o processamento automatizado."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-019",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou recentemente uma API RESTful usando o Amazon API Gateway e o AWS Lambda. O hospital usa o API Gateway e a Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código da Lambda para identificar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI do texto extraído.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI do texto extraído.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Textract extrai texto de PDFs e imagens; o Comprehend Medical detecta entidades de PHI do texto extraído usando uma abordagem de serviço gerenciado.",
    "incorrect_explanations": {
      "A": "Bibliotecas 'faça você mesmo' aumentam a manutenção e carecem de especialização em PNL médica.",
      "B": "O SageMaker requer a construção e manutenção de modelos personalizados.",
      "D": "O OCR do Rekognition não é o serviço principal para extração de texto de documentos em escala; o Textract é feito para isso."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-020",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa opera uma aplicação que gera muitos arquivos, cada um com cerca de 5 MB de tamanho. Os arquivos são armazenados no Amazon S3. A política da empresa exige que os arquivos sejam retidos por 4 anos antes de poderem ser excluídos. A acessibilidade imediata é sempre necessária porque os arquivos contêm dados de negócios críticos que não são facilmente reproduzíveis. Os arquivos são acessados com frequência durante os primeiros 30 dias após a criação do objeto, mas raramente acessados depois disso. Qual solução de armazenamento é a MAIS econômica?",
    "option_a": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Glacier 30 dias após a criação do objeto. Excluir os arquivos 4 anos após a criação.",
    "option_b": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 dias após a criação do objeto. Excluir os arquivos 4 anos após a criação.",
    "option_c": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação do objeto. Excluir os arquivos 4 anos após a criação.",
    "option_d": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação do objeto. Em seguida, mover os arquivos para o S3 Glacier 4 anos após a criação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O S3 Standard-IA após 30 dias reduz o custo enquanto mantém a acessibilidade imediata; os objetos são excluídos em 4 anos de acordo com a política.",
    "incorrect_explanations": {
      "A": "A recuperação do Glacier não é imediata, violando os requisitos de acessibilidade.",
      "B": "O One Zone-IA reduz a durabilidade/disponibilidade em várias AZs.",
      "D": "Arquivar em 4 anos é redundante, pois os objetos são excluídos em 4 anos."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-021",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação em várias instâncias Amazon EC2. A aplicação processa mensagens de uma fila do Amazon SQS, grava em uma tabela do Amazon RDS e exclui a mensagem da fila. Registros duplicados ocasionais são encontrados na tabela do RDS, mas a fila do SQS não contém mensagens duplicadas. O que um arquiteto de soluções deve fazer para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a chamada de API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a chamada de API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a chamada de API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a chamada de API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade impede que outros consumidores recebam a mesma mensagem enquanto ela está sendo processada.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não resolve o processamento duplicado.",
      "B": "As permissões não estão relacionadas à duplicação do processamento.",
      "C": "O tempo de espera afeta a sondagem longa (long polling), não a visibilidade da mensagem em trânsito."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-022",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando uma nova arquitetura híbrida para estender a infraestrutura local de uma empresa para a AWS. A empresa requer uma conexão altamente disponível com latência consistentemente baixa para uma região da AWS. A empresa deve minimizar os custos e está disposta a aceitar tráfego mais lento se a conexão principal falhar. O que o arquiteto de soluções deve fazer?",
    "option_a": "Provisionar uma conexão AWS Direct Connect para uma região. Provisionar uma conexão VPN como backup se o Direct Connect principal falhar.",
    "option_b": "Provisionar uma conexão de túnel VPN para uma região para conectividade privada. Provisionar um segundo túnel VPN para conectividade privada como backup se a VPN principal falhar.",
    "option_c": "Provisionar uma conexão AWS Direct Connect para uma região. Provisionar uma segunda conexão Direct Connect para a mesma região como backup se a principal falhar.",
    "option_d": "Provisionar uma conexão AWS Direct Connect para uma região. Usar o atributo de failover do Direct Connect via AWS CLI para criar automaticamente uma conexão de backup se a principal falhar.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O Direct Connect fornece conectividade privada de baixa latência; um backup de VPN oferece failover de menor custo com desempenho mais lento aceitável.",
    "incorrect_explanations": {
      "B": "VPN dupla não atende ao requisito de desempenho consistente de baixa latência.",
      "C": "Um segundo DX aumenta o custo; o requisito é minimizar o custo.",
      "D": "Não existe um atributo de failover que cria automaticamente um DX de backup."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-023",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação web crítica em instâncias Amazon EC2 atrás de um Application Load Balancer. As instâncias EC2 estão em um grupo de Auto Scaling. A aplicação usa um banco de dados Amazon Aurora PostgreSQL implantado em uma única Zona de Disponibilidade. A empresa quer alta disponibilidade com tempo de inatividade mínimo e perda de dados mínima. Qual solução atende a esses requisitos com o MENOR esforço operacional?",
    "option_a": "Colocar as instâncias EC2 em diferentes regiões da AWS. Usar as verificações de saúde do Amazon Route 53 para redirecionar o tráfego. Usar a replicação entre regiões para o Aurora PostgreSQL.",
    "option_b": "Configurar o grupo de Auto Scaling para abranger várias Zonas de Disponibilidade. Configurar o banco de dados como Multi-AZ. Configurar um Amazon RDS Proxy para o banco de dados.",
    "option_c": "Configurar o grupo de Auto Scaling para usar uma única Zona de Disponibilidade. Fazer snapshots horários do banco de dados. Recuperar o banco de dados a partir de snapshots em caso de falha.",
    "option_d": "Configurar o grupo de Auto Scaling para abranger várias regiões da AWS. Gravar dados da aplicação no Amazon S3. Usar notificações de eventos do S3 para acionar uma função AWS Lambda para gravar dados no banco de dados.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Multi-AZ para computação e banco de dados fornece alta disponibilidade com operações mínimas. O RDS Proxy melhora o manuseio de conexões.",
    "incorrect_explanations": {
      "A": "A replicação entre regiões adiciona complexidade e é desnecessária para HA dentro de uma região.",
      "C": "Snapshots têm RPO/RTO significativos e não fornecem HA.",
      "D": "Computação entre regiões mais gatilhos do S3 é complexo e não apropriado para HA de banco de dados."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-024",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "A aplicação HTTP de uma empresa está atrás de um Network Load Balancer (NLB). O grupo de destino do NLB está configurado com um grupo de Auto Scaling de instâncias EC2 que executam o serviço web. A empresa percebe que o NLB não está detectando erros HTTP da aplicação. Esses erros exigem a reinicialização manual das instâncias EC2 que executam o serviço web. A empresa precisa melhorar a disponibilidade da aplicação sem escrever scripts ou código personalizados. O que um arquiteto de soluções deve fazer?",
    "option_a": "Habilitar verificações de saúde HTTP no NLB fornecendo a URL da aplicação.",
    "option_b": "Adicionar um trabalho cron nas instâncias EC2 para verificar os logs locais da aplicação a cada minuto. Se erros HTTP forem detectados, reiniciar a aplicação.",
    "option_c": "Substituir o NLB por um Application Load Balancer. Habilitar verificações de saúde HTTP fornecendo a URL da aplicação. Configurar uma ação de Auto Scaling para substituir instâncias não saudáveis.",
    "optiond": "Criar um alarme do Amazon CloudWatch para monitorar a métrica UnhealthyHostCount do NLB. Configurar uma ação de Auto Scaling para substituir instâncias não saudáveis quando o alarme estiver no estado ALARM.",
    "option_d": "Criar um alarme do Amazon CloudWatch para monitorar a métrica UnhealthyHostCount do NLB. Configurar uma ação de Auto Scaling para substituir instâncias não saudáveis quando o alarme estiver no estado ALARM.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O ALB suporta verificações de saúde HTTP/HTTPS na camada 7, permitindo que instâncias não saudáveis sejam detectadas e substituídas automaticamente.",
    "incorrect_explanations": {
      "A": "O NLB realiza verificações de saúde TCP/UDP e não pode inspecionar diretamente os códigos de resposta HTTP.",
      "B": "Scripts cron adicionam carga operacional e são frágeis.",
      "D": "Monitorar as métricas do NLB não fornece saúde no nível HTTP e ainda depende de detecção manual/indireta."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-025",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de e-commerce que usa o Amazon DynamoDB para armazenar informações de clientes. Em caso de corrupção de dados, um arquiteto de soluções precisa projetar uma solução que atenda a um objetivo de ponto de recuperação (RPO) de 15 minutos e um objetivo de tempo de recuperação (RTO) de 1 hora. O que o arquiteto de soluções deve recomendar?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para recuperação de RPO, apontar a aplicação para uma região da AWS diferente.",
    "option_b": "Configurar a recuperação point-in-time do DynamoDB. Para recuperação de RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar dados do DynamoDB para o Amazon S3 Glacier diariamente. Para recuperação de RPO, importar os dados do S3 Glacier de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para recuperação de RPO, restaurar a tabela do DynamoDB usando o snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O PITR do DynamoDB permite restaurações para qualquer segundo nos últimos 35 dias, atendendo a um RPO de 15 minutos com restauração rápida para um RTO de 1 hora.",
    "incorrect_explanations": {
      "A": "Tabelas globais abordam a disponibilidade multirregional, не a recuperação point-in-time de corrupção.",
      "C": "As restaurações do Glacier são lentas e não atendem ao RTO/RPO.",
      "D": "O DynamoDB não usa snapshots do EBS; isso não é aplicável."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-026",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda uma aplicação de processamento de fotos que frequentemente carrega e baixa imagens de buckets S3 localizados na mesma região da AWS. Um arquiteto de soluções notou um aumento nos custos de transferência de dados de saída e deve implementar uma solução para reduzir esses custos. Como o arquiteto de soluções pode atender a esse requisito?",
    "option_a": "Implantar o Amazon API Gateway em uma sub-rede pública e ajustar a tabela de rotas para rotear as chamadas do S3 através dele.",
    "option_b": "Implantar um gateway NAT em uma sub-rede pública e anexar uma política de endpoint que permita o acesso aos buckets S3.",
    "optionc": "Implantar a aplicação em uma sub-rede pública e permitir que ela roteie através de um gateway da internet para acessar os buckets S3.",
    "option_d": "Implantar um endpoint de gateway S3 da VPC na VPC e anexar uma política de endpoint que permita o acesso aos buckets S3.",
    "option_c": "Implantar a aplicação em uma sub-rede pública e permitir que ela roteie através de um gateway da internet para acessar os buckets S3.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Um endpoint de gateway da VPC roteia o tráfego do S3 privadamente dentro da rede da AWS, evitando cobranças de saída de NAT/Internet.",
    "incorrect_explanations": {
      "A": "O API Gateway não é usado para intermediar o tráfego do S3 para redução de custos.",
      "B": "O gateway NAT adiciona custo de saída; não o reduz.",
      "C": "Usar um gateway da internet aumenta a exposição e não reduz o custo de transferência."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-027",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma empresa lançou recentemente instâncias de aplicação baseadas em Linux no Amazon EC2 em uma sub-rede privada e um host bastion Linux em uma instância EC2 em uma sub-rede pública de uma VPC. Um arquiteto de soluções precisa se conectar do ambiente local, através da conexão de internet da empresa, tanto ao host bastion quanto aos servidores da aplicação. O arquiteto deve garantir que os grupos de segurança de todas as instâncias EC2 permitam esse acesso. Qual combinação de etapas o arquiteto de soluções deve tomar? (Escolha duas.)",
    "option_a": "Substituir o grupo de segurança atual no host bastion por um que permita acesso de entrada apenas das instâncias da aplicação.",
    "option_b": "Substituir o grupo de segurança atual no host bastion por um que permita acesso de entrada apenas do intervalo de IP interno da empresa.",
    "option_c": "Substituir o grupo de segurança atual no host bastion por um que permita acesso de entrada apenas do intervalo de IP externo da empresa.",
    "option_d": "Substituir o grupo de segurança atual nas instâncias da aplicação por um que permita acesso de entrada SSH apenas do IP privado do host bastion.",
    "option_e": "Substituir o grupo de segurança atual nas instâncias da aplicação por um que permita acesso de entrada SSH apenas do IP público do host bastion.",
    "correct_answers": [
      "C",
      "D"
    ],
    "explanation_detailed": "Restringir a entrada do bastion aos IPs externos da empresa; restringir instâncias privadas ao SSH apenas do IP privado do bastion para acesso controlado por salto.",
    "incorrect_explanations": {
      "A": "O bastion deve aceitar entrada do ambiente local, não das instâncias da aplicação.",
      "B": "IPs internos (privados) não são usados no caminho da internet.",
      "E": "Instâncias privadas não devem permitir SSH de um IP público; o tráfego vem do bastion de dentro da VPC."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-028",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma aplicação web de duas camadas está sendo projetada. A aplicação consiste em uma camada web pública hospedada no Amazon EC2 em sub-redes públicas e uma camada de banco de dados consistindo em Microsoft SQL Server rodando no Amazon EC2 em uma sub-rede privada. A segurança é uma prioridade máxima. Como os grupos de segurança devem ser configurados nesta situação? (Escolha duas.)",
    "option_a": "Configurar o grupo de segurança da camada web para permitir tráfego de entrada na porta 443 de 0.0.0.0/0.",
    "option_b": "Configurar o grupo de segurança da camada web para permitir tráfego de saída na porta 443 para 0.0.0.0/0.",
    "option_c": "Configurar o grupo de segurança da camada de banco de dados para permitir tráfego de entrada na porta 1433 do grupo de segurança da camada web.",
    "option_d": "Configurar o grupo de segurança da camada de banco de dados para permitir tráfego de saída nas portas 443 e 1433 para o grupo de segurança da camada web.",
    "option_e": "Configurar o grupo de segurança da camada de banco de dados para permitir tráfego de entrada nas portas 443 e 1433 do grupo de segurança da camada web.",
    "correct_answers": [
      "A",
      "C"
    ],
    "explanation_detailed": "Permitir HTTPS para a camada web da internet e restringir a entrada do BD para o SQL Server (1433) apenas do grupo de segurança da camada web.",
    "incorrect_explanations": {
      "B": "A saída 443 da camada web não está relacionada à exposição do site.",
      "D": "A saída do BD para a camada web não é necessária para operações padrão.",
      "E": "O BD não deve aceitar HTTPS (443); apenas 1433 é necessário."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-029",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa quer mover uma aplicação de várias camadas do ambiente local para a AWS para melhorar o desempenho da aplicação. A aplicação consiste em camadas que se comunicam via serviços RESTful. As transações são descartadas quando uma camada fica sobrecarregada. Um arquiteto de soluções deve projetar uma solução que resolva esses problemas e modernize a aplicação. Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?",
    "option_a": "Usar o Amazon API Gateway e rotear as transações para funções AWS Lambda como a camada da aplicação. Usar o Amazon SQS como a camada de mensagens entre os serviços da aplicação.",
    "option_b": "Usar as métricas do Amazon CloudWatch para analisar o desempenho histórico e determinar o uso máximo do servidor durante as falhas. Aumentar o tamanho das instâncias EC2 que executam a camada da aplicação para atender aos requisitos de pico.",
    "option_c": "Usar o Amazon Simple Notification Service (Amazon SNS) para lidar com as mensagens entre os servidores da aplicação executados em um grupo de Auto Scaling do EC2. Usar o CloudWatch para monitorar o comprimento da fila do SNS e escalar de acordo.",
    "option_d": "Usar o Amazon Simple Queue Service (Amazon SQS) para lidar com as mensagens entre os servidores da aplicação executados em um grupo de Auto Scaling do EC2. Usar o CloudWatch para monitorar o comprimento da fila do SQS e escalar quando falhas de comunicação forem detectadas.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "API Gateway + Lambda sem servidor remove o gerenciamento de servidores e o SQS desacopla as camadas para evitar transações descartadas.",
    "incorrect_explanations": {
      "B": "O escalonamento vertical não aborda o desacoplamento de picos e adiciona custo.",
      "C": "O SNS é pub/sub sem profundidade de fila; além disso, as métricas de comprimento de fila se aplicam ao SQS, não ao SNS.",
      "D": "Ainda baseado em EC2 e menos eficiente operacionalmente do que sem servidor."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-030",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena dados de transações de clientes sensíveis em uma tabela do Amazon DynamoDB. A empresa deve reter os dados por 7 anos. Qual solução é a MAIS econômica para atender a esses requisitos?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para recuperação de RPO, apontar a aplicação para uma região da AWS diferente.",
    "option_b": "Configurar a recuperação point-in-time do DynamoDB. Para recuperação de RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar os dados do DynamoDB para o Amazon S3 Glacier diariamente. Para recuperação de RPO, importar os dados do S3 Glacier de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para recuperação de RPO, restaurar a tabela do DynamoDB usando o snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o PITR é selecionado para atender às metas de retenção/recuperação com custo operacional mínimo.",
    "incorrect_explanations": {
      "A": "Tabelas globais aumentam o custo entre regiões e não abordam a retenção de longo prazo.",
      "C": "Exportações diárias e importações do Glacier adicionam complexidade e atrasos na recuperação.",
      "D": "Snapshots do EBS não são aplicáveis ao DynamoDB."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-031",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa planeja usar uma tabela do DynamoDB para armazenamento de dados. A empresa está preocupada com a otimização de custos. A tabela não será usada na maioria das manhãs. À noite, o tráfego de leitura e escrita será imprevisível, com picos rápidos quando ocorrerem. O que um arquiteto de soluções deve recomendar?",
    "option_a": "Criar uma tabela do DynamoDB no modo sob demanda.",
    "option_b": "Criar uma tabela do DynamoDB com um índice secundário global.",
    "option_c": "Criar uma tabela do DynamoDB com capacidade provisionada e auto scaling.",
    "option_d": "Criar uma tabela do DynamoDB no modo provisionado e configurá-la como uma tabela global.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A cobrança sob demanda acomoda automaticamente períodos ociosos e picos imprevisíveis sem planejamento de capacidade.",
    "incorrect_explanations": {
      "B": "Um GSI não é uma estratégia de otimização de capacidade/custo por si só.",
      "C": "Provisionado com auto scaling requer configurações de capacidade e pode ter atrasos durante picos repentinos.",
      "D": "Tabelas globais aumentam o custo e не resolvem o padrão de tráfego imprevisível."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-032",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda sua aplicação web na AWS. A empresa quer garantir que todas as instâncias Amazon EC2, instâncias de banco de dados Amazon RDS e clusters Amazon Redshift sejam etiquetados. A empresa quer minimizar o esforço necessário para configurar e operar essa verificação. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar as regras do AWS Config para definir e detectar recursos que não estão devidamente etiquetados.",
    "option_b": "Usar o Cost Explorer para exibir recursos que não estão devidamente etiquetados. Etiquetar manualmente esses recursos.",
    "option_c": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas. Executar o código periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas. Agendar uma função AWS Lambda via CloudWatch para executar o código periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras gerenciadas do AWS Config podem avaliar a conformidade dos recursos com as políticas de etiquetagem continuamente com operações mínimas.",
    "incorrect_explanations": {
      "B": "A revisão e etiquetagem manuais são trabalhosas.",
      "C": "A execução de scripts personalizados no EC2 adiciona sobrecarga de gerenciamento.",
      "D": "Verificações personalizadas da Lambda exigem código e manutenção em comparação com regras gerenciadas."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-033",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico para hospedar o site?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket do Amazon S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância Amazon EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Sites estáticos são mais baratos e simples na hospedagem de sites estáticos do S3 ou via S3 apoiado pelo CloudFront.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custo de tempo de execução e complexidade para conteúdo estático.",
      "C": "O EC2 requer gerenciamento de servidor e é mais caro para ativos estáticos.",
      "D": "ALB + Lambda é superdimensionado para hospedagem estática."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-034",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa opera uma aplicação de marketplace online na AWS. A aplicação atende a centenas de milhares de usuários durante os horários de pico. A empresa precisa de uma solução que seja escalável e quase em tempo real para compartilhar detalhes de milhões de transações financeiras com várias aplicações internas. As transações também precisam ser processadas para remover dados sensíveis antes de serem armazenadas em um banco de dados de documentos para recuperação de baixa latência. O que um arquiteto de soluções deve recomendar?",
    "option_a": "Armazenar os dados da transação no Amazon DynamoDB. Configurar uma regra do DynamoDB para remover dados sensíveis de cada transação após a escrita. Usar o DynamoDB Streams para compartilhar dados da transação com outras aplicações.",
    "option_b": "Transmitir os dados da transação para o Amazon Kinesis Data Firehose para armazenar os dados tanto no Amazon DynamoDB quanto no Amazon S3. Usar a integração Lambda com o Kinesis Data Firehose para remover dados sensíveis. Outras aplicações podem consumir os dados armazenados no Amazon S3.",
    "option_c": "Transmitir os dados da transação para o Amazon Kinesis Data Streams. Usar a integração Lambda para remover dados sensíveis de cada transação e, em seguida, armazenar os dados da transação no Amazon DynamoDB. Outras aplicações podem consumir os dados do stream do Kinesis.",
    "option_d": "Armazenar em lote os dados da transação no Amazon S3 como arquivos. Usar o AWS Lambda para processar cada arquivo e remover dados sensíveis antes de atualizar os arquivos no Amazon S3. A função Lambda então armazena os dados no Amazon DynamoDB. Outras aplicações podem consumir os arquivos de transação armazenados no Amazon S3.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Kinesis Data Streams suporta ingestão e fan-out quase em tempo real; a Lambda pode redigir PII antes de persistir no DynamoDB, enquanto os streams atendem a outros consumidores.",
    "incorrect_explanations": {
      "A": "O DynamoDB не fornece redação pré-escrita e exporia dados sensíveis.",
      "B": "Os alvos do Firehose são limitados; o fan-out quase em tempo real para consumidores se encaixa melhor no KDS.",
      "D": "O processamento em lote do S3 не é quase em tempo real."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-035",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS. Para conformidade, governança, auditoria e segurança, a empresa deve rastrear as alterações de configuração de seus recursos da AWS e registrar uma trilha de auditoria das chamadas de API feitas a esses recursos. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o AWS Config para registrar as chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear as alterações de configuração e o AWS CloudTrail para registrar as chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O AWS Config registra as alterações de configuração dos recursos; o CloudTrail registra a atividade da API em toda a conta.",
    "incorrect_explanations": {
      "A": "O CloudTrail não rastreia as alterações de estado da configuração; o Config faz.",
      "C": "O CloudWatch não é o serviço de log de auditoria de chamadas de API.",
      "D": "O CloudTrail не substitui o Config para rastreamento de alterações de configuração."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-036",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias Amazon EC2 dentro de uma VPC atrás de um Elastic Load Balancer (ELB). Um serviço de terceiros é usado para DNS. O arquiteto de soluções da empresa deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Shield Advanced fornece detecção/mitigação de DDoS aprimorada e se integra com balanceadores de carga para proteção.",
    "incorrect_explanations": {
      "A": "O GuardDuty é detecção de ameaças, não mitigação de DDoS.",
      "B": "O Inspector avalia vulnerabilidades; não mitiga DDoS.",
      "C": "Atribuir o Route 53 é irrelevante quando o DNS é de terceiros e o ELB é o endpoint exposto."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-037",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS. A aplicação produzirá arquivos de saída que variam em tamanho de dezenas de gigabytes a centenas de terabytes. Os dados da aplicação devem ser armazenados em uma estrutura de sistema de arquivos padrão. A empresa quer uma solução que dimensione automaticamente, seja altamente disponível e exija sobrecarga operacional mínima. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias Amazon EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon Elastic File System (Amazon EFS) para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias Amazon EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O EFS fornece um sistema de arquivos POSIX que escala automaticamente e é multi-AZ, minimizando a carga operacional.",
    "incorrect_explanations": {
      "A": "O S3 é armazenamento de objetos, não uma montagem de sistema de arquivos padrão.",
      "B": "Os volumes EBS são limitados a uma AZ e não escalam automaticamente entre instâncias.",
      "D": "O EBS não possui semântica de arquivo compartilhado multi-instância e multi-AZ."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-038",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém na empresa — incluindo usuários administrativos e raiz — pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima resiliência. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar a exclusão de registros por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar a exclusão de registros. Após 10 anos, alterar a política do IAM para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O modo de conformidade do S3 Object Lock impõe a retenção WORM mesmo para usuários raiz; as transições de ciclo de vida atendem aos requisitos de acesso e arquivamento com a maior durabilidade.",
    "incorrect_explanations": {
      "A": "O Glacier por si só não impõe WORM nem acesso imediato no primeiro ano.",
      "B": "As políticas do IAM podem ser alteradas; não fornecem retenção imutável.",
      "D": "O One Zone-IA reduz a resiliência e o modo de governança pode ser contornado por usuários privilegiados."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-039",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa várias cargas de trabalho do Windows na AWS. Os funcionários da empresa usam compartilhamentos de arquivos do Windows hospedados em duas instâncias Amazon EC2. Os compartilhamentos de arquivos sincronizam dados entre si e mantêm cópias duplicadas. A empresa quer uma solução de armazenamento altamente disponível e durável que preserve a maneira como os usuários acessam os arquivos atualmente. O que um arquiteto de soluções deve fazer?",
    "option_a": "Migrar todos os dados para o Amazon S3. Configurar a autenticação do IAM para que os usuários acessem os arquivos.",
    "option_b": "Configurar um Amazon S3 File Gateway. Montar o S3 File Gateway nas instâncias EC2 existentes.",
    "option_c": "Estender o ambiente de compartilhamento de arquivos para o Amazon FSx for Windows File Server com uma configuração Multi-AZ. Migrar todos os dados para o FSx for Windows File Server.",
    "option_d": "Estender o ambiente de compartilhamento de arquivos para o Amazon Elastic File System (Amazon EFS) com uma configuração Multi-AZ. Migrar todos os dados para o Amazon EFS.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O FSx for Windows File Server fornece compatibilidade SMB, HA Multi-AZ e se integra com o Active Directory.",
    "incorrect_explanations": {
      "A": "O S3 é armazenamento de objetos e não é compatível com SMB para compartilhamentos de arquivos de usuários.",
      "B": "O S3 File Gateway apresenta cache NFS/SMB, mas é menos adequado para a semântica completa de servidor de arquivos HA do Windows.",
      "D": "O EFS é baseado em NFS, não em SMB, e не atende aos requisitos de compartilhamento de arquivos do Windows."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-040",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando uma arquitetura de VPC que inclui várias sub-redes. A arquitetura hospedará aplicações que usam instâncias Amazon EC2 e instâncias de banco de dados Amazon RDS. A arquitetura consiste em seis sub-redes em duas Zonas de Disponibilidade. Cada Zona de Disponibilidade inclui uma sub-rede pública, uma sub-rede privada e uma sub-rede de banco de dados dedicada. Apenas as instâncias EC2 nas sub-redes privadas devem ter acesso aos bancos de dados RDS. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma nova tabela de rotas que exclua rotas para os blocos CIDR da sub-rede pública. Associar a tabela de rotas às sub-redes de banco de dados.",
    "option_b": "Criar um grupo de segurança que negue o tráfego de entrada do grupo de segurança atribuído às instâncias da sub-rede pública. Anexar este grupo de segurança às instâncias de banco de dados.",
    "option_c": "Criar um grupo de segurança que permita o tráfego de entrada do grupo de segurança atribuído às instâncias da sub-rede privada. Anexar este grupo de segurança às instâncias de banco de dados.",
    "option_d": "Criar uma nova conexão de emparelhamento de VPC entre as sub-redes pública e privada. Criar uma conexão de emparelhamento separada entre as sub-redes privada e de banco de dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Use grupos de segurança para permitir a entrada no BD apenas do SG da camada privada, aplicando o menor privilégio.",
    "incorrect_explanations": {
      "A": "O roteamento não impõe o controle de acesso no nível da instância.",
      "B": "Os grupos de segurança são listas de permissão; você não pode negar SGs específicos.",
      "D": "O emparelhamento de VPC não é aplicável dentro das sub-redes de uma única VPC."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-041",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53. A empresa usa o Amazon API Gateway na região ca-central-1 como uma interface pública para suas APIs de microsserviços de backend. Serviços de terceiros consomem as APIs com segurança. A empresa quer projetar sua URL do API Gateway usando o nome de domínio e o certificado correspondente da empresa para que os serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Nome de Domínio da Empresa' para substituir a URL padrão. Importar o certificado público associado ao domínio da empresa para o AWS Certificate Manager (ACM).",
    "option_b": "Criar registros DNS do Route 53 com o nome de domínio da empresa. Apontar o registro de alias para o endpoint de estágio Regional do API Gateway. Importar o certificado público associado ao domínio da empresa para o ACM na região us-east-1.",
    "option_c": "Criar um endpoint Regional do API Gateway. Associar o endpoint do API Gateway ao nome de domínio da empresa. Importar o certificado público associado ao domínio da empresa para o ACM na mesma região. Anexar o certificado ao endpoint do API Gateway. Configurar o Route 53 para rotear o tráfego para o endpoint do API Gateway.",
    "option_d": "Criar um endpoint Regional do API Gateway. Associar o endpoint do API Gateway ao nome de domínio da empresa. Importar o certificado público associado ao domínio da empresa para o ACM na região us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 com o nome de domínio da empresa. Apontar um registro A para o nome de domínio da empresa.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, um endpoint Regional com certificado ACM em us-east-1 e registros do Route 53 é selecionado.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio не criam domínios personalizados nem anexam certificados TLS.",
      "B": "A região do certificado e os detalhes de alias estão incorretos de acordo com a abordagem selecionada.",
      "C": "Não selecionado de acordo com a chave fornecida."
    }
  },
  {
    "id": "saa-c03-design_secure_applicationS_architectures-042",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um site de mídia social implantado por um hospital permite que os usuários carreguem relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código da Lambda para detectar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI do texto extraído.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI do texto extraído.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Textract lida com OCR para PDFs/imagens; o Comprehend Medical detecta entidades de PHI com um serviço totalmente gerenciado.",
    "incorrect_explanations": {
      "A": "Bibliotecas personalizadas aumentam a manutenção e podem não ter precisão médica.",
      "B": "O SageMaker requer a construção de modelos e pipelines.",
      "D": "O OCR do Rekognition não é o serviço principal para extração de texto de documentos em comparação com o Textract."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-043",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de processamento em lote em instâncias Amazon EC2. A aplicação processa mensagens de uma fila do Amazon SQS, grava em uma tabela do Amazon RDS e exclui a mensagem da fila. Registros duplicados ocasionais aparecem na tabela do RDS, embora a fila do SQS não tenha mensagens duplicadas. O que um arquiteto de soluções deve fazer para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Um tempo de visibilidade mais longo impede o processamento simultâneo por vários trabalhadores.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não altera a semântica de processamento.",
      "B": "As permissões não são a causa das duplicatas.",
      "C": "O tempo de espera afeta a sondagem longa, não a visibilidade."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-044",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando uma nova arquitetura híbrida para estender a infraestrutura local de uma empresa para a AWS. A empresa requer uma conexão altamente disponível com latência consistentemente baixa para uma região da AWS. A empresa deve minimizar os custos e está disposta a aceitar tráfego mais lento se a conexão principal falhar. O que o arquiteto de soluções deve fazer?",
    "option_a": "Provisionar uma conexão AWS Direct Connect para uma região. Provisionar uma conexão VPN como backup se o Direct Connect principal falhar.",
    "option_b": "Provisionar uma conexão de túnel VPN para uma região para conectividade privada. Provisionar um segundo túnel VPN para conectividade privada como backup se a VPN principal falhar.",
    "option_c": "Provisionar uma conexão AWS Direct Connect para uma região. Provisionar uma segunda conexão Direct Connect para a mesma região como backup se a principal falhar.",
    "option_d": "Provisionar uma conexão AWS Direct Connect para uma região. Usar o atributo de failover via AWS CLI para criar automaticamente uma conexão de backup se o Direct Connect principal falhar.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "DX para desempenho primário, VPN para failover de baixo custo atende aos requisitos de disponibilidade e custo.",
    "incorrect_explanations": {
      "B": "VPN dupla não tem a baixa latência consistente desejada.",
      "C": "DX dupla aumenta o custo além do requisito.",
      "D": "Não existe tal atributo de criação de failover de DX automático."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-045",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando sua aplicação de várias camadas para a AWS e quer implementar uma solução para melhorar o desempenho. A versão local atual da aplicação é executada em uma única instância EC2 com um banco de dados anexado no EBS. Qual solução ajudará a modernizar a aplicação, minimizando a sobrecarga operacional?",
    "option_a": "Mover o banco de dados para que ambas as instâncias EC2 usem volumes EBS duplicados contendo todos os documentos.",
    "option_b": "Configurar o Application Load Balancer para direcionar um usuário para o servidor que tem o conjunto completo de documentos.",
    "option_c": "Migrar os dados de ambos os volumes EBS para o Amazon EFS. Modificar a aplicação para armazenar novos documentos no Amazon EFS.",
    "option_d": "Configurar o Application Load Balancer para enviar solicitações para ambos os servidores, mesclando os resultados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O EFS centraliza o armazenamento de arquivos entre instâncias, removendo a divergência de dados e simplificando o escalonamento.",
    "incorrect_explanations": {
      "A": "Duplicar volumes EBS não resolve a sincronização contínua.",
      "B": "Direcionar usuários não unifica o armazenamento.",
      "D": "Mesclar resultados adiciona complexidade e latência."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-046",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa usa NFS para armazenar arquivos de vídeo grandes em um NAS local. Os arquivos variam de 1 MB a 500 GB, e o armazenamento total é de 70 TB. A empresa decide migrar os arquivos de vídeo para o Amazon S3. Eles devem migrar o mais rápido possível, usando a menor largura de banda da rede. Qual solução atende a esses requisitos?",
    "option_a": "Criar um bucket S3. Criar uma função IAM com permissão para gravar no bucket. Usar a AWS CLI para copiar todos os arquivos localmente para o bucket S3.",
    "option_b": "Criar um trabalho do AWS Snowball Edge. Receber um dispositivo Snowball Edge localmente. Usar o cliente do Snowball Edge para transferir dados para o dispositivo. Devolver o dispositivo para que a AWS possa importar os dados para o S3.",
    "option_c": "Implantar um S3 File Gateway local. Criar um endpoint de serviço público para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento NFS existente para o S3 File Gateway. Transferir os dados do compartilhamento NFS existente para o S3 File Gateway.",
    "option_d": "Configurar uma conexão AWS Direct Connect entre a rede local e a AWS. Implantar um S3 File Gateway local. Criar uma interface virtual pública (VIF) para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento NFS existente para o S3 File Gateway. Transferir os dados do compartilhamento NFS existente para o S3 File Gateway.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o S3 File Gateway é selecionado para fazer a ponte entre NFS e S3 com impacto mínimo na largura de banda.",
    "incorrect_explanations": {
      "A": "A cópia direta pela WAN para 70 TB é lenta e consome muita largura de banda.",
      "B": "O Snowball Edge minimizaria a largura de banda, mas não é selecionado de acordo com a chave.",
      "D": "O Direct Connect adiciona custo/tempo de espera e é desnecessário para uma migração."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-047",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que ingere mensagens. Dezenas de outras aplicações e microsserviços consomem rapidamente essas mensagens. O número de mensagens varia drasticamente e às vezes aumenta subitamente para 100.000 por segundo. A empresa quer desacoplar a solução e aumentar a escalabilidade. Qual solução atende a esses requisitos?",
    "option_a": "Persistir as mensagens no Amazon Kinesis Data Analytics. Configurar as aplicações consumidoras para ler e processar as mensagens.",
    "option_b": "Implantar a aplicação de ingestão em instâncias EC2 em um grupo de Auto Scaling que escala com base em métricas de CPU.",
    "option_c": "Gravar as mensagens no Amazon Kinesis Data Streams com um único shard. Usar uma função AWS Lambda para pré-processar as mensagens e armazená-las no Amazon DynamoDB. Configurar as aplicações consumidoras para ler do DynamoDB.",
    "option_d": "Publicar as mensagens em um tópico do Amazon SNS com várias assinaturas do Amazon SQS. Configurar as aplicações consumidoras para processar mensagens das filas.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, o Kinesis Data Analytics é selecionado para lidar com streaming de alto rendimento e processamento de consumidores.",
    "incorrect_explanations": {
      "B": "O escalonamento do EC2 com base na CPU não aborda o desacoplamento de fluxo para taxas de pico massivas.",
      "C": "Um único shard não pode lidar com 100k msgs/seg; o DynamoDB não é um barramento de streaming.",
      "D": "O fan-out SNS+SQS não é selecionado de acordo com a chave de resposta fornecida."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-048",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando uma aplicação distribuída para a AWS. A aplicação lida com cargas de trabalho variáveis. A plataforma legada consiste em um servidor primário que coordena o trabalho entre vários nós de computação. A empresa quer modernizar a aplicação com uma solução que maximize a resiliência e a escalabilidade. Como o arquiteto de soluções deve projetar a arquitetura?",
    "option_a": "Configurar uma fila do Amazon SQS como destino para os itens de trabalho. Implantar os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o escalonamento agendado para o EC2 Auto Scaling.",
    "option_b": "Configurar uma fila do Amazon SQS como destino para os itens de trabalho. Implantar os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o EC2 Auto Scaling com base no comprimento da fila.",
    "option_c": "Implantar o servidor primário e os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o AWS CloudTrail como destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga do servidor primário.",
    "option_d": "Implantar o servidor primário e os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o Amazon EventBridge (CloudWatch Events) como destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga dos nós de computação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, manter um servidor primário coordenador e escalar por sua carga é a opção selecionada.",
    "incorrect_explanations": {
      "A": "O escalonamento agendado не se adapta à carga de trabalho variável.",
      "B": "O escalonamento por comprimento de fila é uma abordagem comum, mas não selecionada de acordo com a chave.",
      "D": "O EventBridge não é uma fila de trabalho para distribuir trabalhos aos nós."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-049",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus dados sensíveis de transações de clientes em uma tabela do Amazon DynamoDB. A empresa deve reter os dados por 7 anos. Qual solução é a MAIS econômica?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para recuperação de RPO, apontar a aplicação para uma região diferente da AWS.",
    "option_b": "Habilitar a recuperação point-in-time do DynamoDB. Para recuperação de RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar dados do DynamoDB para o Amazon S3 Glacier diariamente. Para recuperação de RPO, importar dados do S3 Glacier de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para recuperação de RPO, restaurar a tabela a partir do snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "De acordo com a chave fornecida, habilitar o PITR atende às necessidades de retenção e recuperação com baixo esforço operacional.",
    "incorrect_explanations": {
      "A": "Tabelas globais aumentam o custo e não lidam com a retenção de longo prazo.",
      "C": "A exportação/importação diária do Glacier adiciona complexidade e recuperação lenta.",
      "D": "O DynamoDB não é copiado via snapshots do EBS."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-050",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que gera um grande número de arquivos, cada um com cerca de 5 MB. Os arquivos são armazenados no Amazon S3. A política da empresa exige que os arquivos sejam retidos por 4 anos antes de poderem ser excluídos. O acesso imediato é necessário em todos os momentos porque os arquivos contêm dados de negócios críticos que não são facilmente reproduzíveis. Os arquivos são acessados com frequência durante os primeiros 30 dias após a criação, mas raramente depois. Qual solução de armazenamento é a MAIS econômica?",
    "option_a": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Glacier 30 dias após a criação do objeto. Excluir os arquivos 4 anos após a criação.",
    "option_b": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 dias após a criação. Excluir os arquivos 4 anos após a criação.",
    "option_c": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação. Excluir os arquivos 4 anos após a criação.",
    "option_d": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação e, em seguida, mover os arquivos para o S3 Glacier 4 anos após a criação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Standard-IA após 30 dias mantém o acesso imediato a um custo menor e a exclusão em 4 anos atende à retenção.",
    "incorrect_explanations": {
      "A": "O Glacier não fornece acesso imediato.",
      "B": "O One Zone-IA reduz a disponibilidade e a durabilidade.",
      "D": "Mover para o Glacier em 4 anos é desnecessário, pois os dados são excluídos em 4 anos."
    }
  },
  {
    "id": "saa-c03-domain-051",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação em múltiplas instâncias EC2. A aplicação processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui a mensagem da fila. Ocasionalmente, registros duplicados são encontrados na tabela RDS, embora a fila SQS não contenha duplicatas. O que um arquiteto de soluções deve fazer para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade do SQS garante que, uma vez que um consumidor leia uma mensagem, ela fique oculta por tempo suficiente para que o processamento seja concluído, impedindo que outros consumidores recebam e processem a mesma mensagem novamente.",
    "incorrect_explanations": {
      "A": "CreateQueue cria uma nova fila, mas não afeta a frequência com que as mensagens são entregues ou impede o processamento duplicado.",
      "B": "AddPermission controla o acesso à fila, mas não influencia a visibilidade da mensagem ou a entrega duplicada.",
      "C": "Alterar o tempo de espera afeta o long polling, não o tempo que uma mensagem permanece invisível após ser lida."
    }
  },
  {
    "id": "saa-c03-domain-052",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa usa um servidor de arquivos local legado executando SMB para armazenar grandes arquivos de vídeo. Os arquivos são acessados com frequência logo após a criação, mas raramente depois, e o armazenamento total está próximo da capacidade. Um arquiteto de soluções deve aumentar o armazenamento disponível sem sacrificar o acesso de baixa latência a arquivos usados recentemente e fornecer gerenciamento de ciclo de vida. Qual solução atende a esses requisitos?",
    "option_a": "Usar o AWS DataSync para copiar arquivos com mais de 7 dias do servidor de arquivos local para a AWS.",
    "option_b": "Criar um Amazon S3 File Gateway para estender o armazenamento. Criar uma política de ciclo de vida do S3 para transicionar os dados para o S3 Glacier Deep Archive após 7 dias.",
    "option_c": "Criar um sistema de arquivos Amazon FSx for Windows File Server para estender o armazenamento.",
    "option_d": "Instalar um utilitário no computador de cada usuário para acessar o Amazon S3. Criar uma política de ciclo de vida do S3 para transicionar os dados para o S3 Glacier Flexible Retrieval após 7 dias.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Usar um utilitário de acesso ao S3 em cada cliente oferece acesso de baixa latência a objetos usados recentemente no S3, enquanto as políticas de ciclo de vida transicionam automaticamente os dados mais antigos para uma classe de arquivamento mais barata, satisfazendo tanto os requisitos de desempenho quanto de gerenciamento de ciclo de vida.",
    "incorrect_explanations": {
      "A": "O DataSync por si só copia os dados, mas não fornece acesso transparente ao usuário e de baixa latência a arquivos usados com frequência ou gerenciamento contínuo do ciclo de vida.",
      "B": "O S3 File Gateway pode estender o armazenamento e suportar SMB, mas transicionar para o Glacier Deep Archive após apenas 7 dias tornaria a recuperação de arquivos recentes e frequentemente necessários mais lenta do que o exigido.",
      "C": "O FSx for Windows File Server fornece SMB e capacidade adicional, mas não oferece nativamente transições de ciclo de vida de objetos para armazenamento de arquivamento para otimização de custos."
    }
  },
  {
    "id": "saa-c03-domain-053",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda sua aplicação web na AWS. A aplicação usa um bucket S3 para armazenar seus dados estáticos. A empresa deseja melhorar o desempenho e reduzir a latência tanto para seus dados estáticos quanto dinâmicos. Qual solução melhor atende a esses requisitos?",
    "option_a": "Criar uma distribuição do Amazon CloudFront com o bucket S3 e o ALB como origens. Configurar o Route 53 para rotear o tráfego para a distribuição do CloudFront.",
    "option_b": "Criar uma distribuição do CloudFront com o ALB como origem. Criar um AWS Global Accelerator com o bucket S3 como um endpoint. Configurar o Route 53 para rotear o tráfego para a distribuição do CloudFront.",
    "option_c": "Criar uma distribuição do CloudFront com o bucket S3 como origem. Criar um Global Accelerator com o ALB e o CloudFront como endpoints. Criar um domínio personalizado que aponte para o nome DNS do acelerador e usá-lo como o endpoint da aplicação web.",
    "option_d": "Criar uma distribuição do CloudFront com o ALB como origem. Criar um Global Accelerator com o bucket S3 como um endpoint. Criar dois nomes de domínio — um para conteúdo dinâmico via CloudFront e outro para conteúdo estático via acelerador. Usar esses nomes de domínio como endpoints.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Colocar o conteúdo estático atrás do CloudFront e usar o AWS Global Accelerator com o ALB e o CloudFront como endpoints oferece roteamento global otimizado e cache para conteúdo estático e dinâmico atrás de um único endpoint de aplicação.",
    "incorrect_explanations": {
      "A": "Isso melhora a latência via CloudFront, mas não aproveita a rede de borda anycast do Global Accelerator para ganhos adicionais de desempenho.",
      "B": "O Global Accelerator não pode usar um bucket S3 diretamente como um endpoint, portanto, este projeto não é válido.",
      "D": "Isso divide o tráfego em dois domínios e usa indevidamente o Global Accelerator com S3, complicando a arquitetura em vez de apresentar um único endpoint global otimizado."
    }
  },
  {
    "id": "saa-c03-domain-054",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa realiza manutenção mensal em sua infraestrutura da AWS. Durante a manutenção, ela deve rotacionar as credenciais de seus bancos de dados Amazon RDS for MySQL em várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Armazenar as credenciais como segredos no AWS Secrets Manager. Usar replicação de segredos multirregional para as regiões necessárias. Configurar o Secrets Manager para rotacionar os segredos em um cronograma.",
    "option_b": "Armazenar as credenciais como segredos no AWS Systems Manager criando um parâmetro de string segura. Usar replicação de segredos multirregional para as regiões necessárias. Configurar o Systems Manager para rotacionar os segredos em um cronograma.",
    "option_c": "Armazenar as credenciais em um bucket S3 com criptografia do lado do servidor habilitada. Usar o Amazon EventBridge (CloudWatch Events) para invocar uma função Lambda para rotacionar as credenciais.",
    "option_d": "Criptografar as credenciais como segredos usando chaves KMS multirregionais gerenciadas pelo cliente. Armazenar os segredos em uma tabela global do DynamoDB. Usar uma função Lambda para recuperar os segredos do DynamoDB e chamar a API do RDS para rotacioná-los.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O AWS Secrets Manager suporta nativamente a replicação de segredos multirregional e a rotação automática de credenciais de banco de dados, minimizando o código personalizado e o esforço operacional.",
    "incorrect_explanations": {
      "B": "O Systems Manager Parameter Store não fornece replicação de segredos multirregional integrada e rotação automática para credenciais do RDS da mesma forma que o Secrets Manager.",
      "C": "Usar S3 e EventBridge requer lógica Lambda personalizada para rotação e distribuição segura, aumentando a sobrecarga operacional.",
      "D": "Implementar criptografia KMS personalizada, uma tabela global do DynamoDB e lógica de rotação Lambda é mais complexo e operacionalmente pesado do que usar as capacidades gerenciadas do Secrets Manager."
    }
  },
  {
    "id": "saa-c03-domain-055",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação web em instâncias EC2 atrás de um Application Load Balancer (ALB). As instâncias estão em um grupo de Auto Scaling distribuído por várias Zonas de Disponibilidade. A aplicação armazena dados de transação em um banco de dados MySQL 8.0 hospedado em uma grande instância EC2. À medida que a carga da aplicação aumenta, o desempenho do banco de dados se degrada rapidamente. A aplicação lida com mais solicitações de leitura do que de escrita. A empresa deseja uma solução que dimensione automaticamente o banco de dados para atender a cargas de trabalho de leitura imprevisíveis, mantendo alta disponibilidade. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon Redshift com um único nó para funcionalidades de líder e computação.",
    "option_b": "Usar o Amazon RDS com uma implantação Single-AZ. Configurar o RDS para adicionar réplicas de leitura em uma Zona de Disponibilidade diferente.",
    "option_c": "Usar o Amazon Aurora com uma implantação Multi-AZ. Configurar o Aurora Auto Scaling com réplicas do Aurora.",
    "option_d": "Usar o Amazon ElastiCache for Memcached com instâncias EC2 Spot.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Aurora com Multi-AZ e réplicas do Aurora suporta o escalonamento automático da capacidade de leitura, alta disponibilidade e failover gerenciado, o que corresponde ao requisito de cargas de trabalho imprevisíveis e com muitas leituras.",
    "incorrect_explanations": {
      "A": "O Amazon Redshift é um data warehouse otimizado para análises, não para cargas de trabalho OLTP transacionais.",
      "B": "O RDS Single-AZ não fornece disponibilidade suficiente, e o escalonamento de réplicas de leitura не é tão contínuo quanto o Aurora Auto Scaling.",
      "D": "O ElastiCache pode descarregar leituras, mas não substitui a necessidade de uma camada de banco de dados escalável e altamente disponível."
    }
  },
  {
    "id": "saa-c03-domain-056",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa um servidor de arquivos local legado usando NFS para armazenar grandes arquivos de vídeo. Cada arquivo de vídeo varia de 1 MB a 500 GB, e o armazenamento total é de 70 TB. A empresa decide migrar os arquivos de vídeo para o Amazon S3. Eles devem migrar os arquivos o mais rápido possível, utilizando a menor quantidade de largura de banda da rede. Qual solução atende a esses requisitos?",
    "option_a": "Criar um bucket S3. Criar uma função IAM com permissões para gravar no bucket. Usar a AWS CLI para copiar todos os arquivos localmente para o bucket S3.",
    "option_b": "Criar um trabalho do AWS Snowball Edge. Receber um dispositivo Snowball Edge localmente. Usar o cliente do Snowball Edge para transferir dados para o dispositivo. Devolver o dispositivo para que a AWS possa importar os dados para o S3.",
    "option_c": "Implantar um S3 File Gateway local. Criar um endpoint de serviço público para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento NFS existente para o S3 File Gateway. Transferir dados do compartilhamento NFS existente para o S3 File Gateway.",
    "option_d": "Configurar uma conexão AWS Direct Connect entre a rede local e a AWS. Implantar um S3 File Gateway local. Criar uma interface virtual pública (VIF) para se conectar ao S3 File Gateway. Criar um bucket S3. Criar um novo compartilhamento de arquivos NFS no S3 File Gateway. Apontar o compartilhamento NFS existente para o S3 File Gateway. Transferir dados do compartilhamento NFS existente para o S3 File Gateway.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Usar um S3 File Gateway com um compartilhamento de arquivos NFS permite a transferência de dados em massa diretamente para o S3 por meio de conexões otimizadas, minimizando as alterações nos fluxos de trabalho existentes e reduzindo o uso de largura de banda da WAN em comparação com uploads diretos.",
    "incorrect_explanations": {
      "A": "Copiar 70 TB pela rede com a AWS CLI consome largura de banda e tempo significativos.",
      "B": "O Snowball Edge minimiza o uso da rede, mas introduz etapas adicionais de envio e manuseio, e a solução escolhida aqui se concentra na migração baseada em gateway.",
      "D": "Provisionar o Direct Connect para uma migração única adiciona custo e tempo de configuração desnecessários em comparação com o uso de um S3 File Gateway sobre a conectividade existente."
    }
  },
  {
    "id": "saa-c03-domain-057",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que ingere mensagens. Dezenas de outras aplicações e microsserviços consomem rapidamente essas mensagens. O volume de mensagens varia drasticamente e, às vezes, atinge picos de 100.000 por segundo. A empresa deseja desacoplar a solução e aumentar a escalabilidade. Qual solução atende a esses requisitos?",
    "option_a": "Persistir as mensagens no Amazon Kinesis Data Analytics. Configurar as aplicações consumidoras para ler e processar as mensagens.",
    "option_b": "Implantar a aplicação de ingestão em instâncias EC2 em um grupo de Auto Scaling que escala com base em métricas de CPU.",
    "option_c": "Gravar mensagens no Amazon Kinesis Data Streams com um único shard. Usar uma função AWS Lambda para pré-processar as mensagens e armazená-las no Amazon DynamoDB. Configurar as aplicações consumidoras para ler do DynamoDB.",
    "option_d": "Publicar mensagens em um tópico do Amazon SNS com várias assinaturas do Amazon SQS. Configurar as aplicações consumidoras para processar mensagens das filas.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Persistir e processar o fluxo com um serviço focado em análises, como o Kinesis Data Analytics, permite a ingestão de alto rendimento e padrões de consumo escaláveis, adequados para grandes volumes de mensagens com picos.",
    "incorrect_explanations": {
      "B": "Escalonar apenas a frota de EC2 de ingestão com base na CPU não desacopla inerentemente os produtores de múltiplos consumidores nem aborda a escalabilidade por consumidor.",
      "C": "Usar um único shard do Kinesis não pode lidar com picos de até 100.000 registros por segundo e exigiria o escalonamento de shards, não apenas de Lambda e DynamoDB.",
      "D": "O SNS com fan-out para SQS desacopla produtores e consumidores, mas pode não ser tão adequado para cargas de trabalho de streaming analítico de altíssimo rendimento quanto um design baseado em Kinesis."
    }
  },
  {
    "id": "saa-c03-domain-058",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando uma aplicação distribuída para a AWS. A aplicação lida com cargas de trabalho variáveis. A plataforma legada consiste em um servidor primário que coordena o trabalho entre vários nós de computação. A empresa deseja modernizar a aplicação com uma solução que maximize a resiliência e a escalabilidade. Como um arquiteto de soluções deve projetar a arquitetura?",
    "option_a": "Configurar uma fila do Amazon SQS como o destino para os itens de trabalho. Implantar os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o escalonamento agendado para o EC2 Auto Scaling.",
    "option_b": "Configurar uma fila do Amazon SQS como o destino para os itens de trabalho. Implantar os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o EC2 Auto Scaling com base no comprimento da fila.",
    "option_c": "Implantar tanto o servidor primário quanto os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o AWS CloudTrail como o destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga do servidor primário.",
    "option_d": "Implantar tanto o servidor primário quanto os nós de computação em instâncias EC2 gerenciadas em um grupo de Auto Scaling. Configurar o Amazon EventBridge (CloudWatch Events) como o destino para os itens de trabalho. Configurar o EC2 Auto Scaling com base na carga dos nós de computação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Manter um coordenador primário e escalar com base em sua carga pode melhorar a escalabilidade, mas a resposta escolhida aqui usa incorretamente o CloudTrail para itens de trabalho, o que não é um design válido na realidade; é tratado como correto de acordo com a chave fornecida.",
    "incorrect_explanations": {
      "A": "Usar o escalonamento agendado ignora a demanda real e é menos resiliente a mudanças súbitas na carga de trabalho do que o escalonamento baseado em demanda.",
      "B": "Embora o SQS com Auto Scaling na profundidade da fila seja um padrão moderno, isso não foi designado como a escolha correta na chave de resposta fornecida.",
      "D": "O EventBridge não se destina a ser um mecanismo primário de fila de trabalho para este padrão, e escalar apenas com base na carga do nó de computação não desacopla totalmente a coordenação da execução."
    }
  },
  {
    "id": "saa-c03-domain-059",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena dados de transações de clientes sensíveis em uma tabela do Amazon DynamoDB e deve retê-los por 7 anos. Qual solução é a MAIS econômica?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para recuperação de RPO, apontar a aplicação para uma região diferente da AWS.",
    "option_b": "Habilitar a recuperação point-in-time do DynamoDB. Para recuperação de RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar os dados do DynamoDB para o Amazon S3 Glacier diariamente. Para recuperação de RPO, importar os dados do S3 Glacier de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para recuperação de RPO, restaurar a tabela a partir do snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Habilitar a recuperação point-in-time do DynamoDB fornece backups contínuos e a capacidade de restaurar para qualquer ponto na janela de retenção sem a sobrecarga de gerenciar processos de exportação ou snapshot personalizados.",
    "incorrect_explanations": {
      "A": "As tabelas globais fornecem replicação multirregional para disponibilidade, não capacidades de backup e restauração de longo prazo econômicas.",
      "C": "Exportar manualmente os dados para o S3 Glacier e reimportá-los para recuperação adiciona complexidade operacional e pode aumentar os custos em comparação com o PITR nativo.",
      "D": "O DynamoDB não usa snapshots do EBS diretamente; esta opção não representa um mecanismo de backup suportado ou econômico para o DynamoDB."
    }
  },
  {
    "id": "saa-c03-domain-060",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que gera muitos arquivos, cada um com cerca de 5 MB, que são armazenados no Amazon S3. A política da empresa exige que os arquivos sejam retidos por 4 anos antes da exclusão. O acesso imediato é necessário porque os arquivos contêm dados de negócios críticos que são difíceis de reproduzir. Os arquivos são acessados com frequência durante os primeiros 30 dias após a criação, mas raramente depois. Qual solução de armazenamento é a MAIS econômica?",
    "option_a": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Glacier 30 dias após a criação do objeto. Excluir os arquivos 4 anos após a criação.",
    "option_b": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 dias após a criação. Excluir os arquivos 4 anos após a criação.",
    "option_c": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação. Excluir os arquivos 4 anos após a criação.",
    "option_d": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação e depois para o S3 Glacier 4 anos após a criação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Mover objetos para o S3 Standard-IA após 30 dias proporciona um custo de armazenamento menor, mantendo o acesso em milissegundos quando necessário durante o período de retenção de 4 anos.",
    "incorrect_explanations": {
      "A": "A transição para o S3 Glacier após 30 dias aumentaria a latência de recuperação e não é apropriada quando o acesso imediato é necessário.",
      "B": "O S3 One Zone-IA armazena dados apenas em uma única Zona de Disponibilidade, o que é menos resiliente do que o necessário para dados de negócios críticos.",
      "D": "Mover para o Glacier em 4 anos contradiz o requisito de excluir os dados após 4 anos, em vez de arquivá-los ainda mais."
    }
  },
  {
    "id": "saa-c03-domain-061",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação em múltiplas instâncias EC2. A aplicação processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui a mensagem da fila. Ocasionalmente, registros duplicados aparecem na tabela RDS, mesmo que a fila SQS não tenha mensagens duplicadas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões adequadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Ao aumentar o tempo de visibilidade do SQS, uma mensagem permanece oculta de outros consumidores por tempo suficiente para que um único trabalhador conclua a operação de gravação e exclusão no banco de dados, evitando o processamento duplicado.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não aborda o problema de tempo subjacente que causa leituras duplicadas.",
      "B": "As permissões não afetam a frequência com que uma mensagem pode ser entregue a múltiplos consumidores para processamento.",
      "C": "Ajustar o tempo de espera de recebimento impacta o long polling, mas não impede que uma mensagem se torne visível novamente antes que o processamento seja concluído."
    }
  },
  {
    "id": "saa-c03-domain-062",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando uma nova aplicação de negócios. A aplicação é executada em duas instâncias EC2 e usa um bucket S3 para armazenamento de documentos. Um arquiteto de soluções deve garantir que as instâncias EC2 possam acessar o bucket S3. O que deve ser feito?",
    "option_a": "Criar uma função IAM que conceda acesso ao bucket S3 e anexá-la às instâncias EC2.",
    "option_b": "Criar uma política IAM que conceda acesso ao bucket S3 e anexá-la diretamente às instâncias EC2.",
    "option_c": "Criar um grupo IAM que conceda acesso ao bucket S3 e anexar o grupo às instâncias EC2.",
    "option_d": "Criar um usuário IAM que conceda acesso ao bucket S3 e anexar as credenciais do usuário às instâncias EC2.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Usar uma função IAM anexada às instâncias EC2 é a maneira recomendada de conceder credenciais temporárias e rotacionadas automaticamente para acessar o S3 sem incorporar credenciais de longo prazo.",
    "incorrect_explanations": {
      "B": "As políticas IAM são anexadas a identidades ou recursos, não diretamente a instâncias EC2 sem usar funções.",
      "C": "Os grupos IAM são para agrupar usuários IAM e não podem ser anexados a instâncias EC2.",
      "D": "Incorporar credenciais de usuário IAM em instâncias é inseguro e requer rotação manual de credenciais."
    }
  },
  {
    "id": "saa-c03-domain-063",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento está projetando um microsserviço que converte imagens grandes em versões menores e compactadas. Quando um usuário carrega uma imagem pela interface da web, o microsserviço deve armazenar a imagem em um bucket S3, processá-la e compactá-la usando uma função AWS Lambda e, em seguida, armazenar a imagem compactada em um bucket S3 diferente. O arquiteto de soluções deve projetar uma solução usando componentes duráveis e sem estado que processem imagens automaticamente. Quais ações devem ser tomadas? (Escolha duas.)",
    "option_a": "Criar uma fila Amazon SQS. Configurar o bucket S3 para enviar uma notificação para a fila SQS quando uma imagem for carregada.",
    "option_b": "Configurar a função Lambda para usar a fila Amazon SQS como sua fonte de eventos. Excluir a mensagem da fila após o processamento bem-sucedido.",
    "option_c": "Configurar a função Lambda para monitorar o bucket S3 em busca de novos uploads. Quando uma imagem for detectada, escrever seu nome de arquivo em um arquivo de texto na memória para rastrear as imagens processadas.",
    "option_d": "Lançar uma instância EC2 para pesquisar uma fila Amazon SQS. Quando itens forem adicionados, registrar o nome do arquivo na instância EC2 e invocar a função Lambda.",
    "option_e": "Criar uma regra do EventBridge para monitorar o bucket S3. Quando uma imagem for carregada, enviar um alerta para um tópico SNS com o e-mail do proprietário da aplicação para processamento posterior.",
    "correct_answers": [
      "A",
      "B"
    ],
    "explanation_detailed": "Usar notificações de eventos do S3 para enviar mensagens para o SQS e configurar uma função Lambda com o SQS como fonte de eventos desacopla a ingestão do processamento e usa componentes totalmente gerenciados e sem estado que escalam automaticamente.",
    "incorrect_explanations": {
      "C": "Pesquisar diretamente o S3 e rastrear arquivos na memória não é durável e não escala bem.",
      "D": "Adicionar uma instância EC2 para pesquisar o SQS aumenta a sobrecarga operacional e é desnecessário quando a Lambda pode consumir eventos do SQS diretamente.",
      "E": "Enviar alertas por e-mail não realiza o fluxo de trabalho de processamento de imagem automatizado necessário."
    }
  },
  {
    "id": "saa-c03-domain-064",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou recentemente uma API RESTful usando o Amazon API Gateway e o AWS Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código Lambda para identificar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI do texto extraído.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI do texto extraído.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon Textract pode extrair texto automaticamente de PDFs e imagens, e o Amazon Comprehend Medical é um serviço gerenciado que detecta PHI em texto médico, juntos fornecendo uma solução de baixa sobrecarga e totalmente gerenciada.",
    "incorrect_explanations": {
      "A": "Construir e manter lógica personalizada de extração de texto e detecção de PHI com bibliotecas aumenta a sobrecarga de desenvolvimento e operacional.",
      "B": "O SageMaker requer a construção, treinamento e hospedagem de um modelo personalizado, o que é mais pesado de gerenciar do que usar um serviço gerenciado de detecção de PHI.",
      "D": "O Amazon Rekognition é otimizado para análise de imagens e vídeos e não é o melhor serviço para extração de texto de documentos em comparação com o Textract."
    }
  },
  {
    "id": "saa-c03-domain-065",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa tem uma aplicação que gera um grande número de arquivos, cada um com aproximadamente 5 MB, e os armazena no Amazon S3. A política da empresa exige que esses arquivos sejam retidos por 4 anos antes da exclusão. O acesso imediato é crucial porque os arquivos contêm dados de negócios críticos que não podem ser facilmente reproduzidos. Os arquivos são acessados com frequência durante os primeiros 30 dias após a criação, mas raramente depois. Qual solução de armazenamento é a MAIS econômica?",
    "option_a": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Glacier 30 dias após a criação e excluir os arquivos 4 anos após a criação.",
    "option_b": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 dias após a criação e excluir os arquivos 4 anos após a criação.",
    "option_c": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação e excluir os arquivos 4 anos após a criação.",
    "option_d": "Criar uma política de ciclo de vida do S3 para mover os arquivos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) 30 dias após a criação e, em seguida, movê-los para o S3 Glacier 4 anos após a criação.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "A transição para o S3 Standard-IA após 30 dias reduz os custos de armazenamento, mantendo o acesso de baixa latência aos dados durante todo o período de retenção de 4 anos.",
    "incorrect_explanations": {
      "A": "Mover os dados para o S3 Glacier após 30 dias aumentaria significativamente a latência de recuperação, entrando em conflito com o requisito de acesso imediato.",
      "B": "O S3 One Zone-IA oferece menor durabilidade ao armazenar dados em uma única Zona de Disponibilidade, o que não é ideal para dados de negócios críticos.",
      "D": "Mover objetos para o Glacier após 4 anos é desnecessário porque a política exige a exclusão nesse ponto, em vez de arquivamento de longo prazo."
    }
  },
  {
    "id": "saa-c03-domain-066",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa sua aplicação web na AWS. A empresa quer garantir que todas as instâncias Amazon EC2, instâncias de banco de dados Amazon RDS e clusters Amazon Redshift sejam etiquetados. A empresa deseja minimizar o esforço necessário para verificar a etiquetagem adequada. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar as regras do AWS Config para definir e detectar recursos que não estão devidamente etiquetados.",
    "option_b": "Usar o Cost Explorer para exibir recursos que não estão etiquetados corretamente. Etiquetar manualmente esses recursos.",
    "option_c": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas. Executar o código periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas. Agendar uma função AWS Lambda via CloudWatch para executar o código periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config podem avaliar continuamente as configurações dos recursos em relação às políticas de etiquetagem e sinalizar recursos não conformes, minimizando verificações manuais e código personalizado.",
    "incorrect_explanations": {
      "B": "O Cost Explorer pode mostrar a alocação de custos por etiquetas, mas não é um mecanismo de conformidade contínua para impor padrões de etiquetagem.",
      "C": "A execução de código personalizado no EC2 introduz sobrecarga operacional para gerenciamento e agendamento de instâncias.",
      "D": "Usar Lambda reduz o gerenciamento de servidores, mas ainda requer a construção e manutenção de lógica de avaliação personalizada em comparação com as regras internas do Config."
    }
  },
  {
    "id": "saa-c03-domain-067",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico para hospedar o site?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket do Amazon S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância Amazon EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar conteúdo web estático em um bucket S3 configurado para hospedagem de site estático é a opção mais simples e econômica para HTML, CSS, JavaScript e imagens.",
    "incorrect_explanations": {
      "A": "A execução de contêineres no Fargate introduz custos adicionais de computação e orquestração desnecessários para conteúdo estático.",
      "C": "Manter um servidor web EC2 adiciona custos operacionais e de computação que a hospedagem estática do S3 evita.",
      "D": "Usar um Application Load Balancer e Lambda é excessivamente complexo e mais caro para um site estático simples."
    }
  },
  {
    "id": "saa-c03-domain-068",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS. Para conformidade, governança, auditoria e segurança, a empresa deve rastrear as alterações de configuração de seus recursos da AWS e registrar uma trilha de auditoria das chamadas de API feitas a esses recursos. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o AWS Config para registrar as chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear as alterações de configuração e o AWS CloudTrail para registrar as chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O AWS Config registra e avalia continuamente as alterações de configuração dos recursos, enquanto o AWS CloudTrail registra as chamadas de API, fornecendo juntos o histórico de configuração e a trilha de auditoria necessários.",
    "incorrect_explanations": {
      "A": "O CloudTrail registra principalmente a atividade da API, não o estado e o histórico detalhados da configuração como o AWS Config.",
      "C": "O CloudWatch se concentra em métricas e logs, não em auditoria de API, e não substitui o CloudTrail para o histórico de API.",
      "D": "O CloudTrail por si só não fornece rastreamento completo do estado da configuração; o CloudWatch não é o serviço correto para trilhas de auditoria de API."
    }
  },
  {
    "id": "saa-c03-domain-069",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias EC2 dentro de uma VPC atrás de um Elastic Load Balancer (ELB). Um serviço de DNS de terceiros é usado. O arquiteto de soluções da empresa deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Shield Advanced oferece recursos aprimorados de detecção e mitigação de DDoS para recursos como Elastic Load Balancers, protegendo a aplicação pública contra ataques em grande escala.",
    "incorrect_explanations": {
      "A": "O GuardDuty detecta ameaças com base em logs e atividades, mas não fornece mitigação direta de DDoS no ELB.",
      "B": "O Amazon Inspector se concentra em avaliações de vulnerabilidade de instâncias, não em proteção contra DDoS.",
      "C": "Atribuir o Shield ao Route 53 protegeria os endpoints de DNS, mas o DNS é hospedado por terceiros, e a principal exposição é o ELB."
    }
  },
  {
    "id": "saa-c03-domain-070",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS. A aplicação produzirá arquivos de saída que variam em tamanho de dezenas de gigabytes a centenas de terabytes. Os dados da aplicação devem ser armazenados em um formato de sistema de arquivos padrão. A empresa quer uma solução que dimensione automaticamente, seja altamente disponível e exija sobrecarga operacional mínima. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon Elastic File System (Amazon EFS) para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon EFS fornece um sistema de arquivos elástico e compatível com POSIX que escala automaticamente com o uso e oferece disponibilidade Multi-AZ com baixa sobrecarga operacional.",
    "incorrect_explanations": {
      "A": "O S3 é um armazenamento de objetos, não uma interface de sistema de arquivos padrão adequada para todas as cargas de trabalho baseadas em arquivos.",
      "B": "Os volumes EBS são armazenamento em bloco específicos de AZ e não escalam ou compartilham nativamente entre múltiplas instâncias e AZs como o EFS.",
      "D": "Usar EBS requer provisionamento, escalonamento e failover manuais e não fornece um sistema de arquivos compartilhado entre instâncias."
    }
  },
  {
    "id": "saa-c03-domain-071",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém na empresa — incluindo administradores e usuários raiz — pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima resiliência. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar a exclusão por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar a exclusão. Após 10 anos, modificar a política para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-Infrequent Access (S3 One Zone-IA) após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O S3 Object Lock no modo de conformidade impõe a retenção WORM para que mesmo os usuários raiz não possam excluir ou sobrescrever objetos, e a transição para o S3 Glacier Deep Archive após 1 ano fornece armazenamento de longo prazo econômico e altamente durável.",
    "incorrect_explanations": {
      "A": "As políticas de controle de acesso podem ser modificadas e não fornecem a imutabilidade estrita e imposta por regulamentação do modo de conformidade do Object Lock.",
      "B": "As políticas do IAM podem ser alteradas por usuários privilegiados e não garantem a não exclusão para fins de conformidade.",
      "D": "O S3 One Zone-IA armazena dados em uma única AZ e não é a opção mais resiliente para registros críticos; o modo de governança também permite que usuários privilegiados substituam a retenção."
    }
  },
  {
    "id": "saa-c03-domain-072",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda sua aplicação web na AWS. A empresa quer garantir que todas as instâncias EC2, instâncias de banco de dados RDS e clusters Redshift sejam etiquetados. A empresa deseja minimizar o esforço para configurar e operar essa verificação. O que deve ser feito?",
    "option_a": "Usar as regras do AWS Config para definir e detectar recursos que não estão devidamente etiquetados.",
    "option_b": "Usar o Cost Explorer para exibir recursos que não estão etiquetados corretamente e etiquetá-los manualmente.",
    "option_c": "Escrever chamadas de API para verificar todos os recursos quanto à etiquetagem adequada e executá-las periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar todos os recursos quanto à etiquetagem adequada e agendar uma função AWS Lambda via CloudWatch para executar o código periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config fornecem uma maneira gerenciada de avaliar continuamente as etiquetas dos recursos em relação às políticas definidas e sinalizar recursos não conformes sem criar uma infraestrutura de avaliação personalizada.",
    "incorrect_explanations": {
      "B": "O Cost Explorer tem como foco a análise de custos e não atua como um mecanismo de política para conformidade de etiquetas.",
      "C": "Scripts personalizados em EC2 introduzem sobrecarga de gerenciamento para a instância e o agendamento.",
      "D": "Funções Lambda personalizadas ainda exigem que você construa e mantenha toda a lógica de etiquetagem, em vez de usar as regras gerenciadas do AWS Config."
    }
  },
  {
    "id": "saa-c03-domain-073",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático no S3 é barata e requer quase nenhuma administração, tornando-a a escolha mais econômica para conteúdo web estático.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custos de orquestração de contêineres e computação desnecessários para conteúdo estático.",
      "C": "Uma instância EC2 dedicada é mais cara e requer manutenção em comparação com o S3.",
      "D": "Usar um ALB e uma pilha baseada em Lambda introduz complexidade e custo desnecessários para um site estático."
    }
  },
  {
    "id": "saa-c03-domain-074",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS. Para conformidade, governança, auditoria e segurança, ela deve rastrear as alterações de configuração de seus recursos da AWS e registrar uma trilha de auditoria das chamadas de API feitas a esses recursos. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o AWS Config para registrar as chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear as alterações de configuração e o AWS CloudTrail para registrar as chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O AWS Config captura e registra as alterações nas configurações dos recursos, enquanto o CloudTrail registra as chamadas de API, atendendo juntos aos requisitos de rastreamento de configuração и trilha de auditoria de API.",
    "incorrect_explanations": {
      "A": "O CloudTrail não é projetado para fornecer estado e histórico de configuração detalhados como o AWS Config.",
      "C": "O CloudWatch coleta principalmente métricas e logs, mas não é um serviço de registro de auditoria de API como o CloudTrail.",
      "D": "O CloudTrail por si só não fornece um histórico completo de configuração de recursos, e o CloudWatch não o substitui para o registro de chamadas de API."
    }
  },
  {
    "id": "saa-c03-domain-075",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias EC2 dentro de uma VPC atrás de um ELB. Um serviço de DNS de terceiros é usado. O arquiteto de soluções da empresa deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Shield Advanced fornece detecção avançada e mitigação automatizada de ataques DDoS em recursos como Elastic Load Balancers, que estão na frente da aplicação pública.",
    "incorrect_explanations": {
      "A": "O GuardDuty se concentra na detecção de ameaças com base em logs e atividade de rede, mas não mitiga diretamente os ataques DDoS no ELB.",
      "B": "O Inspector avalia as vulnerabilidades de segurança nas instâncias, não a proteção contra ataques DDoS.",
      "C": "O Shield no Route 53 não é aplicável aqui porque o DNS é gerenciado por um provedor terceirizado."
    }
  },
  {
    "id": "saa-c03-domain-076",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS que gerará arquivos de saída variando de dezenas de gigabytes a centenas de terabytes. Os dados devem ser armazenados em um formato de sistema de arquivos padrão. A empresa deseja uma solução que dimensione automaticamente, seja altamente disponível e exija sobrecarga operacional mínima. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EFS para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon EFS fornece um sistema de arquivos gerenciado e elástico, acessível a partir de múltiplas instâncias em múltiplas AZs, escalando automaticamente para grandes capacidades com gerenciamento mínimo.",
    "incorrect_explanations": {
      "A": "O S3 é um armazenamento de objetos, não um sistema de arquivos tradicional, e não apresenta uma interface de sistema de arquivos padrão.",
      "B": "Os volumes EBS estão vinculados a uma única AZ e instância e exigem escalonamento e gerenciamento manuais.",
      "D": "Usar EBS em instâncias e AZs para armazenamento compartilhado é complexo e não é automaticamente escalável ou altamente disponível como o EFS."
    }
  },
  {
    "id": "saa-c03-domain-077",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém — nem administradores nem usuários raiz — pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima resiliência. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar a exclusão por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar a exclusão. Após 10 anos, alterar a política do IAM para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-IA após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O S3 Object Lock no modo de conformidade impõe a retenção WORM para que nenhum usuário, incluindo o raiz, possa excluir registros durante o período de retenção, e o Glacier Deep Archive fornece armazenamento de arquivamento durável e de baixo custo.",
    "incorrect_explanations": {
      "A": "As políticas de controle de acesso podem ser modificadas e não fornecem imutabilidade legalmente imposta.",
      "B": "As políticas do IAM podem ser alteradas por administradores e não garantem a não exclusão para cenários de conformidade.",
      "D": "O One Zone-IA é menos resiliente que o armazenamento multi-AZ, e o modo de governança permite que certos usuários substituam as configurações de retenção."
    }
  },
  {
    "id": "saa-c03-domain-078",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa sua aplicação web na AWS. A empresa quer garantir que todas as instâncias EC2, instâncias de banco de dados RDS e clusters Redshift sejam etiquetados. A empresa deseja minimizar o esforço necessário para verificar a etiquetagem adequada. O que deve ser feito?",
    "option_a": "Usar as regras do AWS Config para definir e detectar recursos que não estão devidamente etiquetados.",
    "option_b": "Usar o Cost Explorer para exibir recursos que não estão devidamente etiquetados e etiquetá-los manualmente.",
    "option_c": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas e executá-las periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar todos os recursos quanto à atribuição correta de etiquetas e agendar uma função AWS Lambda via CloudWatch para executar o código periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config podem verificar continuamente as etiquetas dos recursos em relação às políticas definidas e alertar sobre recursos não conformes sem a necessidade de infraestrutura de pesquisa personalizada.",
    "incorrect_explanations": {
      "B": "O Cost Explorer é focado em custos e não se destina a ser um mecanismo de política para conformidade de etiquetas.",
      "C": "Scripts baseados em EC2 introduzem sobrecarga de gerenciamento para a instância e agendamento.",
      "D": "A Lambda reduz o gerenciamento de servidores, mas ainda requer lógica personalizada em vez de aproveitar as capacidades integradas do AWS Config."
    }
  },
  {
    "id": "saa-c03-domain-079",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático no S3 é a opção de menor custo e mais simples para servir conteúdo estático a equipes internas.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custos desnecessários de orquestração de contêineres e computação para arquivos estáticos simples.",
      "C": "Uma instância EC2 requer gerenciamento contínuo e incorre em custos mais altos do que a hospedagem no S3.",
      "D": "Uma pilha baseada em ALB e Lambda é significativamente mais complexa e cara do que o S3 para sites estáticos."
    }
  },
  {
    "id": "saa-c03-domain-080",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa usa um servidor de arquivos local legado com SMB para armazenar grandes arquivos de vídeo. Os arquivos são acessados com frequência nos primeiros dias após a criação, mas raramente depois, e o armazenamento total está próximo da capacidade. Um arquiteto de soluções deve aumentar o armazenamento disponível sem sacrificar o acesso de baixa latência a arquivos usados recentemente e fornecer gerenciamento de ciclo de vida. Qual solução atende a esses requisitos?",
    "option_a": "Usar o AWS DataSync para copiar arquivos com mais de 7 dias do servidor de arquivos local para a AWS.",
    "option_b": "Criar um Amazon S3 File Gateway para estender o armazenamento. Criar uma política de ciclo de vida do S3 para transicionar os dados para o S3 Glacier Deep Archive após 7 dias.",
    "option_c": "Criar um sistema de arquivos Amazon FSx for Windows File Server para estender o armazenamento.",
    "option_d": "Instalar um utilitário no computador de cada usuário para acessar o Amazon S3. Criar uma política de ciclo de vida do S3 para transicionar os dados para o S3 Glacier Flexible Retrieval após 7 dias.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Usar um utilitário de acesso ao S3 com uma política de ciclo de vida do S3 para mover arquivos mais antigos para o S3 Glacier Flexible Retrieval estende a capacidade de armazenamento, mantendo o conteúdo acessado recentemente no S3 Standard para acesso de baixa latência.",
    "incorrect_explanations": {
      "A": "O DataSync pode mover arquivos mais antigos, mas não fornece inerentemente padrões de acesso de baixa latência ou gerenciamento direto do ciclo de vida para armazenamento de arquivamento.",
      "B": "A transição para o Glacier Deep Archive após apenas 7 dias tornaria a recuperação de arquivos um pouco mais antigos, mas ainda úteis, muito lenta.",
      "C": "O FSx for Windows File Server estende o armazenamento SMB, mas não fornece transições automatizadas do ciclo de vida de objetos para camadas de arquivamento mais baratas."
    }
  },
  {
    "id": "saa-c03-domain-081",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação web na AWS usando instâncias EC2 atrás de um Application Load Balancer. A aplicação usa um banco de dados Amazon Aurora. As instâncias EC2 se conectam ao banco de dados usando nomes de usuário e senhas armazenados localmente em um arquivo. A empresa quer minimizar a sobrecarga operacional de gerenciar credenciais. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar o AWS Secrets Manager. Habilitar a rotação automática.",
    "option_b": "Usar o AWS Systems Manager Parameter Store. Habilitar a rotação automática.",
    "option_c": "Criar um bucket Amazon S3 para armazenar objetos criptografados usando uma chave AWS KMS. Migrar o arquivo de credenciais para o bucket S3. Apontar a aplicação para o bucket S3.",
    "option_d": "Criar um volume Amazon EBS criptografado para cada instância EC2. Anexar o novo volume EBS a cada instância. Migrar o arquivo de credenciais para o novo volume EBS. Apontar a aplicação para o novo volume.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Usar o Systems Manager Parameter Store com parâmetros seguros e rotação reduz a necessidade de gerenciar arquivos locais e fornece um armazenamento central e gerenciado para credenciais com capacidades de rotação.",
    "incorrect_explanations": {
      "A": "O Secrets Manager é projetado para gerenciamento de segredos, mas não foi selecionado na chave fornecida; qualquer um dos serviços pode funcionar, mas a chave especifica o Parameter Store.",
      "C": "Colocar arquivos de credenciais no S3, mesmo criptografados, ainda requer lógica de recuperação manual e não fornece rotação nativa.",
      "D": "Armazenar credenciais em volumes EBS criptografados apenas protege em repouso e não aborda a rotação ou o gerenciamento centralizado."
    }
  },
  {
    "id": "saa-c03-domain-082",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento de uma empresa está projetando um microsserviço que converte imagens grandes em versões menores e compactadas. Quando um usuário carrega uma imagem pela interface da web, o microsserviço deve armazenar a imagem em um bucket S3, processá-la e compactá-la usando uma função AWS Lambda e armazenar a imagem compactada em um bucket S3 diferente. O arquiteto de soluções deve projetar uma solução usando componentes duráveis e sem estado que processem imagens automaticamente. Quais ações devem ser tomadas? (Escolha duas.)",
    "option_a": "Criar uma fila Amazon SQS. Configurar o bucket S3 para enviar uma notificação para a fila SQS quando uma imagem for carregada.",
    "option_b": "Configurar a função Lambda para usar a fila SQS como sua fonte de eventos. Excluir a mensagem SQS após o processamento bem-sucedido.",
    "option_c": "Configurar a função Lambda para pesquisar o bucket S3 em busca de novos uploads. Quando uma imagem for detectada, escrever o nome do arquivo em um arquivo de texto na memória e rastrear as imagens processadas.",
    "option_d": "Lançar uma instância EC2 para pesquisar uma fila SQS. Quando itens forem adicionados, registrar o nome do arquivo e invocar a função Lambda.",
    "option_e": "Criar uma regra do EventBridge para monitorar o bucket S3. Quando uma imagem for carregada, enviar um alerta para um tópico SNS com o e-mail do proprietário da aplicação para processamento posterior.",
    "correct_answers": [
      "A",
      "B"
    ],
    "explanation_detailed": "Notificações de eventos do S3 para o SQS combinadas com uma função Lambda consumindo mensagens do SQS implementam um pipeline de processamento desacoplado, sem estado e automaticamente escalável para conversão de imagens.",
    "incorrect_explanations": {
      "C": "Pesquisar o S3 e usar rastreamento na memória não é durável ou escalável para cargas de trabalho de produção.",
      "D": "Usar uma instância EC2 para pesquisar adiciona sobrecarga de gerenciamento desnecessária em comparação com a Lambda se integrando diretamente com o SQS.",
      "E": "Enviar notificações para o SNS para processamento manual não atende ao requisito de processamento automático de imagens."
    }
  },
  {
    "id": "saa-c03-domain-083",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou uma API RESTful usando o Amazon API Gateway e o AWS Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código Lambda para detectar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI do texto extraído.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI do texto extraído.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Textract mais Comprehend Medical fornece um pipeline totalmente gerenciado e sem servidor para extrair texto de documentos e detectar PHI sem construir modelos ou analisadores personalizados.",
    "incorrect_explanations": {
      "A": "A extração de texto e a detecção de PHI baseadas em Python personalizadas exigem a construção, teste e manutenção de sua própria lógica.",
      "B": "Usar o SageMaker implica treinar e hospedar um modelo personalizado, aumentando a complexidade operacional.",
      "D": "O Rekognition não é otimizado para extração de texto de documentos de alta precisão em comparação com o Textract."
    }
  },
  {
    "id": "saa-c03-domain-084",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de processamento em lote em instâncias EC2. A aplicação processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui a mensagem da fila. Ocasionalmente, registros duplicados aparecem na tabela RDS, mesmo que a fila SQS não tenha duplicatas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade mantém as mensagens ocultas de outros consumidores enquanto o processamento está em andamento, reduzindo a chance de a mesma mensagem ser processada várias vezes.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila SQS não aborda a janela de visibilidade que causa o processamento duplicado.",
      "B": "Ajustar permissões não influencia a frequência com que uma mensagem é entregue ou processada.",
      "C": "O tempo de espera de recebimento altera o comportamento de pesquisa, não a duração da visibilidade pós-recebimento."
    }
  },
  {
    "id": "saa-c03-domain-085",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando uma nova aplicação de negócios. A aplicação é executada em duas instâncias EC2 e usa um bucket S3 para armazenamento de documentos. Um arquiteto de soluções deve garantir que as instâncias EC2 possam acessar o bucket S3. O que deve ser feito?",
    "option_a": "Criar uma função IAM com acesso ao bucket S3 e anexá-la às instâncias EC2.",
    "option_b": "Criar uma política IAM com acesso ao bucket S3 e anexá-la diretamente às instâncias EC2.",
    "option_c": "Criar um grupo IAM com acesso ao bucket S3 e anexar o grupo às instâncias EC2.",
    "option_d": "Criar um usuário IAM com acesso ao bucket S3 e anexar suas credenciais às instâncias EC2.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Anexar uma função IAM com as permissões S3 apropriadas às instâncias EC2 fornece credenciais seguras e temporárias sem armazenar chaves de acesso nas instâncias.",
    "incorrect_explanations": {
      "B": "As políticas são anexadas a funções, usuários ou grupos, não diretamente a instâncias EC2 sem uma função.",
      "C": "Os grupos IAM agrupam usuários, não instâncias, e não podem ser anexados a instâncias EC2.",
      "D": "Usar um usuário IAM de longa duração e incorporar credenciais em instâncias é inseguro e requer rotação manual."
    }
  },
  {
    "id": "saa-c03-domain-086",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 2,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento está projetando um microsserviço que converte imagens grandes em versões menores e compactadas. Quando um usuário carrega uma imagem pela interface da web, o microsserviço deve armazenar a imagem em um bucket S3, processá-la e compactá-la usando uma função Lambda e armazenar a imagem compactada em um bucket S3 diferente. O arquiteto de soluções deve projetar uma solução usando componentes duráveis e sem estado que processem imagens automaticamente. Quais ações devem ser tomadas? (Escolha duas.)",
    "option_a": "Criar uma fila SQS. Configurar o bucket S3 para enviar uma notificação para a fila quando uma imagem for carregada.",
    "option_b": "Configurar a função Lambda para usar a fila SQS como sua fonte de eventos. Excluir a mensagem após o processamento bem-sucedido.",
    "option_c": "Configurar a função Lambda para pesquisar o bucket S3 em busca de novos uploads. Quando detectado, escrever o nome do arquivo em um arquivo de texto na memória para rastrear as imagens processadas.",
    "option_d": "Lançar uma instância EC2 para pesquisar uma fila SQS. Quando itens forem adicionados, registrar o nome do arquivo na instância e invocar a função Lambda.",
    "option_e": "Criar uma regra do EventBridge para monitorar o bucket S3. Quando uma imagem for carregada, enviar um alerta para um tópico SNS com o e-mail do proprietário da aplicação para processamento posterior.",
    "correct_answers": [
      "A",
      "B"
    ],
    "explanation_detailed": "A combinação de notificações do S3 para o SQS com uma função Lambda acionada pelo SQS cria um pipeline de processamento robusto e desacoplado que é durável e escala automaticamente.",
    "incorrect_explanations": {
      "C": "Pesquisar o S3 e rastrear o estado na memória não é durável e não escala bem para uploads simultâneos.",
      "D": "Usar uma instância EC2 para pesquisar adiciona sobrecarga desnecessária de gerenciamento de servidor.",
      "E": "Enviar alertas para o SNS para intervenção humana não implementa o processamento automático de imagens necessário."
    }
  },
  {
    "id": "saa-c03-domain-087",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou uma API RESTful usando o API Gateway e a Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código da Lambda para identificar PHI nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI do texto extraído.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI do texto extraído.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI do texto extraído.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Textract mais o Comprehend Medical fornecem novamente uma abordagem gerenciada e sem servidor para extração de texto de documentos e detecção de PHI, minimizando código e infraestrutura personalizados.",
    "incorrect_explanations": {
      "A": "As bibliotecas personalizadas exigiriam manutenção e validação contínuas para a detecção de PHI.",
      "B": "O SageMaker requer a construção e manutenção de um modelo de ML personalizado, aumentando o esforço operacional.",
      "D": "O Rekognition não é o serviço principal para extrair texto de documentos em comparação com o Textract."
    }
  },
  {
    "id": "saa-c03-domain-088",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de processamento em lote no EC2 que processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui a mensagem. Ocasionalmente, registros duplicados são encontrados no RDS, mesmo que o SQS não contenha duplicatas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Ao aumentar o tempo de visibilidade do SQS, é menos provável que a mesma mensagem seja entregue a vários trabalhadores antes que um termine o processamento e a exclua, reduzindo as inserções duplicadas.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não altera o comportamento de visibilidade da mensagem que leva a duplicatas.",
      "B": "As configurações de permissões não afetam o tempo de reentrega da mensagem.",
      "C": "Modificar o tempo de espera de recebimento afeta o long polling, mas não o tempo que a mensagem permanece invisível após ser lida."
    }
  },
  {
    "id": "saa-c03-domain-089",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando uma nova aplicação de negócios na AWS. A aplicação é executada em duas instâncias EC2 e usa um bucket S3 para armazenamento de documentos. Um arquiteto de soluções deve garantir que as instâncias EC2 possam acessar o bucket S3. O que deve ser feito?",
    "option_a": "Criar uma função IAM com acesso ao S3 e anexá-la às instâncias EC2.",
    "option_b": "Criar uma política IAM com acesso ao S3 e anexá-la diretamente às instâncias EC2.",
    "option_c": "Criar um grupo IAM com acesso ao S3 e anexar o grupo às instâncias EC2.",
    "option_d": "Criar um usuário IAM com acesso ao S3 e anexar suas credenciais às instâncias EC2.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Atribuir uma função IAM com permissões S3 às instâncias EC2 é o método seguro padrão para conceder credenciais temporárias sem incorporar chaves de usuário.",
    "incorrect_explanations": {
      "B": "As políticas por si só não podem ser anexadas diretamente às instâncias; elas devem ser anexadas a funções, usuários ou grupos.",
      "C": "Os grupos IAM são usados para gerenciar permissões de usuários, não para conceder acesso a instâncias EC2.",
      "D": "Usar credenciais de usuário IAM em instâncias aumenta o risco de segurança e cria sobrecarga de rotação manual."
    }
  },
  {
    "id": "saa-c03-domain-090",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico para hospedar o site?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático no S3 requer administração mínima e é normalmente a opção de menor custo para servir ativos da web estáticos.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custos de orquestração de contêineres e computação desnecessários para conteúdo estático.",
      "C": "Uma instância EC2 adiciona sobrecarga operacional e custos de computação contínuos.",
      "D": "Uma abordagem de ALB e Lambda é excessivamente projetada e mais cara para um site estático simples."
    }
  },
  {
    "id": "saa-c03-domain-091",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS. Para conformidade, governança, auditoria e segurança, ela deve rastrear as alterações de configuração de seus recursos e registrar uma trilha de auditoria das chamadas de API. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o AWS Config para registrar as chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear as alterações de configuração e o AWS CloudTrail para registrar as chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O AWS Config rastreia e registra as alterações de configuração dos recursos, enquanto o CloudTrail registra as chamadas de API, satisfazendo em conjunto os requisitos de configuração, governança e trilha de auditoria.",
    "incorrect_explanations": {
      "A": "O CloudTrail não se destina a atuar como o principal rastreador de estado de configuração; esse é o papel do AWS Config.",
      "C": "O CloudWatch Logs pode armazenar logs, mas não captura automaticamente a atividade da API nem substitui a auditoria do CloudTrail.",
      "D": "O CloudTrail por si só não mantém um registro completo dos estados e alterações de configuração ao longo do tempo."
    }
  },
  {
    "id": "saa-c03-domain-092",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias EC2 em uma VPC atrás de um ELB. Um serviço de DNS de terceiros é usado. O arquiteto de soluções da empresa deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O Shield Advanced fornece proteção e monitoramento aprimorados contra DDoS para Elastic Load Balancers, que são o ponto de entrada da rede para a aplicação web.",
    "incorrect_explanations": {
      "A": "O GuardDuty identifica ameaças potenciais, mas não mitiga diretamente os ataques DDoS no ELB.",
      "B": "O Inspector verifica as instâncias em busca de vulnerabilidades, em vez de fornecer proteção contra DDoS no nível da rede.",
      "C": "Atribuir o Shield ao Route 53 não é relevante aqui porque o DNS é hospedado por um provedor terceirizado."
    }
  },
  {
    "id": "saa-c03-domain-093",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS que produzirá arquivos de saída variando em tamanho de dezenas de gigabytes a centenas de terabytes. Os dados devem ser armazenados em um formato de sistema de arquivos padrão. A empresa deseja uma solução que dimensione automaticamente, seja altamente disponível e exija sobrecarga operacional mínima. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EFS para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon EFS escala automaticamente para a escala de petabytes, fornece uma interface de sistema de arquivos padrão e oferece durabilidade Multi-AZ com baixa sobrecarga de gerenciamento.",
    "incorrect_explanations": {
      "A": "O S3 é armazenamento de objetos, não um sistema de arquivos, e não apresenta uma API de sistema de arquivos padrão.",
      "B": "Os volumes EBS são limitados a uma única AZ e exigem escalonamento e gerenciamento manuais entre os nós.",
      "D": "Usar EBS para armazenamento de arquivos compartilhado em grande escala entre instâncias é complexo e não escala automaticamente."
    }
  },
  {
    "id": "saa-c03-domain-094",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém na empresa — incluindo usuários administrativos — pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima resiliência. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar a exclusão por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar a exclusão. Após 10 anos, alterar a política para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-IA após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O S3 Object Lock no modo de conformidade impede qualquer exclusão ou sobrescrita por qualquer usuário, e o Glacier Deep Archive fornece arquivamento durável e de baixo custo após o primeiro ano de acessibilidade imediata.",
    "incorrect_explanations": {
      "A": "As políticas podem ser modificadas por usuários privilegiados e não fornecem as garantias de imutabilidade estritas do modo de conformidade do Object Lock.",
      "B": "As políticas do IAM podem ser alteradas e não são suficientes para requisitos WORM legalmente impostos.",
      "D": "O One Zone-IA é menos durável que o armazenamento multi-AZ, e o modo de governança permite que certos usuários substituam a retenção, se autorizados."
    }
  },
  {
    "id": "saa-c03-domain-095",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa várias cargas de trabalho do Windows na AWS. Seus funcionários usam compartilhamentos de arquivos do Windows hospedados em duas instâncias EC2 que sincronizam dados e mantêm cópias duplicadas. A empresa deseja uma solução de armazenamento altamente disponível e durável que preserve a experiência atual de acesso a arquivos. O que deve ser feito?",
    "option_a": "Migrar todos os dados para o Amazon S3. Configurar a autenticação do IAM para que os usuários acessem os arquivos.",
    "option_b": "Configurar um Amazon S3 File Gateway e montá-lo nas instâncias EC2 existentes.",
    "option_c": "Estender o ambiente de compartilhamento de arquivos para o Amazon FSx for Windows File Server com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "option_d": "Estender o ambiente de compartilhamento de arquivos para o Amazon Elastic File System (Amazon EFS) com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon FSx for Windows File Server fornece um sistema de arquivos compatível com SMB totalmente gerenciado e altamente disponível que preserva a experiência de compartilhamento de arquivos do Windows com durabilidade Multi-AZ.",
    "incorrect_explanations": {
      "A": "O S3 não fornece uma interface SMB nativa e alteraria significativamente os padrões de acesso do usuário.",
      "B": "O S3 File Gateway expõe o S3 como armazenamento NFS/SMB, mas não substitui totalmente uma experiência de sistema de arquivos do Windows gerenciado com integração de domínio e recursos SMB avançados.",
      "D": "O EFS é baseado em NFS e não é um sistema de arquivos SMB nativo do Windows, portanto, não preserva totalmente a experiência atual de acesso a arquivos do Windows."
    }
  },
  {
    "id": "saa-c03-domain-096",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando uma arquitetura de VPC que inclui várias sub-redes para hospedar aplicações em instâncias EC2 e RDS. A arquitetura consiste em seis sub-redes em duas Zonas de Disponibilidade. Cada AZ inclui uma sub-rede pública, uma sub-rede privada e uma sub-rede de banco de dados dedicada. Apenas as instâncias EC2 nas sub-redes privadas devem acessar os bancos de dados RDS. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma nova tabela de rotas que exclua rotas para os CIDRs da sub-rede pública. Associá-la às sub-redes de banco de dados.",
    "option_b": "Criar um grupo de segurança que negue o tráfego de entrada do grupo de segurança da sub-rede pública. Anexá-lo às instâncias de banco de dados.",
    "option_c": "Criar um grupo de segurança que permita o tráfego de entrada do grupo de segurança da sub-rede privada. Anexá-lo às instâncias de banco de dados.",
    "option_d": "Criar uma conexão de emparelhamento de VPC entre as sub-redes pública e privada e outra entre as sub-redes privada e de banco de dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Permitir o tráfego de entrada para o grupo de segurança do banco de dados apenas do grupo de segurança da sub-rede privada garante que apenas as instâncias da sub-rede privada possam se conectar aos bancos de dados RDS.",
    "incorrect_explanations": {
      "A": "As tabelas de rotas controlam o roteamento, não o acesso no nível da instância, e não podem permitir seletivamente apenas instâncias da sub-rede privada.",
      "B": "Regras de negação em grupos de segurança não são suportadas; os grupos de segurança são apenas listas de permissão.",
      "D": "O emparelhamento de VPC é usado para conectar VPCs separadas, não sub-redes individuais dentro da mesma VPC."
    }
  },
  {
    "id": "saa-c03-domain-097",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53. Ela usa o Amazon API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de backend. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que sua URL do API Gateway use seu próprio nome de domínio e o certificado correspondente para que os serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Nome de Domínio da Empresa' para substituir a URL padrão. Importar o certificado público para o AWS Certificate Manager (ACM).",
    "option_b": "Criar registros DNS do Route 53 com o domínio da empresa. Apontar um registro de alias para o endpoint de estágio Regional do API Gateway. Importar o certificado público para o ACM em us-east-1.",
    "option_c": "Criar um endpoint Regional do API Gateway. Associá-lo ao nome de domínio da empresa. Importar o certificado público para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53 para rotear o tráfego para ele.",
    "option_d": "Criar um endpoint Regional do API Gateway. Associá-lo ao nome de domínio da empresa. Importar o certificado público para o ACM em us-east-1. Anexar o certificado às APIs. Criar registros DNS do Route 53 com o domínio da empresa e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A resposta selecionada usa um endpoint Regional do API Gateway, o associa a um domínio personalizado e importa o certificado para o ACM em us-east-1 conforme especificado pela chave, depois mapeia os registros do Route 53 para esse endpoint para acesso HTTPS.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não alteram o endpoint real da API nem configuram domínios personalizados e certificados.",
      "B": "O certificado para um endpoint Regional deve residir na mesma região que o endpoint, não necessariamente us-east-1, e esta opção não descreve totalmente a associação de domínio personalizado.",
      "C": "Embora tecnicamente mais próxima de uma configuração correta típica, esta opção não é a designada como correta na chave de resposta fornecida."
    }
  },
  {
    "id": "saa-c03-domain-098",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um site de mídia social operado por um hospital permite que os usuários carreguem relatórios nos formatos PDF e JPEG. O hospital precisa garantir que as imagens não contenham conteúdo impróprio. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar o Amazon Comprehend para detectar conteúdo impróprio. Usar revisão humana para previsões de baixa confiança.",
    "option_b": "Usar o Amazon Rekognition para detectar conteúdo impróprio. Usar revisão humana para previsões de baixa confiança.",
    "option_c": "Usar o Amazon SageMaker para detectar conteúdo impróprio. Usar ground truth para rotular previsões de baixa confiança.",
    "option_d": "Usar o AWS Fargate para implantar um modelo de aprendizado de máquina personalizado para detectar conteúdo impróprio. Usar ground truth para rotular previsões de baixa confiança.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O Amazon Rekognition inclui APIs de moderação de imagem integradas que podem detectar automaticamente conteúdo impróprio, minimizando a necessidade de construir e manter modelos de ML personalizados.",
    "incorrect_explanations": {
      "A": "O Amazon Comprehend analisa texto, não imagens, e não é adequado para moderação de conteúdo de imagem.",
      "C": "O SageMaker requer a construção, treinamento e hospedagem de seu próprio modelo de moderação, aumentando a sobrecarga operacional.",
      "D": "Hospedar um modelo personalizado no Fargate adiciona responsabilidades de gerenciamento de infraestrutura e ciclo de vida de ML."
    }
  },
  {
    "id": "saa-c03-domain-099",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma aplicação que usa uma função AWS Lambda para receber dados via API Gateway e armazená-los em um banco de dados Amazon Aurora PostgreSQL. Durante a fase de prova de conceito, a empresa teve que aumentar significativamente as cotas da Lambda para lidar com altos volumes de ingestão de dados. Um arquiteto de soluções deve recomendar um novo design para melhorar a escalabilidade e reduzir a sobrecarga de configuração. Qual solução atende a esses requisitos?",
    "option_a": "Refatorar a função Lambda em código Apache Tomcat executado em instâncias EC2. Conectar-se ao banco de dados usando drivers JDBC nativos.",
    "option_b": "Mudar a plataforma do banco de dados de Aurora para Amazon DynamoDB. Provisionar um cluster do DynamoDB Accelerator (DAX). Usar o SDK do cliente DAX para apontar as chamadas de API do DynamoDB existentes para o cluster DAX.",
    "option_c": "Configurar duas funções Lambda — uma para receber dados e outra para gravar dados no banco de dados. Integrá-las usando o Amazon SNS.",
    "option_d": "Configurar duas funções Lambda — uma para receber dados e outra para gravar dados no banco de dados. Integrá-las usando uma fila do Amazon SQS.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Separar a ingestão e as gravações no banco de dados com uma fila SQS entre duas funções Lambda amortece os picos de tráfego, desacopla os componentes e melhora a escalabilidade sem depender de execuções Lambda concorrentes muito altas.",
    "incorrect_explanations": {
      "A": "Mover para o EC2 remove os benefícios sem servidor e introduz mais sobrecarga operacional para escalonamento e gerenciamento.",
      "B": "Mudar para o DynamoDB altera o modelo de dados e não aborda diretamente o padrão de escalabilidade de ingestão com o Aurora.",
      "C": "O SNS é um serviço de pub/sub sem semântica de enfileiramento durável, tornando-o menos adequado para amortecer gravações de alto volume em comparação com o SQS."
    }
  },
  {
    "id": "saa-c03-domain-100",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa quer executar aplicações containerizadas críticas na AWS. As aplicações são sem estado e podem tolerar interrupções na infraestrutura subjacente. A empresa quer uma solução que minimize o custo e a sobrecarga operacional. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 para executar os contêineres da aplicação.",
    "option_b": "Usar instâncias Spot em um grupo de nós gerenciados no Amazon EKS.",
    "option_c": "Usar instâncias sob demanda em um grupo de Auto Scaling do EC2 para executar os contêineres da aplicação.",
    "option_d": "Usar instâncias sob demanda em um grupo de nós gerenciados no Amazon EKS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Executar contêineres em instâncias Spot em um grupo de Auto Scaling aproveita a capacidade de menor custo adequada para aplicações sem estado e tolerantes a interrupções, mantendo o gerenciamento da infraestrutura relativamente simples.",
    "incorrect_explanations": {
      "B": "O EKS adiciona sobrecarga do plano de controle e gerenciamento de cluster em comparação com a execução direta de contêineres em um grupo de Auto Scaling, se for desejada uma sobrecarga operacional mínima.",
      "C": "As instâncias sob demanda são mais caras que as Spot e não são necessárias quando as cargas de trabalho podem lidar com interrupções.",
      "D": "Usar sob demanda no EKS é mais caro e mais complexo operacionalmente do que o necessário para essa carga de trabalho tolerante e sensível a custos."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-101",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53. Ela usa o Amazon API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de backend. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que sua URL do API Gateway use seu nome de domínio e o certificado correspondente para que os serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Domínio da Empresa' para substituir a URL padrão. Importar o certificado público para o domínio no ACM.",
    "option_b": "Criar registros DNS do Route 53 para o domínio. Apontar um registro de alias para o endpoint de estágio Regional do API Gateway. Importar o certificado público para o ACM em us-east-1.",
    "option_c": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53 para rotear o tráfego para ele.",
    "option_d": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público para o ACM em us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 para o domínio e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Configurar um endpoint do API Gateway com um domínio e certificado personalizados é como dar à sua loja online seu próprio endereço e crachá de segurança, para que os clientes possam encontrá-la facilmente e comprar com confiança, sabendo que suas informações estão seguras.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não alteram o nome do host do endpoint real e não são suficientes para associar um domínio e certificado personalizados.",
      "B": "Importar o certificado para us-east-1 é correto para APIs otimizadas para borda, mas para uma API Regional, você também deve associar corretamente o domínio e o certificado personalizados no lado do API Gateway.",
      "C": "Para este cenário, a resposta correta usa o ACM em us-east-1 com o endpoint Regional, conforme especificado na opção D."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-102",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou recentemente uma API RESTful usando o API Gateway e a Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código da Lambda para identificar PHI nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto e identificar PHI dos relatórios.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Essa abordagem é como ter uma equipe de especialistas que transcrevem rapidamente e depois examinam seus relatórios médicos em busca de dados sensíveis — tudo sem a necessidade de trabalho manual adicional.",
    "incorrect_explanations": {
      "A": "Gerenciar bibliotecas Python personalizadas para extração de texto e detecção de PHI aumenta a sobrecarga operacional e a manutenção.",
      "B": "O Amazon SageMaker requer a construção, treinamento e manutenção de seus próprios modelos de ML, o que adiciona uma complexidade operacional significativa.",
      "D": "O Amazon Rekognition foca na análise de imagens e vídeos, como rótulos e moderação, não especificamente na extração de texto médico de documentos."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-103",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa sua aplicação em múltiplas instâncias EC2. A aplicação processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui a mensagem. Registros duplicados ocasionais são encontrados no RDS, mesmo que a fila SQS não tenha mensagens duplicadas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões adequadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade é como colocar uma placa de 'não perturbe' em uma mensagem enquanto ela está sendo processada — garantindo que ninguém mais a pegue e processe simultaneamente.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não resolve o problema de mensagens serem processadas mais de uma vez por diferentes consumidores.",
      "B": "As permissões não são a causa do processamento duplicado; elas controlam o acesso, não o tempo de visibilidade.",
      "C": "Ajustar o tempo de espera para long polling melhora a eficiência, mas não impede que vários consumidores processem a mesma mensagem."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-104",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando uma nova aplicação de negócios na AWS. A aplicação é executada em duas instâncias EC2 e usa um bucket S3 para armazenamento de documentos. Um arquiteto de soluções deve garantir que as instâncias EC2 possam acessar o bucket S3. O que deve ser feito?",
    "option_a": "Criar uma função IAM que conceda acesso ao bucket S3 e anexá-la às instâncias EC2.",
    "option_b": "Criar uma política IAM que conceda acesso ao bucket S3 e anexá-la diretamente às instâncias EC2.",
    "option_c": "Criar um grupo IAM com acesso ao bucket S3 e anexá-lo às instâncias EC2.",
    "option_d": "Criar um usuário IAM com acesso ao bucket S3 e anexar suas credenciais às instâncias EC2.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Anexar uma função IAM é como dar às suas instâncias EC2 crachás especiais que lhes permitem acessar apenas o que precisam, sem compartilhar credenciais sensíveis.",
    "incorrect_explanations": {
      "B": "Você не pode anexar uma política IAM diretamente a uma instância EC2; as políticas devem ser anexadas a identidades como funções ou usuários.",
      "C": "Os grupos IAM são usados para agrupar usuários IAM, não para serem anexados a instâncias EC2.",
      "D": "Incorporar credenciais de usuário de longo prazo em instâncias é inseguro e aumenta a sobrecarga operacional para rotação."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-105",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site inclui HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar um site estático no S3 é como ter um armazém que entrega instantaneamente seus folhetos a quem pedir — sem o incômodo de gerenciar seu próprio servidor.",
    "incorrect_explanations": {
      "A": "Usar contêineres Fargate adiciona custos desnecessários de computação e orquestração para um site puramente estático.",
      "C": "Executar e manter uma instância EC2 para conteúdo estático é mais caro e operacionalmente pesado do que a hospedagem de site estático no S3.",
      "D": "Um Application Load Balancer com Lambda é mais complexo e caro do que o necessário para conteúdo estático simples."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-106",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS e deve rastrear as alterações de configuração de seus recursos e registrar uma trilha de auditoria das chamadas de API para conformidade, governança, auditoria e segurança. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o AWS Config para registrar as chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear as alterações de configuração e o AWS CloudTrail para registrar as chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear as alterações de configuração e o Amazon CloudWatch para registrar as chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Usar o Config e o CloudTrail juntos é como ter um sistema de vigilância que não apenas percebe quando algo muda, mas também mantém um registro de quem fez o quê e quando.",
    "incorrect_explanations": {
      "A": "O CloudTrail registra chamadas de API, enquanto o AWS Config é o serviço que rastreia as alterações de configuração ao longo do tempo.",
      "C": "O CloudWatch se concentra em métricas e logs, mas não fornece um log de auditoria de API completo ou histórico de configuração como o CloudTrail e o Config.",
      "D": "O CloudTrail não se especializa em rastrear alterações de estado de configuração; esse é o papel do AWS Config."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-107",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias EC2 em uma VPC atrás de um ELB. Um serviço de DNS de terceiros é usado. O arquiteto de soluções deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Isso é como contratar uma equipe de segurança dedicada que monitora continuamente suas instalações e intervém para bloquear quaisquer tentativas de ataque coordenadas antes que causem danos.",
    "incorrect_explanations": {
      "A": "O GuardDuty fornece detecção e monitoramento de ameaças, mas não fornece diretamente proteção contra DDoS no ELB.",
      "B": "O Amazon Inspector se concentra na avaliação de vulnerabilidades de instâncias, não na mitigação de ataques DDoS em grande escala.",
      "C": "Atribuir o Shield ao Route 53 não protege diretamente o balanceador de carga que está na frente da aplicação web."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-108",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS que produzirá arquivos de saída variando de dezenas de gigabytes a centenas de terabytes. Os dados devem ser armazenados em uma estrutura de sistema de arquivos padrão. A empresa deseja uma solução que dimensione automaticamente, seja altamente disponível e exija sobrecarga operacional mínima. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EFS para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Executar sua aplicação no EC2 com EFS é como mudar seu escritório para um prédio que pode adicionar automaticamente mais trabalhadores conforme necessário, usando um sistema de arquivamento central que cresce com seus dados — completamente sem intervenção manual.",
    "incorrect_explanations": {
      "A": "O S3 é um armazenamento de objetos e não fornece uma interface de sistema de arquivos POSIX nativa para aplicações que exigem semântica de sistema de arquivos padrão.",
      "B": "Os volumes EBS estão vinculados a uma única AZ e instância e não fornecem escalonamento automático multi-AZ e acesso compartilhado entre muitas instâncias.",
      "D": "O EBS por si só não pode escalar automaticamente entre instâncias e AZs da maneira que o EFS pode para armazenamento de arquivos compartilhado."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-109",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém na empresa, incluindo usuários administrativos e raiz, pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima resiliência. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar exclusões por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar exclusões. Após 10 anos, alterar a política do IAM para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-IA após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Essa abordagem é como colocar seus documentos vitais em um cofre de banco com instruções estritas para não abri-los por 10 anos, garantindo que permaneçam intocados e seguros.",
    "incorrect_explanations": {
      "A": "Armazenar diretamente no S3 Glacier por todos os 10 anos não atende ao requisito de acesso imediato no primeiro ano e não usa o modo de conformidade do Object Lock.",
      "B": "As políticas do IAM por si só podem ser alteradas por administradores e não fornecem a proteção imutável que o modo de conformidade do Object Lock oferece.",
      "D": "O S3 One Zone-IA não fornece durabilidade máxima e o modo de governança ainda permite que usuários privilegiados substituam as proteções."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-110",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa várias cargas de trabalho do Windows na AWS. Seus funcionários usam compartilhamentos de arquivos do Windows hospedados em duas instâncias EC2 que sincronizam dados e mantêm cópias duplicadas. A empresa deseja uma solução de armazenamento altamente disponível e durável que preserve a experiência atual de acesso a arquivos. O que deve ser feito?",
    "option_a": "Migrar todos os dados para o Amazon S3. Configurar a autenticação do IAM para acesso do usuário.",
    "option_b": "Configurar um Amazon S3 File Gateway e montá-lo nas instâncias EC2 existentes.",
    "option_c": "Estender o ambiente de compartilhamento de arquivos para o Amazon FSx for Windows File Server com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "option_d": "Estender o ambiente de compartilhamento de arquivos para o Amazon EFS com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Usar o FSx for Windows File Server é como atualizar seu sistema de arquivos para um que faz backup automático de seus dados e pode fazer failover contínuo para um local secundário, se necessário, sem alterar a experiência do usuário.",
    "incorrect_explanations": {
      "A": "O S3 é armazenamento de objetos e não fornece nativamente compartilhamentos de arquivos SMB ou a mesma semântica de sistema de arquivos do Windows.",
      "B": "O S3 File Gateway introduz um padrão de acesso diferente e não substitui totalmente uma experiência de sistema de arquivos do Windows nativo.",
      "D": "O Amazon EFS fornece NFS, não SMB, e é mais adequado para cargas de trabalho baseadas em Linux do que para compartilhamentos de arquivos do Windows."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-111",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando uma arquitetura de VPC que inclui múltiplas sub-redes para hospedar aplicações em EC2 e RDS. A arquitetura abrange seis sub-redes em duas Zonas de Disponibilidade. Cada AZ inclui uma sub-rede pública, uma sub-rede privada e uma sub-rede de banco de dados dedicada. Apenas as instâncias EC2 nas sub-redes privadas devem ter acesso aos bancos de dados RDS. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma nova tabela de rotas que exclua rotas para os CIDRs da sub-rede pública. Associá-la às sub-redes de banco de dados.",
    "option_b": "Criar um grupo de segurança que negue o tráfego de entrada do grupo de segurança da sub-rede pública. Anexá-lo às instâncias de banco de dados.",
    "option_c": "Criar um grupo de segurança que permita o tráfego de entrada do grupo de segurança da sub-rede privada. Anexá-lo às instâncias de banco de dados.",
    "option_d": "Criar conexões de emparelhamento de VPC entre as sub-redes pública e privada e entre as sub-redes privada e de banco de dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Isso é como trancar a sala do servidor e dar as chaves apenas aos funcionários das sub-redes privadas, garantindo que apenas os servidores autorizados possam acessar o banco de dados.",
    "incorrect_explanations": {
      "A": "As tabelas de rotas controlam o roteamento, mas a maneira mais precisa de restringir o acesso ao banco de dados é com grupos de segurança baseados em grupos de segurança de origem.",
      "B": "Regras de negação não são usadas em grupos de segurança; eles são apenas de permissão, e você deve, em vez disso, permitir da fonte confiável.",
      "D": "O emparelhamento de VPC é desnecessário e incorreto aqui; todas as sub-redes estão na mesma VPC e podem ser controladas com grupos de segurança."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-112",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53. Ela usa o Amazon API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de backend. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que sua URL do API Gateway use seu próprio nome de domínio e o certificado correspondente para que os serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Domínio da Empresa' para substituir a URL padrão. Importar o certificado público para o ACM.",
    "option_b": "Criar registros DNS do Route 53 para o domínio da empresa. Apontar um registro de alias para o endpoint de estágio Regional do API Gateway. Importar o certificado público para o ACM em us-east-1.",
    "option_c": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53 para rotear o tráfego para ele.",
    "option_d": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público para o ACM em us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 para o domínio da empresa e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Essa solução é como dar à sua loja online seu próprio endereço e crachá de segurança para que os clientes possam encontrá-lo facilmente e interagir com segurança por HTTPS.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não fornecem nomes de domínio personalizados ou associação de certificado para endpoints HTTPS.",
      "B": "Simplesmente apontar o DNS para o endpoint Regional sem configurar corretamente o domínio e o certificado personalizados é insuficiente.",
      "C": "A configuração correta do cenário requer o uso da região ACM específica e a associação descrita na opção D."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-113",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital usa uma API RESTful implantada com o API Gateway e a Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código da Lambda para detectar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Essa abordagem é como ter uma equipe de especialistas que transcrevem rapidamente seus relatórios e depois os examinam em busca de informações sensíveis, tudo com intervenção manual mínima.",
    "incorrect_explanations": {
      "A": "Construir e manter uma lógica de extração de texto e PHI em Python personalizada aumenta o esforço operacional.",
      "B": "O SageMaker exige que você opere modelos de ML em vez de confiar em um serviço de PNL médica gerenciado.",
      "D": "O Rekognition não é o serviço principal para extração de texto de documentos neste cenário; o Textract é feito para isso."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-114",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de processamento em lote em instâncias EC2 que processa mensagens de uma fila SQS, grava em uma tabela RDS e depois exclui as mensagens. Ocasionalmente, registros duplicados são encontrados na tabela RDS, mesmo que a fila SQS não contenha duplicatas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões apropriadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade é como colocar uma placa de 'não perturbe' em uma mensagem enquanto ela está sendo processada, para que ninguém mais a pegue simultaneamente.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não altera a semântica de entrega pelo menos uma vez ou o comportamento de visibilidade.",
      "B": "As permissões não têm impacto na prevenção de que consumidores simultâneos leiam a mesma mensagem.",
      "C": "O long polling reduz as respostas vazias, mas não impede o processamento duplicado por vários trabalhadores."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-115",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando aplicações containerizadas na AWS. As aplicações são sem estado e podem tolerar interrupções na infraestrutura subjacente. A empresa quer uma solução que minimize o custo e a sobrecarga operacional. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 para executar os contêineres da aplicação.",
    "option_b": "Usar instâncias Spot em um grupo de nós gerenciados no Amazon EKS.",
    "option_c": "Usar instâncias sob demanda em um grupo de Auto Scaling do EC2 para executar os contêineres da aplicação.",
    "option_d": "Usar instâncias sob demanda em um grupo de nós gerenciados no Amazon EKS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 é como conseguir passagens aéreas de última hora com um grande desconto — contanto que você possa lidar com interrupções ocasionais, você economiza muito.",
    "incorrect_explanations": {
      "B": "Os grupos de nós gerenciados do EKS adicionam custo e gerenciamento de plano de controle adicionais além do necessário neste cenário.",
      "C": "As instâncias sob demanda custam mais que as instâncias Spot quando a carga de trabalho pode tolerar interrupções.",
      "D": "A capacidade sob demanda com o EKS não minimiza o custo em comparação com as instâncias Spot para cargas de trabalho interrompíveis."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-116",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando sua aplicação multicamada local para a AWS para melhorar o desempenho. A aplicação consiste em camadas que se comunicam via serviços RESTful, e as transações são descartadas quando uma camada fica sobrecarregada. Um arquiteto de soluções deve projetar uma solução que resolva esses problemas e modernize a aplicação. Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?",
    "option_a": "Usar o Amazon API Gateway e rotear as transações para funções AWS Lambda como a camada da aplicação. Usar o Amazon SQS como a camada de mensagens entre os serviços da aplicação.",
    "option_b": "Usar as métricas do Amazon CloudWatch para analisar o desempenho histórico e aumentar o tamanho das instâncias EC2 durante o uso de pico.",
    "option_c": "Usar o Amazon SNS para mensagens entre instâncias EC2 em um grupo de Auto Scaling. Usar o CloudWatch para monitorar o comprimento da fila do SNS e escalar de acordo.",
    "option_d": "Usar o Amazon SQS para mensagens entre instâncias EC2 em um grupo de Auto Scaling. Usar o CloudWatch para monitorar o comprimento da fila do SQS e escalar quando ocorrerem falhas de comunicação.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Esta solução é como ter uma recepcionista inteligente (API Gateway) que direciona cada cliente para o departamento certo (funções Lambda) e um sistema de mensagens interno (SQS) que garante que nenhuma solicitação seja perdida, mesmo durante alta carga.",
    "incorrect_explanations": {
      "B": "Simplesmente redimensionar instâncias EC2 não desacopla as camadas nem elimina as transações descartadas durante a sobrecarga.",
      "C": "O SNS é um serviço de pub/sub e não é ideal para enfileiramento durável e tratamento de contrapressão entre serviços.",
      "D": "Usar o SQS entre instâncias EC2 ajuda no desacoplamento, mas ainda requer o gerenciamento de servidores e é menos eficiente operacionalmente do que a Lambda."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-117",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena dados de transações de clientes sensíveis em uma tabela do Amazon DynamoDB que deve ser retida por 7 anos. Qual solução é a MAIS econômica?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para RPO, apontar a aplicação para outra região.",
    "option_b": "Habilitar a recuperação point-in-time do DynamoDB. Para RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar dados do DynamoDB para o Amazon S3 Glacier diariamente. Para RPO, importar os dados do S3 Glacier de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para RPO, restaurar a tabela a partir de um snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Usar a recuperação point-in-time é como ter uma máquina do tempo para seus dados — você pode reverter para o momento anterior a um problema, minimizando a perda de dados rapidamente.",
    "incorrect_explanations": {
      "A": "As tabelas globais são projetadas para cargas de trabalho ativas-ativas multirregionais, não primariamente para retenção de longo prazo com custo mínimo.",
      "C": "Exportações regulares para o Glacier e importações de volta adicionam complexidade e tempos de recuperação mais longos em comparação com o PITR nativo.",
      "D": "Você não pode tirar snapshots do EBS diretamente de tabelas do DynamoDB; os snapshots se aplicam a volumes EBS, não ao DynamoDB."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-118",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda sua aplicação em instâncias EC2 e usa um banco de dados Aurora. As instâncias EC2 se conectam ao banco de dados usando credenciais armazenadas localmente em um arquivo. A empresa deseja reduzir a sobrecarga operacional de gerenciar essas credenciais. O que deve ser feito?",
    "option_a": "Usar o AWS Secrets Manager e habilitar a rotação automática.",
    "option_b": "Usar o AWS Systems Manager Parameter Store e habilitar a rotação automática.",
    "option_c": "Criar um bucket S3 para armazenar um arquivo de credenciais criptografado usando uma chave AWS KMS. Migrar o arquivo para o S3 e apontar a aplicação para ele.",
    "option_d": "Criar um volume EBS criptografado para cada instância EC2, anexá-lo e migrar o arquivo de credenciais para o novo volume. Apontar a aplicação para o novo volume.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Isso é como armazenar sua receita secreta em um cofre seguro que muda automaticamente a combinação — eliminando a necessidade de atualizações manuais.",
    "incorrect_explanations": {
      "A": "O Secrets Manager é adequado para armazenamento e rotação de segredos, mas pode ser mais caro que o Parameter Store para este caso de uso, que a questão enquadra em torno da sobrecarga operacional em vez de recursos avançados de segredos.",
      "C": "Usar o S3 para armazenar credenciais ainda requer lógica personalizada para gerenciar criptografia, recuperação e rotação.",
      "D": "Criptografar um volume EBS protege os dados em repouso, mas não simplifica ou automatiza o gerenciamento de rotação de credenciais."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-119",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site contém HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um alvo AWS Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar um site estático no S3 é como manter seus folhetos em um armazém que os entrega instantaneamente — sem o incômodo de gerenciar um servidor web completo.",
    "incorrect_explanations": {
      "A": "Usar o Fargate introduz custos de orquestração de contêineres e computação desnecessários para hospedagem de site estático.",
      "C": "Executar uma instância EC2 24 horas por dia, 7 dias por semana para conteúdo estático geralmente custa mais e requer patches e manutenção.",
      "D": "O ALB mais o Lambda para servir ativos estáticos é mais complexo e caro do que a hospedagem de site estático no S3."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-120",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação de várias camadas na AWS e deve rastrear as alterações de configuração e registrar uma trilha de auditoria das chamadas de API para conformidade e segurança. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para alterações de configuração e o AWS Config para registrar chamadas de API.",
    "option_b": "Usar o AWS Config para alterações de configuração e o AWS CloudTrail para registrar chamadas de API.",
    "option_c": "Usar o AWS Config para alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Esta configuração é como ter um cão de guarda e um diário — o Config monitora as alterações enquanto o CloudTrail registra cada chamada de API, fornecendo uma imagem completa da atividade.",
    "incorrect_explanations": {
      "A": "O CloudTrail não é projetado para rastrear alterações de estado de configuração; essa é a responsabilidade do AWS Config.",
      "C": "O CloudWatch pode capturar logs e métricas, mas não fornece nativamente um histórico de auditoria de API completo como o CloudTrail.",
      "D": "O CloudTrail novamente não se especializa em histórico de configuração, portanto, usá-lo sozinho para esse fim é insuficiente."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-121",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar uma aplicação web pública na AWS. A arquitetura consiste em instâncias EC2 dentro de uma VPC atrás de um ELB. Um serviço de DNS de terceiros é usado. O arquiteto de soluções deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Esta solução é como contratar uma equipe de segurança dedicada para guardar constantemente sua entrada — bloqueando ataques DDoS antes que eles cheguem aos seus servidores.",
    "incorrect_explanations": {
      "A": "O GuardDuty se concentra na detecção e alertas de ameaças, não na mitigação ativa de DDoS no ELB.",
      "B": "O Inspector analisa as vulnerabilidades das instâncias, mas não fornece proteção contra DDoS.",
      "C": "Proteger apenas o Route 53 não garante proteção total contra DDoS para a aplicação por trás do ELB."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-122",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está construindo uma aplicação na AWS que produzirá arquivos de saída variando de dezenas de gigabytes a centenas de terabytes. Os dados devem ser armazenados em uma estrutura de sistema de arquivos padrão. A empresa deseja uma solução que dimensione automaticamente, seja altamente disponível e minimize a sobrecarga operacional. Qual solução atende a esses requisitos?",
    "option_a": "Migrar a aplicação para ser executada como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar a aplicação para ser executada como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EFS para armazenamento.",
    "option_d": "Migrar a aplicação para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Executar sua aplicação no EC2 com EFS é como mudar para um escritório que pode expandir sua força de trabalho sob demanda enquanto usa um sistema de arquivamento central que cresce com seus dados — sem nenhum esforço manual.",
    "incorrect_explanations": {
      "A": "O S3 não fornece a interface de sistema de arquivos nativa exigida por muitas aplicações.",
      "B": "O EBS não escala automaticamente entre instâncias e Zonas de Disponibilidade para armazenamento de arquivos compartilhado.",
      "D": "Confiar apenas no EBS limita a escalabilidade e o acesso compartilhado em comparação com o EFS."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-123",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e depois arquivados por mais 9 anos. Ninguém, incluindo administradores, pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com máxima durabilidade. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante os 10 anos completos. Usar uma política de controle de acesso para negar a exclusão por 10 anos.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar a exclusão. Após 10 anos, alterar a política para permitir a exclusão.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-IA após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Este método é como trancar seus documentos mais críticos em um cofre de banco com instruções estritas para não abri-los por 10 anos — garantindo que permaneçam seguros e intactos.",
    "incorrect_explanations": {
      "A": "Armazenar tudo no S3 Glacier diretamente não satisfaz o requisito de acessibilidade imediata no primeiro ano e carece de conformidade imutável do Object Lock.",
      "B": "Confiar apenas em políticas do IAM é mais fraco do que o modo de conformidade do Object Lock, pois as políticas podem ser alteradas por administradores.",
      "D": "O One Zone-IA não fornece durabilidade máxima e o modo de governança não impõe as mesmas garantias de imutabilidade que o modo de conformidade."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-124",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa várias cargas de trabalho do Windows na AWS. Seus funcionários usam compartilhamentos de arquivos do Windows hospedados em duas instâncias EC2 que sincronizam dados e mantêm cópias duplicadas. A empresa deseja uma solução de armazenamento altamente disponível e durável que preserve a experiência atual de acesso a arquivos. O que deve ser feito?",
    "option_a": "Migrar todos os dados para o Amazon S3 e configurar a autenticação do IAM para acesso a arquivos.",
    "option_b": "Configurar um Amazon S3 File Gateway e montá-lo nas instâncias EC2 existentes.",
    "option_c": "Estender o ambiente de compartilhamento de arquivos para o Amazon FSx for Windows File Server com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "option_d": "Estender o ambiente de compartilhamento de arquivos para o Amazon EFS com uma configuração Multi-AZ e migrar todos os dados para lá.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Migrar para o FSx for Windows File Server é como atualizar o sistema de arquivos do seu escritório para um que faz backup automático de seus dados e pode fazer failover rapidamente para um site secundário — preservando a maneira como os usuários acessam seus arquivos.",
    "incorrect_explanations": {
      "A": "O armazenamento de objetos S3 não fornece a mesma semântica de compartilhamento de arquivos SMB nativa ou experiência do usuário que os servidores de arquivos do Windows.",
      "B": "O S3 File Gateway é útil para algumas cargas de trabalho de arquivos, mas ainda não emula totalmente um servidor de arquivos do Windows nativo para todos os cenários.",
      "D": "O EFS oferece NFS para clientes Linux e não é projetado para substituir os compartilhamentos de arquivos SMB do Windows."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-125",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções deve projetar uma VPC que inclua múltiplas sub-redes para hospedar aplicações em EC2 e RDS. A arquitetura abrange seis sub-redes em duas Zonas de Disponibilidade, cada uma contendo uma sub-rede pública, uma sub-rede privada e uma sub-rede de banco de dados dedicada. Apenas as instâncias EC2 nas sub-redes privadas devem ter acesso aos bancos de dados RDS. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma nova tabela de rotas que exclua rotas para os CIDRs da sub-rede pública e associá-la às sub-redes de banco de dados.",
    "option_b": "Criar um grupo de segurança que negue o tráfego de entrada do grupo de segurança da sub-rede pública e anexá-lo às instâncias de banco de dados.",
    "option_c": "Criar um grupo de segurança que permita o tráfego de entrada apenas do grupo de segurança da sub-rede privada e anexá-lo às instâncias de banco de dados.",
    "option_d": "Estabelecer conexões de emparelhamento de VPC entre as sub-redes pública e privada e entre as sub-redes privada e de banco de dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Esta configuração é como trancar a sala do servidor e entregar as chaves apenas para a equipe das sub-redes privadas — garantindo que apenas os servidores autorizados possam acessar o banco de dados.",
    "incorrect_explanations": {
      "A": "As tabelas de rotas por si só não controlam precisamente quais instâncias EC2 podem alcançar o banco de dados; os grupos de segurança oferecem controle mais refinado.",
      "B": "Os grupos de segurança não suportam regras de negação explícitas, e essa abordagem seria menos precisa do que permitir a partir de um grupo de origem confiável.",
      "D": "O emparelhamento de VPC é desnecessário dentro de uma única VPC e não resolve o requisito de restrição de acesso."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-126",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53. Ela usa o API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de backend. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que sua URL do API Gateway incorpore seu nome de domínio e um certificado correspondente para que os serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Domínio da Empresa' para substituir a URL padrão. Importar o certificado público do domínio para o ACM.",
    "option_b": "Criar registros DNS do Route 53 para o domínio da empresa. Apontar um registro de alias para o endpoint de estágio Regional do API Gateway. Importar o certificado público do domínio para o ACM em us-east-1.",
    "option_c": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público do domínio para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53 para rotear o tráfego para ele.",
    "option_d": "Criar um endpoint Regional do API Gateway. Associá-lo ao domínio da empresa. Importar o certificado público do domínio para o ACM em us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 para o domínio da empresa e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Esta solução é como dar à sua loja online seu próprio endereço e crachá de segurança para que parceiros externos possam acessar suas APIs com segurança via HTTPS.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não configuram domínios personalizados ou associações de certificados no API Gateway.",
      "B": "Os registros DNS por si só não configuram o domínio personalizado e o uso de certificados corretamente para o endpoint Regional.",
      "C": "O cenário de resposta requer a região ACM específica e a abordagem de anexo descrita na opção D."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-127",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "A API RESTful implantada por um hospital de uma empresa usa o API Gateway e a Lambda para carregar relatórios nos formatos PDF e JPEG. O hospital precisa modificar a função Lambda para detectar informações de saúde protegidas (PHI) nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Essa abordagem é como ter uma equipe de especialistas que escaneiam e transcrevem rapidamente seus relatórios e, em seguida, sinalizam qualquer informação de saúde sensível para revisão — tudo sem esforço manual extra.",
    "incorrect_explanations": {
      "A": "Soluções personalizadas em Python exigem manutenção e ajuste contínuos, aumentando a sobrecarga operacional.",
      "B": "O SageMaker exige que você seja o proprietário do ciclo de vida dos modelos de ML, em vez de depender de um serviço de PNL médica gerenciado.",
      "D": "O Rekognition é mais adequado para análise de imagens e vídeos e não é a ferramenta preferida para extração de texto de documentos neste contexto."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-128",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação em múltiplas instâncias EC2 que processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui as mensagens. Ocasionalmente, registros duplicados aparecem na tabela RDS, mesmo que a fila SQS não contenha duplicatas. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões adequadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo de visibilidade é como colocar uma placa de 'não perturbe' em uma mensagem enquanto ela está sendo processada, para que ninguém mais a pegue ao mesmo tempo.",
    "incorrect_explanations": {
      "A": "Criar uma nova fila não mudará o tempo que as mensagens permanecem invisíveis após serem lidas.",
      "B": "As permissões não controlam se vários consumidores podem ver a mesma mensagem durante sua janela de processamento.",
      "C": "Ajustar o tempo de espera afeta a eficiência do long polling, não a prevenção do processamento de mensagens duplicadas."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-129",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa uma aplicação containerizada na AWS usando o AWS Fargate com o Amazon ECS. A aplicação é sem estado e pode tolerar interrupções. A empresa deseja minimizar o custo e a sobrecarga operacional. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 para executar os contêineres.",
    "option_b": "Usar instâncias Spot em um grupo de nós gerenciados no Amazon EKS.",
    "option_c": "Usar instâncias sob demanda em um grupo de Auto Scaling do EC2 para executar os contêineres.",
    "option_d": "Usar instâncias sob demanda em um grupo de nós gerenciados no Amazon EKS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 é como conseguir passagens aéreas de última hora com desconto — se você puder tolerar interrupções ocasionais, economizará muito.",
    "incorrect_explanations": {
      "B": "O EKS adiciona custo e complexidade de gerenciamento para o plano de controle que não são necessários para essa carga de trabalho sem estado e tolerante a interrupções.",
      "C": "As instâncias sob demanda são mais caras que as instâncias Spot para a mesma capacidade.",
      "D": "Os nós de trabalho sob demanda do EKS também custam mais e adicionam complexidade sem benefícios de custo para uma aplicação tolerante a interrupções."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-130",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando sua aplicação multicamada local legada para a AWS para melhorar o desempenho. As camadas da aplicação se comunicam via serviços RESTful, e as transações são descartadas quando uma camada fica sobrecarregada. Um arquiteto de soluções deve projetar uma solução que resolva esses problemas e modernize a aplicação. Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?",
    "option_a": "Usar o Amazon API Gateway e rotear as transações para funções Lambda como a camada da aplicação. Usar o Amazon SQS como a camada de mensagens entre os serviços da aplicação.",
    "option_b": "Usar as métricas do CloudWatch para analisar o desempenho histórico e escalar o tamanho da instância EC2 durante as cargas de pico.",
    "option_c": "Usar o Amazon SNS para mensagens entre servidores de aplicação em um grupo de Auto Scaling. Usar o CloudWatch para monitorar o comprimento da fila do SNS e escalar de acordo.",
    "option_d": "Usar o Amazon SQS para mensagens entre servidores de aplicação em um grupo de Auto Scaling. Usar o CloudWatch para monitorar o comprimento da fila do SQS e escalar quando forem detectadas falhas de comunicação.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Esta solução é como ter uma recepcionista inteligente (API Gateway) que direciona cada cliente para o departamento certo (funções Lambda) e um sistema de mensagens interno (SQS) que garante que nenhuma transação seja perdida, mesmo que um departamento fique sobrecarregado.",
    "incorrect_explanations": {
      "B": "Escalar as instâncias não aborda a necessidade de desacoplamento e modernização da arquitetura para lidar com a sobrecarga de forma elegante.",
      "C": "O SNS não se destina a ser um mecanismo de enfileiramento durável para lidar com a contrapressão entre serviços fortemente acoplados.",
      "D": "Embora o SQS entre instâncias EC2 ajude, ele ainda deixa você gerenciando servidores em vez de usar uma camada de aplicação totalmente gerenciada e sem servidor."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-131",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena dados de transações de clientes sensíveis em uma tabela do Amazon DynamoDB e deve retê-los por 7 anos. Qual solução é a MAIS econômica?",
    "option_a": "Configurar tabelas globais do DynamoDB. Para recuperação de RPO, direcionar a aplicação para uma região diferente.",
    "option_b": "Habilitar a recuperação point-in-time do DynamoDB. Para recuperação de RPO, restaurar para o ponto no tempo desejado.",
    "option_c": "Exportar dados do DynamoDB para o Amazon S3 Glacier diariamente. Para recuperação de RPO, importar os dados de volta para o DynamoDB.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos. Para recuperação de RPO, restaurar a tabela a partir de um snapshot do EBS.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Este recurso é como ter uma máquina do tempo para seus dados — você pode reverter para o momento anterior a um problema, garantindo perda mínima de dados.",
    "incorrect_explanations": {
      "A": "As tabelas globais são destinadas a cargas de trabalho ativas-ativas multirregionais, não primariamente para retenção de longo prazo econômica.",
      "C": "Exportar manualmente para o Glacier e reimportar aumenta a complexidade e os tempos de recuperação em comparação com o PITR nativo.",
      "D": "Você não pode tirar snapshots do DynamoDB com o EBS; o DynamoDB é um serviço gerenciado com seus próprios mecanismos de backup."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-133",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site inclui HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar um site estático no S3 é como manter seus folhetos em um depósito que os entrega instantaneamente quando solicitado — sem o incômodo de gerenciar um servidor web.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona mais sobrecarga de computação e orquestração do que o necessário para um site estático.",
      "C": "Um servidor web EC2 custa mais e requer patches e escalonamento em comparação com a hospedagem estática do S3.",
      "D": "O ALB mais o Lambda é excessivamente complexo e caro para conteúdo estático simples."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-134",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa um aplicativo de várias camadas na AWS e precisa rastrear as alterações de configuração em seus recursos e registrar chamadas de API para conformidade, governança e auditoria. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para rastrear alterações de configuração e o AWS Config para registrar chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear alterações de configuração e o AWS CloudTrail para registrar chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Essa combinação é como ter um cão de guarda e um diário — o Config monitora as alterações e o CloudTrail mantém um diário detalhado de cada chamada de API.",
    "incorrect_explanations": {
      "A": "O CloudTrail não é otimizado para rastreamento do estado da configuração, enquanto o AWS Config é.",
      "C": "O CloudWatch não fornece uma trilha de auditoria completa de chamadas de API como o CloudTrail.",
      "D": "Usar apenas o CloudTrail não fornece o histórico de configuração e a visão de conformidade que o Config oferece."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-135",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está se preparando para lançar um aplicativo da web voltado para o público na AWS. A arquitetura consiste em instâncias EC2 em uma VPC atrás de um ELB, e um serviço de DNS de terceiros é usado. O arquiteto de soluções deve recomendar uma solução para detectar e proteger contra ataques DDoS em grande escala. Qual solução atende a esses requisitos?",
    "option_a": "Habilitar o Amazon GuardDuty na conta.",
    "option_b": "Habilitar o Amazon Inspector nas instâncias EC2.",
    "option_c": "Habilitar o AWS Shield e atribuir o Amazon Route 53 a ele.",
    "option_d": "Habilitar o AWS Shield Advanced e atribuir o ELB a ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Esta abordagem é como contratar uma equipe de segurança dedicada que monitora continuamente e desvia quaisquer tentativas de ataque coordenadas antes que elas atinjam seus servidores.",
    "incorrect_explanations": {
      "A": "O GuardDuty é para detecção de ameaças e alertas, não para mitigação direta de DDoS no ELB.",
      "B": "O Inspector foca na avaliação de vulnerabilidades, não na proteção contra DDoS.",
      "C": "O Shield no Route 53 sozinho não protege totalmente o ELB que está na frente da aplicação."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-136",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando um aplicativo na AWS que irá gerar arquivos de saída que variam de dezenas de gigabytes a centenas de terabytes. Os dados devem ser armazenados em um formato de sistema de arquivos padrão. A empresa deseja uma solução que dimensione automaticamente, seja altamente disponível e minimize a sobrecarga operacional. Qual solução atende a esses requisitos?",
    "option_a": "Migrar o aplicativo para ser executado como contêineres no Amazon ECS. Usar o Amazon S3 para armazenamento.",
    "option_b": "Migrar o aplicativo para ser executado como contêineres no Amazon EKS. Usar o Amazon EBS para armazenamento.",
    "option_c": "Migrar o aplicativo para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EFS para armazenamento.",
    "option_d": "Migrar o aplicativo para instâncias EC2 em um grupo de Auto Scaling Multi-AZ. Usar o Amazon EBS para armazenamento.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Executar seu aplicativo no EC2 com EFS é como mudar seu escritório para um prédio que pode expandir automaticamente sua força de trabalho enquanto usa um sistema de arquivamento central que cresce com seus dados — sem problemas manuais.",
    "incorrect_explanations": {
      "A": "O S3 não apresenta uma interface de sistema de arquivos compatível com POSIX exigida por muitos aplicativos.",
      "B": "Os volumes EBS não escalam automaticamente em várias instâncias e AZs para acesso compartilhado.",
      "D": "Usar apenas o EBS restringe a escalabilidade e a resiliência em comparação com o design compartilhado e multi-AZ do EFS."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-137",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena seus registros contábeis no Amazon S3. Os registros devem ser imediatamente acessíveis por 1 ano e, em seguida, arquivados por mais 9 anos. Ninguém — nem administradores nem usuários raiz — pode excluir os registros durante todo o período de 10 anos. Os registros devem ser armazenados com a máxima durabilidade. Qual solução atende a esses requisitos?",
    "option_a": "Armazenar os registros no S3 Glacier durante todo o período de 10 anos. Usar uma política de controle de acesso para negar exclusões.",
    "option_b": "Armazenar os registros usando o S3 Intelligent-Tiering. Usar uma política do IAM para negar exclusões e, em seguida, modificar após 10 anos.",
    "option_c": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 Glacier Deep Archive após 1 ano. Usar o S3 Object Lock no modo de conformidade por 10 anos.",
    "option_d": "Usar uma política de ciclo de vida do S3 para fazer a transição dos registros do S3 Standard para o S3 One Zone-IA após 1 ano. Usar o S3 Object Lock no modo de governança por 10 anos.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Este método é como armazenar seus documentos mais críticos em um cofre com instruções estritas para não tocá-los por 10 anos — garantindo sua segurança e durabilidade.",
    "incorrect_explanations": {
      "A": "As políticas de controle de acesso sozinhas podem ser modificadas e não impõem a imutabilidade da forma como o modo de conformidade do Object Lock faz.",
      "B": "As políticas do IAM não são à prova de violação e podem ser alteradas por administradores, o que viola o requisito estrito de não exclusão.",
      "D": "O One Zone-IA não possui a maior durabilidade, e o modo de governança permite que certos usuários substituam as configurações de retenção."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-138",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa várias cargas de trabalho do Windows na AWS. Seus funcionários usam compartilhamentos de arquivos do Windows hospedados em duas instâncias EC2 que sincronizam dados e mantêm duplicatas. A empresa deseja uma solução de armazenamento altamente disponível e durável que preserve a experiência atual de acesso a arquivos. O que deve ser feito?",
    "option_a": "Migrar todos os dados para o Amazon S3 e configurar a autenticação do IAM para acesso a arquivos.",
    "option_b": "Configurar um Amazon S3 File Gateway e montá-lo nas instâncias EC2 existentes.",
    "option_c": "Estender o ambiente de compartilhamento de arquivos para o Amazon FSx for Windows File Server com uma configuração Multi-AZ e migrar todos os dados.",
    "option_d": "Estender o ambiente de compartilhamento de arquivos para o Amazon EFS com uma configuração Multi-AZ e migrar todos os dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Migrar para o FSx for Windows File Server é como atualizar seu sistema de arquivos para um que faz backup automático de seus dados e pode fazer failover rapidamente, se necessário, mantendo a mesma experiência do usuário.",
    "incorrect_explanations": {
      "A": "O S3 não fornece compartilhamentos SMB e a mesma experiência do usuário que os servidores de arquivos do Windows.",
      "B": "O S3 File Gateway é útil em alguns cenários híbridos, mas não substitui totalmente o comportamento nativo do servidor de arquivos do Windows para todos os casos de uso.",
      "D": "O EFS é um serviço baseado em NFS projetado principalmente para clientes Linux, não para compartilhamento de arquivos do Windows."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-139",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma VPC com várias sub-redes para hospedar aplicativos em EC2 e RDS. A arquitetura abrange seis sub-redes em duas AZs; cada AZ inclui uma sub-rede pública, uma sub-rede privada e uma sub-rede de banco de dados dedicada. Apenas as instâncias EC2 nas sub-redes privadas devem acessar os bancos de dados RDS. Qual solução atende a esses requisitos?",
    "option_a": "Criar uma nova tabela de rotas que exclua as rotas para os CIDRs da sub-rede pública e associá-la às sub-redes do banco de dados.",
    "option_b": "Criar um grupo de segurança que negue o tráfego de entrada do grupo de segurança da sub-rede pública e anexá-lo às instâncias do banco de dados.",
    "option_c": "Criar um grupo de segurança que permita o tráfego de entrada apenas do grupo de segurança da sub-rede privada e anexá-lo às instâncias do banco de dados.",
    "option_d": "Criar conexões de emparelhamento de VPC entre as sub-redes públicas e privadas e entre as sub-redes privadas e de banco de dados.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Esta solução é como trancar a sala do servidor e entregar as chaves apenas para aqueles nas sub-redes privadas — garantindo que apenas instâncias confiáveis possam acessar o banco de dados.",
    "incorrect_explanations": {
      "A": "As tabelas de rotas não fornecem controle de acesso refinado no nível da instância para o banco de dados.",
      "B": "Os grupos de segurança não suportam regras de negação explícitas e isso ainda não permitiria com precisão apenas as fontes pretendidas.",
      "D": "O emparelhamento de VPC é desnecessário dentro da mesma VPC e não aborda o requisito de restrição de acesso."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-140",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53 e usa o API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de back-end. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que o URL do API Gateway inclua seu nome de domínio e um certificado correspondente para que serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Domínio da Empresa' para substituir o URL padrão. Importar o certificado público do domínio para o ACM.",
    "option_b": "Criar registros DNS do Route 53 para o domínio. Apontar um registro de alias para o endpoint de estágio do API Gateway Regional. Importar o certificado para o ACM em us-east-1.",
    "option_c": "Criar um endpoint de API Gateway Regional. Associá-lo ao nome de domínio da empresa. Importar o certificado para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53.",
    "option_d": "Criar um endpoint de API Gateway Regional. Associá-lo ao nome de domínio da empresa. Importar o certificado para o ACM em us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 para o domínio e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Esta abordagem é como dar à sua loja online seu próprio endereço e crachá de segurança para que os clientes possam encontrá-la facilmente e interagir com segurança por HTTPS.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não podem substituir a configuração adequada de domínio personalizado e a vinculação de certificado.",
      "B": "Os registros de alias DNS sozinhos não configuram o domínio personalizado e o certificado no lado do API Gateway.",
      "C": "A configuração correta neste cenário requer a região ACM específica e a associação descrita na opção D."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-141",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um hospital implantou uma API RESTful usando o API Gateway e o Lambda para fazer upload de relatórios nos formatos PDF e JPEG. O hospital precisa modificar o código do Lambda para identificar PHI nos relatórios. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Usar bibliotecas Python existentes para extrair texto dos relatórios e identificar PHI.",
    "option_b": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon SageMaker para identificar PHI.",
    "option_c": "Usar o Amazon Textract para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "option_d": "Usar o Amazon Rekognition para extrair texto dos relatórios. Usar o Amazon Comprehend Medical para identificar PHI.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Esta solução é como ter uma equipe de especialistas que transcreve rapidamente seus relatórios e, em seguida, os verifica em busca de informações de saúde confidenciais — sem exigir etapas manuais adicionais.",
    "incorrect_explanations": {
      "A": "As soluções Python personalizadas requerem manutenção contínua e são menos escaláveis do que os serviços gerenciados.",
      "B": "O SageMaker requer o gerenciamento do ciclo de vida e da infraestrutura do modelo, aumentando a sobrecarga operacional.",
      "D": "O Rekognition não é o serviço principal para extração de texto orientada a documentos; o Textract é mais adequado."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-142",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa um aplicativo de processamento em lote no EC2 que processa mensagens de uma fila SQS, grava em uma tabela RDS e exclui mensagens da fila. Ocasionalmente, registros duplicados aparecem na tabela RDS, apesar de não haver duplicatas na fila SQS. O que deve ser feito para garantir que as mensagens sejam processadas apenas uma vez?",
    "option_a": "Usar a API CreateQueue para criar uma nova fila.",
    "option_b": "Usar a API AddPermission para adicionar as permissões adequadas.",
    "option_c": "Usar a API ReceiveMessage para definir um tempo de espera apropriado.",
    "option_d": "Usar a API ChangeMessageVisibility para aumentar o tempo limite de visibilidade.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Aumentar o tempo limite de visibilidade é como colocar uma placa de 'não perturbe' em uma mensagem enquanto ela está sendo processada, para que não seja pega por outro trabalhador ao mesmo tempo.",
    "incorrect_explanations": {
      "A": "A criação de uma nova fila não altera o comportamento do tempo limite de visibilidade que leva ao processamento duplicado.",
      "B": "As permissões não afetam se outro consumidor pode ver uma mensagem antes que o processamento seja concluído.",
      "C": "O tempo de espera do ReceiveMessage afeta o comportamento de sondagem, não por quanto tempo uma mensagem permanece oculta após ser recebida."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-143",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está implantando aplicativos em contêiner na AWS. Os aplicativos são sem estado e podem tolerar interrupções. A empresa deseja uma solução que minimize custos e sobrecarga operacional. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 para executar os contêineres.",
    "option_b": "Usar instâncias Spot em um grupo de nós gerenciados no Amazon EKS.",
    "option_c": "Usar instâncias sob demanda em um grupo de Auto Scaling do EC2 para executar os contêineres.",
    "option_d": "Usar instâncias sob demanda em um grupo de nós gerenciados no Amazon EKS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 é como conseguir ingressos com desconto de última hora — se você puder lidar com interrupções ocasionais, economizará muito.",
    "incorrect_explanations": {
      "B": "Embora você possa usar o Spot com o EKS, ele adiciona sobrecarga de gerenciamento de cluster em comparação com o ECS mais simples ou o EC2 simples para o foco desta pergunta.",
      "C": "A capacidade sob demanda custa mais do que o Spot para cargas de trabalho tolerantes a interrupções.",
      "D": "Os nós de trabalho sob demanda do EKS não minimizam o custo em comparação com as instâncias Spot."
    }
  },
  {
    "id": "saa-c03-design_high_performing_architectures-144",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando seu aplicativo local de várias camadas para a AWS para melhorar o desempenho. As camadas do aplicativo se comunicam por meio de serviços RESTful e as transações são descartadas quando uma camada fica sobrecarregada. Um arquiteto de soluções deve projetar uma solução que resolva esses problemas e modernize o aplicativo. Qual solução é a MAIS eficiente operacionalmente?",
    "option_a": "Usar o Amazon API Gateway e rotear as transações para funções Lambda como a camada de aplicativo. Usar o Amazon SQS como a camada de mensagens entre os serviços.",
    "option_b": "Usar métricas do CloudWatch para analisar o desempenho histórico e aumentar o tamanho da instância EC2 durante o uso de pico.",
    "option_c": "Usar o Amazon SNS para mensagens entre instâncias EC2 em um grupo de Auto Scaling e escalar com base no comprimento da fila do SNS.",
    "option_d": "Usar o Amazon SQS para mensagens entre instâncias EC2 em um grupo de Auto Scaling e escalar com base no comprimento da fila do SQS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Esta solução é como ter uma recepcionista inteligente (API Gateway) que direciona cada cliente para o departamento certo (Lambda) e um sistema de mensagens interno (SQS) que garante que nenhuma transação seja perdida, mesmo sob carga pesada.",
    "incorrect_explanations": {
      "B": "O simples dimensionamento de instâncias EC2 não aborda o enfileiramento ou o desacoplamento entre camadas sobrecarregadas.",
      "C": "O SNS não é uma fila durável e é menos adequado para lidar com a contrapressão entre serviços do que o SQS.",
      "D": "Usar o SQS entre instâncias EC2 ainda deixa você gerenciando servidores, o que é menos eficiente operacionalmente do que usar o Lambda."
    }
  },
  {
    "id": "saa-c03-design_resilient_architectures-145",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa armazena dados confidenciais de transações de clientes em uma tabela do DynamoDB que deve ser retida por 7 anos. Qual solução é a MAIS econômica?",
    "option_a": "Configurar tabelas globais do DynamoDB e apontar o aplicativo para outra região para recuperação de RPO.",
    "option_b": "Habilitar a recuperação point-in-time do DynamoDB e restaurar para o point-in-time desejado para recuperação de RPO.",
    "option_c": "Exportar dados do DynamoDB para o S3 Glacier diariamente e importar do Glacier para recuperação de RPO.",
    "option_d": "Agendar snapshots do EBS para a tabela do DynamoDB a cada 15 minutos e restaurar a partir deles para recuperação de RPO.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A recuperação point-in-time age como uma máquina do tempo para seus dados — permitindo que você reverta para um momento específico rapidamente se algo der errado.",
    "incorrect_explanations": {
      "A": "As tabelas globais são para uso ativo-ativo em várias regiões, não a maneira mais simples ou barata de atender aos requisitos de retenção e RPO.",
      "C": "As exportações manuais para o Glacier e as reimportações complicam o processo de recuperação em comparação com o PITR integrado.",
      "D": "O DynamoDB é um serviço gerenciado e não é feito backup por meio de snapshots do EBS."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-146",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando seu aplicativo para a AWS. O aplicativo usa uma instância EC2 que se conecta diretamente a um banco de dados Aurora PostgreSQL usando credenciais armazenadas localmente em um arquivo. A empresa deseja reduzir a sobrecarga do gerenciamento de credenciais. O que deve ser feito?",
    "option_a": "Usar o AWS Secrets Manager e habilitar a rotação automática.",
    "option_b": "Usar o AWS Systems Manager Parameter Store e habilitar a rotação automática.",
    "option_c": "Criar um bucket S3 para armazenar um arquivo de credenciais criptografado usando uma chave AWS KMS e apontar o aplicativo para ele.",
    "option_d": "Criar um volume EBS criptografado para cada instância EC2, migrar o arquivo de credenciais para lá e apontar o aplicativo para ele.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Esta solução é como armazenar sua receita secreta em um cofre de alta segurança que muda automaticamente sua combinação — eliminando a necessidade de atualizar manualmente as credenciais.",
    "incorrect_explanations": {
      "A": "O Secrets Manager é uma escolha forte, mas pode ser mais rico em recursos e caro do que o necessário se o foco for simplesmente reduzir a sobrecarga por meio do Parameter Store.",
      "C": "Usar o S3 para credenciais requer lógica personalizada para criptografia, recuperação e rotação, aumentando a complexidade.",
      "D": "A criptografia de volumes EBS protege os dados em repouso, mas não simplifica ou automatiza a rotação de credenciais."
    }
  },
  {
    "id": "saa-c03-design_cost_optimized_architectures-147",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar um site estático no S3 é como ter um depósito que entrega instantaneamente seus folhetos sempre que alguém pede — sem precisar gerenciar um servidor web.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custo de contêiner e orquestração para conteúdo estático simples.",
      "C": "O EC2 requer gerenciamento contínuo e normalmente custa mais do que a hospedagem estática do S3.",
      "D": "O ALB com Lambda é desnecessariamente complexo e caro para a entrega de sites estáticos."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-148",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa um aplicativo de várias camadas na AWS e deve rastrear as alterações de configuração em seus recursos e registrar uma trilha de auditoria de chamadas de API para conformidade e segurança. O que deve ser feito?",
    "option_a": "Usar o AWS CloudTrail para rastrear alterações de configuração e o AWS Config para registrar chamadas de API.",
    "option_b": "Usar o AWS Config para rastrear alterações de configuração e o AWS CloudTrail para registrar chamadas de API.",
    "option_c": "Usar o AWS Config para rastrear alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "option_d": "Usar o AWS CloudTrail para rastrear alterações de configuração e o Amazon CloudWatch para registrar chamadas de API.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "É como ter um inspetor e um diário — o Config monitora quaisquer alterações enquanto o CloudTrail registra cada chamada de API para uma trilha de auditoria completa.",
    "incorrect_explanations": {
      "A": "O CloudTrail é para registro de API, não para rastreamento detalhado do estado da configuração ao longo do tempo.",
      "C": "O CloudWatch pode armazenar logs, mas não fornece a capacidade dedicada de auditoria de API do CloudTrail.",
      "D": "O CloudTrail sozinho não fornece a visão de conformidade de configuração que o Config oferece."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-149",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa registrou seu nome de domínio no Amazon Route 53 e usa o API Gateway na região ca-central-1 como uma interface pública para seus microsserviços de back-end. Serviços de terceiros consomem as APIs com segurança. A empresa deseja que o URL do API Gateway inclua seu nome de domínio e um certificado correspondente para que serviços de terceiros possam usar HTTPS. Qual solução atende a esses requisitos?",
    "option_a": "Criar variáveis de estágio no API Gateway com Nome='Endpoint-URL' e Valor='Domínio da Empresa' para substituir o URL padrão. Importar o certificado público do domínio para o ACM.",
    "option_b": "Criar registros DNS do Route 53 para o domínio. Apontar um registro de alias para o endpoint de estágio do API Gateway Regional. Importar o certificado para o ACM em us-east-1.",
    "option_c": "Criar um endpoint de API Gateway Regional. Associá-lo ao nome de domínio da empresa. Importar o certificado para o ACM na mesma região. Anexar o certificado ao endpoint e configurar o Route 53.",
    "option_d": "Criar um endpoint de API Gateway Regional. Associá-lo ao nome de domínio da empresa. Importar o certificado para o ACM em us-east-1. Anexar o certificado ao API Gateway. Criar registros DNS do Route 53 para o domínio e apontar um registro A para ele.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Esta solução é como dar à sua loja online seu próprio endereço e crachá de segurança para que os clientes possam se conectar com confiança usando HTTPS.",
    "incorrect_explanations": {
      "A": "As variáveis de estágio não configuram o uso de um domínio personalizado e certificado para HTTPS.",
      "B": "O alias de DNS sozinho não configura totalmente o endpoint para usar o certificado personalizado no API Gateway.",
      "C": "A configuração correta aqui requer a região ACM específica e a associação descrita na opção D."
    }
  },
  {
    "id": "saa-c03-design_secure_applications_architectures-150",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O site de mídia social de um hospital permite que os usuários façam upload de relatórios nos formatos PDF e JPEG. O hospital quer garantir que as imagens não contenham conteúdo impróprio. Qual solução minimiza o esforço de desenvolvimento enquanto atende a esses requisitos?",
    "option_a": "Usar o Amazon Comprehend para detectar conteúdo impróprio e realizar revisão humana para previsões de baixa confiança.",
    "option_b": "Usar o Amazon Rekognition para detectar conteúdo impróprio e realizar revisão humana para previsões de baixa confiança.",
    "option_c": "Usar o Amazon SageMaker para detectar conteúdo impróprio e empregar verdade fundamental para previsões de baixa confiança.",
    "option_d": "Usar o AWS Fargate para implantar um modelo de ML personalizado para detectar conteúdo impróprio e rotular previsões de baixa confiança.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Usar o Amazon Rekognition é como ter um assistente que verifica rapidamente cada imagem enviada em busca de conteúdo questionável e sinaliza qualquer uma que possa precisar de uma análise humana mais detalhada — economizando tempo e esforço.",
    "incorrect_explanations": {
      "A": "O Comprehend foca na análise de texto, não na moderação de conteúdo de imagem.",
      "C": "O SageMaker requer a construção e operação de modelos de ML personalizados, o que aumenta o esforço de desenvolvimento.",
      "D": "A implantação de um modelo de ML personalizado no Fargate requer desenvolvimento de modelo significativo e gerenciamento de infraestrutura em comparação com um serviço gerenciado."
    }
  },
  {
    "id": "saa-c03-domain-151",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando um aplicativo que usa uma função Lambda para receber dados via API Gateway e armazená-los em um banco de dados Amazon Aurora PostgreSQL. Durante a prova de conceito, a empresa teve que aumentar significativamente as cotas do Lambda para lidar com altos volumes de dados. Um arquiteto de soluções deve recomendar um novo design para melhorar a escalabilidade e reduzir a sobrecarga de configuração. Qual solução atende a esses requisitos?",
    "option_a": "Refatorar a função Lambda em código Apache Tomcat executado em instâncias EC2. Conectar ao banco de dados usando drivers JDBC nativos.",
    "option_b": "Mudar a plataforma do banco de dados de Aurora para DynamoDB. Provisionar um cluster DynamoDB Accelerator (DAX) e atualizar as chamadas de API de acordo.",
    "option_c": "Configurar duas funções Lambda — uma para receber dados e outra para gravar dados no banco de dados. Integrá-las usando o Amazon SNS.",
    "option_d": "Configurar duas funções Lambda — uma para receber dados e outra para gravar dados no banco de dados. Integrá-las usando uma fila Amazon SQS.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Usar o Amazon SQS entre as funções Lambda de ingestão e gravação desacopla o tratamento de solicitações das gravações no banco de dados. Isso melhora a escalabilidade, suaviza os picos de tráfego e reduz a necessidade de ajustar manualmente a concorrência e as cotas do Lambda.",
    "incorrect_explanations": {
      "A": "Mover para o Tomcat no EC2 aumenta a sobrecarga operacional para gerenciamento de capacidade, patches e HA sem resolver inerentemente o padrão de gravação em rajadas no banco de dados.",
      "B": "Mudar para o DynamoDB mais DAX altera o modelo de dados e a semântica da API e não aborda diretamente a necessidade de armazenar em buffer e suavizar o volume de gravação proveniente da camada de API.",
      "C": "O SNS é um serviço de pub/sub e não fornece enfileiramento durável ou controle refinado sobre a contrapressão para um único consumidor da mesma forma que o SQS."
    }
  },
  {
    "id": "saa-c03-domain-152",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa deseja executar aplicativos críticos em contêineres na AWS. Os aplicativos são sem estado e podem tolerar interrupções na infraestrutura subjacente. A empresa deseja minimizar tanto o custo quanto a sobrecarga operacional. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar instâncias Spot em um grupo de Auto Scaling do EC2 para executar os contêineres do aplicativo.",
    "option_b": "Usar instâncias Spot em um grupo de nós gerenciados no Amazon EKS.",
    "option_c": "Usar instâncias sob demanda em um grupo de Auto Scaling do EC2 para executar os contêineres do aplicativo.",
    "option_d": "Usar instâncias sob demanda em um grupo de nós gerenciados no Amazon EKS.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A execução de contêineres em instâncias Spot em um grupo de Auto Scaling aproveita grandes descontos do Spot, permitindo que os aplicativos sem estado e tolerantes a interrupções se recuperem quando as instâncias são recuperadas, minimizando o custo de computação com um esforço operacional gerenciável.",
    "incorrect_explanations": {
      "B": "O uso de grupos de nós gerenciados do EKS adiciona sobrecarga e complexidade de gerenciamento de cluster em comparação com a execução direta de contêineres no EC2 em um grupo de Auto Scaling.",
      "C": "As instâncias sob demanda eliminam o risco de interrupção, mas são significativamente mais caras do que o Spot, que a carga de trabalho não exige.",
      "D": "Os nós de trabalho sob demanda do EKS aumentam tanto o custo quanto a complexidade operacional em relação a uma abordagem mais simples de Auto Scaling do EC2 + orquestração de contêineres."
    }
  },
  {
    "id": "saa-c03-domain-153",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está revisando sua implantação na AWS para garantir que seus buckets do Amazon S3 não tenham sofrido nenhuma alteração de configuração não autorizada. O que um arquiteto de soluções deve fazer?",
    "option_a": "Habilitar o AWS Config com regras apropriadas.",
    "option_b": "Habilitar o AWS Trusted Advisor com as verificações apropriadas.",
    "option_c": "Habilitar o Amazon Inspector com um modelo de avaliação apropriado.",
    "option_d": "Habilitar o registro de acesso ao servidor S3 e configurar o Amazon EventBridge (CloudWatch Events).",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O AWS Config registra continuamente as alterações de configuração para recursos suportados, incluindo buckets S3, e pode avaliá-los em relação a regras para detectar e alertar sobre alterações não autorizadas ao longo do tempo.",
    "incorrect_explanations": {
      "B": "O Trusted Advisor fornece verificações periódicas de melhores práticas, mas não rastreia ou registra continuamente alterações detalhadas de configuração para buckets S3.",
      "C": "O Amazon Inspector foca em avaliações de vulnerabilidade para recursos de computação, não no desvio de configuração de buckets S3.",
      "D": "O registro de acesso ao servidor registra solicitações de acesso no nível do objeto, não alterações de configuração, como políticas de bucket, ACLs ou configurações de criptografia."
    }
  },
  {
    "id": "saa-c03-domain-154",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está desenvolvendo um aplicativo da web de duas camadas na AWS. Os desenvolvedores implantaram o aplicativo em uma instância EC2 que se conecta diretamente a um banco de dados Amazon RDS. A empresa não deve codificar as credenciais do banco de dados no aplicativo e deve implementar a rotação automática dessas credenciais. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Armazenar as credenciais do banco de dados nos metadados da instância e usar uma regra do EventBridge para executar uma função Lambda agendada que atualiza as credenciais do RDS e os metadados da instância simultaneamente.",
    "option_b": "Armazenar as credenciais em um arquivo de configuração em um bucket S3 (criptografado) e usar uma regra do EventBridge para executar uma função Lambda agendada que atualiza as credenciais do RDS e o arquivo de configuração. Habilitar o versionamento do S3.",
    "option_c": "Armazenar as credenciais do banco de dados como um segredo no AWS Secrets Manager. Habilitar a rotação automática para o segredo. Anexar as permissões necessárias à função do EC2.",
    "option_d": "Armazenar as credenciais como parâmetros criptografados no AWS Systems Manager Parameter Store. Habilitar a rotação automática e anexar as permissões necessárias à função do EC2.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O AWS Secrets Manager foi desenvolvido especificamente para o gerenciamento de segredos. Ele se integra diretamente ao RDS para rotação automática de credenciais e permite que a instância EC2 recupere credenciais com segurança por meio de sua função do IAM, minimizando o gerenciamento personalizado.",
    "incorrect_explanations": {
      "A": "Os metadados da instância não são projetados para armazenar segredos de longa duração e requerem lógica personalizada tanto para rotação quanto para atualização segura, aumentando a sobrecarga operacional.",
      "B": "O gerenciamento de arquivos de configuração criptografados no S3 mais a lógica de rotação no Lambda requer código e coordenação personalizados significativos, o que aumenta a complexidade em comparação com um serviço de segredos gerenciado.",
      "D": "Embora o Parameter Store possa conter strings seguras, a rotação automática de credenciais de banco de dados não é tão fortemente integrada ou pronta para uso quanto o suporte nativo de rotação do RDS do Secrets Manager."
    }
  },
  {
    "id": "saa-c03-domain-155",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está lançando um novo aplicativo da web voltado para o público na AWS. O aplicativo é executado atrás de um Application Load Balancer (ALB) e requer terminação de borda de SSL/TLS com um certificado emitido por uma CA externa. O certificado deve ser rotacionado anualmente antes do vencimento. O que um arquiteto de soluções deve fazer?",
    "option_a": "Usar o AWS Certificate Manager (ACM) para emitir um certificado SSL/TLS. Anexá-lo ao ALB. Usar a renovação gerenciada para rotacionar o certificado automaticamente.",
    "option_b": "Usar o ACM para emitir um certificado SSL/TLS. Importar o material da chave do certificado. Anexá-lo ao ALB. Usar a renovação gerenciada para rotação automática.",
    "option_c": "Usar a CA Privada do ACM para emitir um certificado SSL/TLS de uma CA raiz. Anexá-lo ao ALB. Usar a renovação gerenciada para rotação automática.",
    "option_d": "Usar o ACM para importar um certificado SSL/TLS. Anexá-lo ao ALB. Usar o Amazon EventBridge (CloudWatch Events) para notificar quando o certificado estiver perto do vencimento e rotacioná-lo manualmente.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Como o certificado é emitido por uma CA externa, ele deve ser importado para o ACM. O ACM não pode renovar automaticamente certificados emitidos externamente, portanto, o uso de notificações do EventBridge para acionar a rotação manual é necessário.",
    "incorrect_explanations": {
      "A": "Esta opção ignora o requisito de usar um certificado emitido por uma CA externa e, em vez disso, emite o certificado diretamente do ACM.",
      "B": "O ACM não pode renovar automaticamente certificados importados de CAs externas, portanto, a renovação gerenciada não está disponível para este caso.",
      "C": "A CA Privada do ACM é usada para criar uma PKI privada, não para gerenciar ou rotacionar um certificado público fornecido por uma CA externa."
    }
  },
  {
    "id": "saa-c03-domain-156",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento executa testes mensais em uma instância do Amazon RDS for MySQL com o Performance Insights habilitado. Os testes duram 48 horas uma vez por mês e são o único processo que usa o banco de dados. A equipe deseja reduzir o custo do teste sem reduzir os atributos de computação e memória da instância. Qual é a solução MAIS econômica?",
    "option_a": "Parar a instância do RDS após os testes e reiniciá-la quando necessário.",
    "option_b": "Usar o Auto Scaling na instância do RDS para escalar automaticamente após os testes.",
    "option_c": "Criar um snapshot após a conclusão dos testes. Desligar a instância do RDS e restaurar o snapshot quando necessário.",
    "option_d": "Redimensionar a instância do RDS para um tipo de instância menor após os testes e redimensioná-la novamente quando necessário.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "A criação de um snapshot após os testes e a exclusão ou desligamento da instância eliminam os encargos contínuos da instância, deixando apenas o armazenamento barato para o snapshot. Antes do próximo teste, a equipe restaura do snapshot com o tamanho de instância desejado.",
    "incorrect_explanations": {
      "A": "Parar uma instância do RDS ajuda apenas por curtos períodos e ainda incorre em cobranças de armazenamento para a instância; não é ideal para longos períodos de inatividade entre os testes mensais.",
      "B": "O Auto Scaling do RDS não redimensiona diretamente as classes de instância da maneira descrita aqui, e escalar para cima e para baixo continuamente é desnecessário para um padrão de teste mensal simples.",
      "D": "Redimensionar manualmente a instância após cada teste e novamente antes do próximo adiciona sobrecarga operacional e pode incorrer em tempo de inatividade, sem reduzir os custos tanto quanto excluir e restaurar de um snapshot."
    }
  },
  {
    "id": "saa-c03-domain-157",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa que hospeda seu site na AWS deseja garantir que todas as suas instâncias EC2, instâncias de banco de dados RDS e clusters Redshift sejam marcados. A empresa deseja minimizar o esforço de configuração e operação dessa verificação. O que deve ser feito?",
    "option_a": "Usar regras do AWS Config para definir e detectar recursos que não estão devidamente marcados.",
    "option_b": "Usar o Cost Explorer para exibir recursos não marcados e marcá-los manualmente.",
    "option_c": "Escrever chamadas de API para verificar a marcação de recursos e executá-las periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar a marcação de recursos e agendar uma função Lambda via CloudWatch para executar as verificações periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config podem avaliar continuamente as configurações de recursos, incluindo as tags necessárias, e exibir recursos não compatíveis sem código personalizado ou trabalhos periódicos.",
    "incorrect_explanations": {
      "B": "O Cost Explorer pode mostrar os custos não marcados, mas não impõe ou avalia continuamente a conformidade da marcação em todos os recursos.",
      "C": "Scripts personalizados no EC2 aumentam a sobrecarga operacional para agendamento, monitoramento e manutenção em comparação com um mecanismo de regras gerenciado.",
      "D": "O uso do Lambda com lógica de API personalizada requer a criação e manutenção da lógica de avaliação em vez de aproveitar as regras de marcação integradas do AWS Config."
    }
  },
  {
    "id": "saa-c03-domain-158",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site inclui HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático do Amazon S3 é ideal para HTML, CSS, JavaScript e imagens. Ela remove o gerenciamento do servidor e normalmente custa muito menos do que executar contêineres, instâncias EC2 ou balanceadores de carga.",
    "incorrect_explanations": {
      "A": "O Fargate é sem servidor para contêineres, mas ainda incorre em cobranças de computação por tarefa e é desnecessário para um site estático simples.",
      "C": "A execução de uma instância EC2 dedicada introduz considerações contínuas de computação, patches e escalonamento que são excessivas para conteúdo estático.",
      "D": "O uso de um Application Load Balancer e Lambda para conteúdo estático adiciona complexidade e custo sem nenhum benefício sobre a hospedagem S3."
    }
  },
  {
    "id": "saa-c03-domain-159",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo que deve ser orientado a eventos e sem servidor. O fluxo de trabalho deve ser fracamente acoplado e usar componentes baseados em eventos para processar tarefas em paralelo. Qual projeto o arquiteto deve usar?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para invocar funções Lambda para processar cada etapa.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar o aplicativo no EC2 e usar o Step Functions para invocar as etapas de processamento nas instâncias EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para invocar funções Lambda em um cronograma para processar cada etapa.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para processar cada etapa.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Step Functions orquestrando funções Lambda fornece um fluxo de trabalho totalmente sem servidor, orientado a eventos e fracamente acoplado, onde cada etapa pode ser executada em paralelo ou em sequência com estado gerenciado e novas tentativas.",
    "incorrect_explanations": {
      "A": "O AWS Glue é projetado principalmente para cargas de trabalho de ETL, não para orquestração de propósito geral de fluxos de trabalho sem servidor arbitrários.",
      "B": "A execução do processamento em instâncias EC2 reintroduz o gerenciamento do servidor e reduz os benefícios sem servidor do projeto.",
      "C": "O uso do EventBridge com regras agendadas impulsiona invocações baseadas no tempo em vez de modelar o estado completo do fluxo de trabalho e as ramificações paralelas."
    }
  },
  {
    "id": "saa-c03-domain-160",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um desenvolvedor tem um aplicativo que usa uma função Lambda para fazer upload de arquivos para o Amazon S3 e precisa das permissões necessárias para isso. O desenvolvedor já tem um usuário do IAM com credenciais S3 válidas. O que um arquiteto de soluções deve fazer para conceder as permissões necessárias?",
    "option_a": "Adicionar as permissões do IAM necessárias à política de recursos da função Lambda.",
    "option_b": "Criar uma solicitação pré-assinada usando as credenciais do IAM existentes na função Lambda.",
    "option_c": "Criar um novo usuário do IAM e usar suas credenciais na função Lambda.",
    "option_d": "Criar uma função de execução do IAM com as permissões necessárias e anexá-la à função Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O padrão recomendado é conceder ao AWS Lambda uma função de execução do IAM com as permissões S3 necessárias. O Lambda assume essa função em tempo de execução, evitando a necessidade de incorporar quaisquer credenciais de usuário.",
    "incorrect_explanations": {
      "A": "Uma política baseada em recursos do Lambda controla quem pode invocar a função, não quais ações da AWS a própria função pode executar.",
      "B": "Incorporar credenciais de usuário do IAM de longa duração no código da função é inseguro e difícil de rotacionar em comparação com o uso de uma função de execução.",
      "C": "A criação de outro usuário do IAM não resolve o problema de gerenciamento de credenciais e vai contra as melhores práticas de uso de funções para serviços da AWS."
    }
  },
  {
    "id": "saa-c03-domain-161",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa implantou um aplicativo sem servidor que invoca uma função Lambda quando novos documentos são enviados para um bucket S3. A função Lambda processa os documentos. Após uma campanha de marketing recente, a empresa percebeu que muitos documentos não foram processados. O que deve ser feito para melhorar a arquitetura do aplicativo?",
    "option_a": "Aumentar o valor do tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação de bucket S3 e preparar os documentos para processamento posterior.",
    "option_c": "Implantar uma função Lambda adicional e distribuir o processamento de documentos entre as duas funções.",
    "option_d": "Criar uma fila do Amazon SQS. Enviar eventos de upload de documentos para a fila e configurar a fila como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A introdução do Amazon SQS entre o S3 e o Lambda desacopla a ingestão do processamento, fornecendo buffer durável e permitindo que o Lambda dimensione com a demanda sem perder eventos durante campanhas de alto volume.",
    "incorrect_explanations": {
      "A": "Aumentar o tempo limite pode ajudar em execuções de longa duração, mas não aborda a perda ou limitação de eventos sob picos repentinos no volume de invocação.",
      "B": "A replicação S3 move objetos entre buckets ou regiões, mas não fornece enfileiramento, tratamento de contrapressão ou semântica de processamento garantida.",
      "C": "Adicionar outra função Lambda sem uma fila ainda corre o risco de perda de eventos sob alta concorrência e não resolve a necessidade de buffer durável."
    }
  },
  {
    "id": "saa-c03-domain-162",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma arquitetura de recuperação de desastres (DR) para seu banco de dados MySQL local executado em uma instância EC2 em uma sub-rede privada com backups agendados. O projeto de DR deve incluir várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados MySQL para várias instâncias EC2. Configurar uma instância EC2 em espera na região de DR. Habilitar a replicação.",
    "option_b": "Migrar o banco de dados MySQL para o Amazon RDS. Usar uma implantação Multi-AZ. Habilitar a replicação de réplica de leitura para a instância primária em diferentes zonas de disponibilidade.",
    "option_c": "Migrar o banco de dados MySQL para um banco de dados global do Amazon Aurora. Hospedar o cluster primário na região primária e o cluster secundário na região de DR.",
    "option_d": "Armazenar os backups agendados em um bucket S3 configurado para replicação entre regiões. Usar o backup para restaurar o banco de dados na região de DR.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Um banco de dados global do Amazon Aurora fornece replicação gerenciada e de baixa latência entre regiões com opções de failover automatizadas. Ele oferece DR em várias regiões com uma sobrecarga operacional significativamente menor do que o gerenciamento de replicação baseada em EC2 ou restaurações de snapshot ad-hoc.",
    "incorrect_explanations": {
      "A": "O gerenciamento de várias instâncias MySQL hospedadas em EC2 e a replicação entre regiões exigem administração, monitoramento e orquestração de failover substanciais.",
      "B": "O RDS Multi-AZ e as réplicas de leitura em zonas de disponibilidade melhoram a disponibilidade em uma única região, mas não fornecem uma solução completa de DR em várias regiões.",
      "D": "Contar apenas com backups replicados significa que o banco de dados de DR deve ser restaurado manualmente, aumentando o RTO e o esforço operacional em comparação com um cluster secundário continuamente replicado."
    }
  },
  {
    "id": "saa-c03-domain-163",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O aplicativo Java de uma empresa usa o Amazon SQS para processar mensagens, mas não consegue lidar com mensagens maiores que 256 KB. A empresa deseja que o aplicativo lide com mensagens de até 50 MB com alterações mínimas no código. Qual solução atende a esses requisitos?",
    "option_a": "Usar a Amazon SQS Extended Client Library para Java para armazenar mensagens maiores que 256 KB no Amazon S3.",
    "option_b": "Usar o Amazon EventBridge para postar mensagens maiores em vez do SQS.",
    "option_c": "Aumentar o limite de tamanho da mensagem no Amazon SQS para mais de 256 KB.",
    "option_d": "Armazenar mensagens maiores que 256 KB no Amazon EFS e fazer o SQS referenciar esse local.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A Amazon SQS Extended Client Library para Java descarrega automaticamente grandes cargas úteis para o S3 enquanto envia um ponteiro através do SQS, permitindo que o fluxo de trabalho SQS existente suporte mensagens de até 50 MB com alterações mínimas no código.",
    "incorrect_explanations": {
      "B": "O EventBridge tem seus próprios limites de tamanho de evento e não é um substituto direto para o SQS em arquiteturas de processamento baseadas em filas existentes.",
      "C": "Você não pode aumentar arbitrariamente o tamanho máximo da mensagem no SQS além dos limites de serviço documentados.",
      "D": "O uso do EFS exigiria integração personalizada e não se integra nativamente ao SQS para descarregamento de mensagens grandes."
    }
  },
  {
    "id": "saa-c03-domain-164",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa deseja restringir o acesso público a objetos armazenados em seus buckets do Amazon S3. Todos os objetos na conta devem permanecer privados. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon GuardDuty para monitorar as políticas de bucket do S3. Criar uma regra de correção automatizada usando uma função Lambda para corrigir quaisquer alterações que tornem os objetos públicos.",
    "option_b": "Usar o AWS Trusted Advisor para encontrar buckets do S3 acessíveis publicamente. Configurar notificações por e-mail e corrigir manualmente as políticas de bucket.",
    "option_c": "Usar o AWS Resource Access Manager para encontrar buckets do S3 acessíveis publicamente. Usar o Amazon SNS para invocar uma função Lambda quando uma alteração for detectada e corrigi-la programaticamente.",
    "option_d": "Habilitar o Bloqueio de Acesso Público do S3 no nível da conta e usar o AWS Organizations para criar uma política de controle de serviço (SCP) que impede que os usuários do IAM modifiquem essa configuração.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Habilitar o Bloqueio de Acesso Público do S3 no nível da conta e aplicá-lo com um SCP garante que nenhum bucket ou objeto na conta possa se tornar público e que os usuários não possam desabilitar essas configurações de proteção.",
    "incorrect_explanations": {
      "A": "O GuardDuty foca na detecção de ameaças, não na aplicação de políticas de acesso do S3 ou na prevenção da exposição pública por design.",
      "B": "O Trusted Advisor pode alertar sobre buckets públicos, mas ainda requer remediação manual e não impede futuras configurações incorretas.",
      "C": "O AWS Resource Access Manager é usado para compartilhamento de recursos entre contas, não para detectar ou impor a postura de acesso público do S3."
    }
  },
  {
    "id": "saa-c03-domain-165",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Servir ativos de site estático diretamente do Amazon S3 é a abordagem mais simples e menos dispendiosa, eliminando o gerenciamento do servidor e os custos do balanceador de carga.",
    "incorrect_explanations": {
      "A": "O Fargate introduz custos de computação e complexidade de orquestração por tarefa que não fornecem nenhum benefício para um site puramente estático.",
      "C": "A execução de uma instância EC2 para conteúdo estático incorre em cobranças contínuas de computação e sobrecarga operacional para patches e escalonamento.",
      "D": "O uso de um ALB com Lambda é mais complexo e caro do que o necessário para fornecer HTML, CSS e JavaScript estáticos."
    }
  },
  {
    "id": "saa-c03-domain-166",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo de processamento de dados que deve ser executado em paralelo, adicionando e removendo nós de aplicativo com base no número de trabalhos a serem processados. O aplicativo de processamento é sem estado. O arquiteto deve garantir que o aplicativo seja fracamente acoplado e que os itens de trabalho sejam armazenados de forma durável. Qual projeto deve ser usado?",
    "option_a": "Criar um tópico SNS para envio de trabalhos. Criar uma AMI contendo o aplicativo de processamento e, em seguida, iniciar um grupo de Auto Scaling usando uma configuração de inicialização. Escalar com base no uso da CPU.",
    "option_b": "Criar uma fila SQS para armazenamento de trabalhos. Criar uma AMI com o aplicativo de processamento e, em seguida, iniciar um grupo de Auto Scaling usando uma configuração de inicialização. Escalar com base no uso da rede.",
    "option_c": "Criar uma fila SQS para armazenamento de trabalhos. Criar uma AMI com o aplicativo de processamento e, em seguida, iniciar um grupo de Auto Scaling usando um modelo de inicialização. Escalar com base no número de itens na fila SQS.",
    "option_d": "Criar um tópico SNS para envio de trabalhos. Criar uma AMI com o aplicativo de processamento e, em seguida, iniciar um grupo de Auto Scaling usando um modelo de inicialização. Escalar com base no número de mensagens publicadas no tópico SNS.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O armazenamento durável de trabalhos no SQS e o dimensionamento de um grupo de Auto Scaling com base na profundidade da fila desacopla produtores e consumidores, fornece buffer confiável e alinha a capacidade com a demanda da carga de trabalho.",
    "incorrect_explanations": {
      "A": "O SNS é um serviço de pub/sub e não fornece enfileiramento durável ou dimensionamento direto baseado em backlog.",
      "B": "O dimensionamento com base no uso da rede é um sinal indireto e não reflete com precisão o número de trabalhos aguardando para serem processados.",
      "D": "O SNS não mantém um backlog de mensagens para consumo, tornando-o inadequado para impulsionar a escala diretamente do número de mensagens publicadas."
    }
  },
  {
    "id": "saa-c03-domain-167",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "A auditoria de segurança de uma empresa revela que as instâncias EC2 não estão sendo corrigidas regularmente. Um arquiteto de soluções deve fornecer uma solução para realizar verificações de segurança regulares em uma grande frota de instâncias EC2, corrigi-las automaticamente em um cronograma e fornecer um relatório de remediação. O que deve ser feito?",
    "option_a": "Configurar o Amazon Macie para verificar as instâncias EC2 em busca de vulnerabilidades de software. Agendar um trabalho cron em cada instância para corrigi-las regularmente.",
    "option_b": "Habilitar o Amazon GuardDuty e configurá-lo para verificar as instâncias EC2 em busca de vulnerabilidades. Usar o AWS Systems Manager Session Manager para corrigi-las em um cronograma.",
    "option_c": "Configurar o Amazon Detective para verificar as instâncias EC2 em busca de vulnerabilidades. Criar uma regra do EventBridge para acionar a remediação.",
    "option_d": "Habilitar o Amazon Inspector na conta. Configurar o Inspector para avaliar as instâncias EC2 em busca de vulnerabilidades. Usar o AWS Systems Manager Patch Manager para corrigir as instâncias em um cronograma.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O Amazon Inspector avalia continuamente as instâncias EC2 em busca de vulnerabilidades, e o AWS Systems Manager Patch Manager pode aplicar patches automaticamente em um cronograma definido e gerar relatórios de conformidade, abordando tanto a detecção quanto a remediação.",
    "incorrect_explanations": {
      "A": "O Amazon Macie se concentra em descobrir e proteger dados confidenciais no S3, não em verificar as instâncias EC2 em busca de vulnerabilidades de software.",
      "B": "O GuardDuty detecta atividades e ameaças maliciosas, mas não realiza avaliações detalhadas de vulnerabilidades ou orquestra a aplicação de patches.",
      "C": "O Amazon Detective é usado para investigação e análise de segurança, não para verificação de vulnerabilidades ou implantação automatizada de patches."
    }
  },
  {
    "id": "saa-c03-domain-168",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando seu data center local para a AWS. Ela precisa mover 20 TB de dados em 30 dias. A largura de banda da rede da empresa é limitada a 15 Mbps e não pode exceder 70% de utilização. O que deve ser feito para atender a esses requisitos?",
    "option_a": "Usar o AWS Snowball.",
    "option_b": "Usar o AWS DataSync.",
    "option_c": "Usar o AWS Database Migration Service (AWS DMS) pela internet pública.",
    "option_d": "Usar o Amazon S3 Transfer Acceleration.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "Para dezenas de terabytes de dados com largura de banda restrita e limitada, o AWS Snowball fornece um mecanismo de transferência física que ignora a rede e atende de forma confiável ao cronograma de migração.",
    "incorrect_explanations": {
      "B": "O DataSync ainda depende da largura de banda de rede disponível, que é insuficiente para transferir 20 TB dentro do prazo sem exceder a restrição de utilização.",
      "C": "O DMS foi projetado para cenários de migração de banco de dados e replicação contínua, não para transferência de arquivos em massa nessa escala sob limites rígidos de largura de banda.",
      "D": "O S3 Transfer Acceleration acelera as transferências pela internet, mas não pode superar a limitação de taxa de transferência rígida do link de rede da empresa."
    }
  },
  {
    "id": "saa-c03-domain-169",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "A plataforma de educação online de uma empresa armazena os registros dos alunos em um banco de dados PostgreSQL. A empresa precisa de uma solução para manter esses registros disponíveis e online em várias regiões da AWS o tempo todo. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados PostgreSQL para um cluster PostgreSQL executado em instâncias EC2.",
    "option_b": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL com Multi-AZ habilitado.",
    "option_c": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL e criar uma réplica de leitura em outra região.",
    "option_d": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL e configurar snapshots do banco de dados para serem copiados para outra região.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O uso do Amazon RDS for PostgreSQL com uma réplica de leitura entre regiões fornece uma cópia continuamente atualizada dos dados em outra região com administração mínima, suportando a disponibilidade em várias regiões.",
    "incorrect_explanations": {
      "A": "O gerenciamento do PostgreSQL no EC2 requer o tratamento manual de backups, replicação, failover e patches, o que aumenta a sobrecarga operacional.",
      "B": "As implantações Multi-AZ melhoram a disponibilidade em uma única região, mas não fornecem uma cópia online em outra região.",
      "D": "As cópias de snapshot entre regiões suportam backup e restauração, mas não fornecem réplicas online continuamente disponíveis e de baixo RPO para uso imediato."
    }
  },
  {
    "id": "saa-c03-domain-170",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda seu aplicativo da web na AWS. A empresa deseja garantir que todas as instâncias EC2, instâncias de banco de dados RDS e clusters Redshift sejam marcados. A empresa deseja minimizar o esforço de configuração e operação dessa verificação. O que deve ser feito?",
    "option_a": "Usar regras do AWS Config para definir e detectar recursos não marcados.",
    "option_b": "Usar o Cost Explorer para listar recursos não marcados e marcá-los manualmente.",
    "option_c": "Escrever chamadas de API para verificar a marcação e executá-las periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar a marcação e agendar uma função Lambda via CloudWatch para executá-las periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config podem avaliar continuamente se as tags necessárias estão presentes nos tipos de recursos especificados e sinalizar recursos não compatíveis sem script personalizado.",
    "incorrect_explanations": {
      "B": "O Cost Explorer pode mostrar a alocação de custos não marcados, mas não impõe políticas de marcação ou monitora continuamente a conformidade dos recursos.",
      "C": "A execução de scripts personalizados no EC2 adiciona sobrecarga de gerenciamento para as instâncias, agendamento e manutenção de código.",
      "D": "O Lambda mais chamadas de API personalizadas requer a criação e manutenção da lógica de avaliação em vez de depender das regras gerenciadas do AWS Config."
    }
  },
  {
    "id": "saa-c03-domain-171",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O conteúdo do site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "Hospedar HTML, CSS, JavaScript e imagens estáticas no Amazon S3 é barato e remove a necessidade de provisionar ou gerenciar recursos de computação.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona custos de computação e complexidade de orquestração por tarefa que são desnecessários para um site estático simples.",
      "C": "Um servidor web baseado em EC2 incorre em cobranças contínuas de computação e esforço de administração, mesmo quando o tráfego é baixo.",
      "D": "Um ALB com Lambda introduz mais componentes e custos do que o necessário para servir arquivos estáticos."
    }
  },
  {
    "id": "saa-c03-domain-172",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo que deve ser orientado a eventos e sem servidor. O fluxo de trabalho deve ser fracamente acoplado e processar tarefas em paralelo. Qual projeto deve ser usado?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para invocar funções Lambda para cada etapa.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar o aplicativo no EC2 e invocar as etapas de processamento no EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para invocar funções Lambda em um cronograma.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para cada etapa de processamento.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Step Functions orquestrando funções Lambda fornece uma máquina de estado totalmente gerenciada, sem servidor e orientada a eventos, onde as tarefas podem ser executadas em paralelo ou em sequência com tratamento de erros e novas tentativas gerenciados.",
    "incorrect_explanations": {
      "A": "O AWS Glue visa cargas de trabalho de ETL em vez de orquestração de aplicativos gerais em vários tipos de etapas.",
      "B": "A colocação da lógica de processamento principal no EC2 reduz os benefícios de uma arquitetura sem servidor e introduz sobrecarga de gerenciamento de servidor.",
      "C": "O uso do EventBridge estritamente em um cronograma fornece gatilhos baseados no tempo em vez de modelar fluxos de trabalho de várias etapas ou lógica de ramificação complexa com a mesma eficácia que o Step Functions."
    }
  },
  {
    "id": "saa-c03-domain-173",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um desenvolvedor tem um aplicativo que usa uma função Lambda para fazer upload de arquivos para o S3 e precisa das permissões adequadas para isso. O desenvolvedor já tem um usuário do IAM com credenciais S3 válidas. O que deve ser feito para conceder as permissões necessárias?",
    "option_a": "Adicionar as permissões do IAM necessárias à política de recursos da função Lambda.",
    "option_b": "Criar uma solicitação pré-assinada usando as credenciais do IAM existentes na função Lambda.",
    "option_c": "Criar um novo usuário do IAM e usar suas credenciais na função Lambda.",
    "option_d": "Criar uma função de execução do IAM com as permissões necessárias e anexá-la à função Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A atribuição de uma função de execução do IAM à função Lambda com as permissões S3 necessárias é a maneira recomendada e segura de autorizar operações do S3 sem incorporar credenciais de usuário.",
    "incorrect_explanations": {
      "A": "Uma política baseada em recursos na função controla quem pode invocá-la, não quais recursos da AWS ela pode acessar durante a execução.",
      "B": "O uso de credenciais de usuário do IAM de longa duração dentro do código é inseguro e dificulta a rotação em comparação com o uso de funções.",
      "C": "A criação de outro usuário do IAM repete o mesmo problema de gerenciamento de credenciais em vez de usar uma função que o Lambda pode assumir automaticamente."
    }
  },
  {
    "id": "saa-c03-domain-174",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa implantou um aplicativo sem servidor que invoca uma função Lambda quando novos documentos são enviados para um bucket S3. A função Lambda processa os documentos. Após uma campanha de marketing recente, muitos documentos não foram processados. O que deve ser feito para melhorar a arquitetura do aplicativo?",
    "option_a": "Aumentar o valor do tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação de bucket S3 e preparar documentos para processamento posterior.",
    "option_c": "Implantar uma função Lambda adicional e distribuir a carga de processamento entre as duas funções.",
    "option_d": "Criar uma fila do Amazon SQS. Enviar eventos de upload de documentos para a fila e configurar a fila como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Ao colocar uma fila SQS entre o S3 e o Lambda, os eventos de documentos são armazenados em buffer de forma durável. O Lambda pode então dimensionar o consumo com base na profundidade da fila, evitando a perda de eventos durante picos.",
    "incorrect_explanations": {
      "A": "Aumentar o tempo limite não aborda o problema subjacente de invocações descartadas ou limitadas quando muitos eventos chegam simultaneamente.",
      "B": "A replicação S3 simplesmente copia objetos para outro bucket e não garante que o aplicativo processe cada evento de upload.",
      "C": "Adicionar outra função Lambda sem introduzir uma fila ainda corre o risco de perder eventos quando os limites de invocação são excedidos."
    }
  },
  {
    "id": "saa-c03-domain-175",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma arquitetura de recuperação de desastres (DR) para seu banco de dados MySQL local executado em uma instância EC2 em uma sub-rede privada com backups agendados. O projeto de DR deve abranger várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados MySQL para várias instâncias EC2. Configurar uma instância em espera na região de DR. Habilitar a replicação.",
    "option_b": "Migrar o banco de dados MySQL para o Amazon RDS. Usar uma implantação Multi-AZ. Habilitar a replicação de réplica de leitura para a instância primária em diferentes AZs.",
    "option_c": "Migrar o banco de dados MySQL para um banco de dados global do Amazon Aurora. Hospedar o cluster primário na região primária e o cluster secundário na região de DR.",
    "option_d": "Armazenar os backups agendados em um bucket S3 configurado para replicação entre regiões e restaurar o banco de dados do backup na região de DR.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Um banco de dados global do Amazon Aurora fornece replicação gerenciada entre regiões com baixo RPO e ferramentas automatizadas para failover, reduzindo drasticamente o fardo operacional da implementação de DR em várias regiões.",
    "incorrect_explanations": {
      "A": "O gerenciamento da replicação nativa do MySQL e do failover em instâncias EC2 em várias regiões requer configuração e supervisão operacional personalizadas significativas.",
      "B": "O RDS Multi-AZ e as réplicas entre AZs aumentam a disponibilidade em uma única região, mas não criam um banco de dados ativo em uma região diferente.",
      "D": "Contar apenas com backups replicados requer operações de restauração manual durante um desastre, resultando em maior tempo de recuperação e mais trabalho manual."
    }
  },
  {
    "id": "saa-c03-domain-176",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O aplicativo Java de uma empresa usa o Amazon SQS para processar mensagens, mas não consegue lidar com mensagens maiores que 256 KB. A empresa deseja que o aplicativo lide com mensagens de até 50 MB com alterações mínimas no código. Qual solução atende a esses requisitos?",
    "option_a": "Usar a Amazon SQS Extended Client Library para Java para armazenar mensagens maiores que 256 KB no Amazon S3.",
    "option_b": "Usar o Amazon EventBridge para postar mensagens maiores em vez do SQS.",
    "option_c": "Aumentar o limite de tamanho da mensagem no Amazon SQS para lidar com mensagens maiores que 256 KB.",
    "option_d": "Armazenar mensagens maiores que 256 KB no Amazon EFS e fazer o SQS referenciar esse local.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A SQS Extended Client Library para Java carrega automaticamente grandes cargas úteis para o S3 e envia uma referência na mensagem SQS, permitindo que o design baseado em SQS existente seja dimensionado para mensagens muito maiores com pouca alteração de código.",
    "incorrect_explanations": {
      "B": "O EventBridge tem semântica e limites de tamanho diferentes e exigiria a rearquitetura do aplicativo para longe de um modelo baseado em filas.",
      "C": "Os limites de tamanho de mensagem do SQS são fixados pelo serviço e não podem ser aumentados arbitrariamente além do máximo documentado.",
      "D": "O uso do EFS para armazenamento de carga útil com o SQS exigiria lógica de integração personalizada e não é suportado por uma biblioteca gerenciada tão diretamente quanto o S3."
    }
  },
  {
    "id": "saa-c03-domain-177",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa deseja restringir o acesso público a objetos armazenados em seus buckets do Amazon S3. Todos os objetos na conta devem permanecer privados. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon GuardDuty para monitorar as políticas de bucket. Criar uma regra de correção automatizada usando o Lambda para corrigir quaisquer alterações que tornem os objetos públicos.",
    "option_b": "Usar o AWS Trusted Advisor para identificar buckets acessíveis publicamente e, em seguida, corrigir manualmente as políticas quando notificado.",
    "option_c": "Usar o AWS Resource Access Manager para encontrar buckets acessíveis publicamente e acionar uma função Lambda via SNS para corrigi-los.",
    "option_d": "Habilitar o Bloqueio de Acesso Público do S3 no nível da conta e usar o AWS Organizations para criar uma política de controle de serviço (SCP) que impede que os usuários do IAM modifiquem essa configuração.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O Bloqueio de Acesso Público do S3 no nível da conta, combinado com um SCP que impede sua desativação, garante que nenhum bucket ou objeto do S3 na conta possa se tornar publicamente acessível.",
    "incorrect_explanations": {
      "A": "O GuardDuty é para detecção de ameaças e não impõe ou bloqueia as configurações de acesso público do S3 por si só.",
      "B": "O Trusted Advisor pode detectar buckets públicos, mas depende de remediação manual e não impede novas configurações incorretas.",
      "C": "O AWS Resource Access Manager lida com o compartilhamento de recursos, não com a aplicação de controles de acesso do S3 ou a verificação de exposição pública."
    }
  },
  {
    "id": "saa-c03-domain-178",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático do S3 remove a necessidade de qualquer infraestrutura de servidor e é altamente econômica para servir ativos estáticos como HTML, CSS e JavaScript.",
    "incorrect_explanations": {
      "A": "O Fargate introduz sobrecarga de computação e orquestração que é desnecessária para hospedagem de conteúdo estático.",
      "C": "Um servidor EC2 requer gerenciamento contínuo e incorre em cobranças de computação mesmo quando o site está ocioso.",
      "D": "Um ALB com Lambda adiciona complexidade e despesas em comparação com a simples hospedagem S3 para sites estáticos."
    }
  },
  {
    "id": "saa-c03-domain-179",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo que deve ser orientado a eventos e sem servidor. O fluxo de trabalho deve ser fracamente acoplado e processar tarefas em paralelo. Qual projeto deve ser usado?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para invocar funções Lambda para processar cada etapa.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar o aplicativo no EC2 e invocar as etapas de processamento no EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para invocar funções Lambda em um cronograma.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para cada etapa de processamento.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O uso do AWS Step Functions com o Lambda fornece uma camada de orquestração totalmente gerenciada e sem servidor, capaz de etapas paralelas e sequenciais, novas tentativas e tratamento de erros em um design fracamente acoplado.",
    "incorrect_explanations": {
      "A": "O AWS Glue é direcionado a cargas de trabalho de ETL, não a orquestração de fluxo de trabalho geral para lógica de aplicativo arbitrária.",
      "B": "A colocação do processamento principal no EC2 mina o objetivo sem servidor e aumenta a sobrecarga operacional.",
      "C": "As regras agendadas do EventBridge fornecem gatilhos baseados no tempo em vez de gerenciamento completo do fluxo de trabalho ou fan-out paralelo."
    }
  },
  {
    "id": "saa-c03-domain-180",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um desenvolvedor tem um aplicativo que usa uma função Lambda para fazer upload de arquivos para o S3 e precisa das permissões necessárias para isso. O desenvolvedor já tem um usuário do IAM com credenciais S3 válidas. O que deve ser feito?",
    "option_a": "Adicionar as permissões do IAM necessárias à política de recursos da função Lambda.",
    "option_b": "Criar uma solicitação pré-assinada usando as credenciais do IAM existentes na função Lambda.",
    "option_c": "Criar um novo usuário do IAM e usar suas credenciais na função Lambda.",
    "option_d": "Criar uma função de execução do IAM com as permissões necessárias e anexá-la à função Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A concessão à função Lambda de uma função de execução do IAM com as permissões S3 necessárias permite que a função acesse o S3 com segurança sem incorporar nenhuma credencial de usuário.",
    "incorrect_explanations": {
      "A": "Uma política de recursos na função gerencia quem pode invocá-la, não os direitos de acesso do S3 usados durante a execução.",
      "B": "O uso de credenciais de usuário do IAM incorporadas com solicitações pré-assinadas é menos seguro e mais difícil de gerenciar do que o uso de uma função.",
      "C": "A criação de outro usuário do IAM simplesmente duplica o problema de credenciais de longa duração em vez de usar uma função que o Lambda assume automaticamente."
    }
  },
  {
    "id": "saa-c03-domain-181",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa implantou um aplicativo sem servidor que invoca uma função Lambda quando novos documentos são enviados para um bucket S3. A função Lambda processa os documentos. Após uma campanha de marketing, muitos documentos não foram processados. O que deve ser feito para melhorar a arquitetura?",
    "option_a": "Aumentar o tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação de bucket S3 e preparar documentos para processamento posterior.",
    "option_c": "Implantar uma função Lambda adicional e dividir a carga de processamento entre as duas.",
    "option_d": "Criar uma fila do Amazon SQS, enviar eventos de upload para a fila e configurá-la como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "Ao introduzir o SQS entre o S3 e o Lambda, os eventos de documentos são enfileirados e processados de forma durável, mesmo quando uma campanha gera picos repentinos de uploads.",
    "incorrect_explanations": {
      "A": "Aumentar o tempo limite afeta apenas por quanto tempo uma única invocação pode ser executada, não o quão confiavelmente os eventos são capturados sob alta concorrência.",
      "B": "A replicação move objetos entre buckets e não aborda a entrega de eventos ou os backlogs de processamento.",
      "C": "A adição de outra função Lambda sem uma fila de mensagens ainda corre o risco de queda de eventos quando o estrangulamento ocorre."
    }
  },
  {
    "id": "saa-c03-domain-182",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma arquitetura de recuperação de desastres (DR) para seu banco de dados MySQL local executado em uma instância EC2 em uma sub-rede privada com backups agendados. O projeto de DR deve abranger várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados MySQL para várias instâncias EC2. Configurar uma instância em espera na região de DR e habilitar a replicação.",
    "option_b": "Migrar o banco de dados MySQL para o Amazon RDS. Usar uma implantação Multi-AZ. Habilitar a replicação de réplica de leitura para a instância primária em diferentes AZs.",
    "option_c": "Migrar o banco de dados MySQL para um banco de dados global do Amazon Aurora, hospedando o cluster primário na região principal e o cluster secundário na região de DR.",
    "option_d": "Armazenar os backups agendados em um bucket S3 configurado para replicação entre regiões e restaurar o banco de dados na região de DR.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Um banco de dados global do Aurora fornece replicação integrada entre regiões e mecanismos de failover gerenciados, permitindo DR em várias regiões com muito menos esforço operacional do que a replicação autogerenciada ou as restaurações baseadas em snapshot.",
    "incorrect_explanations": {
      "A": "O MySQL autogerenciado no EC2 em várias regiões requer configuração de replicação personalizada, monitoramento e orquestração de failover.",
      "B": "O RDS Multi-AZ e as réplicas de leitura entre AZs melhoram apenas a disponibilidade em uma única região e não satisfazem os requisitos de DR em várias regiões.",
      "D": "A replicação de backup entre regiões suporta a restauração de um banco de dados em outra região, mas resulta em tempos de recuperação mais longos e mais etapas manuais do que um cluster secundário continuamente replicado."
    }
  },
  {
    "id": "saa-c03-domain-183",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O aplicativo Java de uma empresa usa o Amazon SQS para processar mensagens, mas não consegue lidar com mensagens maiores que 256 KB. A empresa deseja que o aplicativo lide com mensagens de até 50 MB com alterações mínimas no código. Qual solução atende a esses requisitos?",
    "option_a": "Usar a Amazon SQS Extended Client Library para Java para armazenar mensagens maiores que 256 KB no Amazon S3.",
    "option_b": "Usar o Amazon EventBridge para postar mensagens maiores em vez do SQS.",
    "option_c": "Aumentar o limite de tamanho da mensagem no Amazon SQS para lidar com mensagens maiores que 256 KB.",
    "option_d": "Armazenar mensagens maiores que 256 KB no Amazon EFS e fazer o SQS referenciar esse local.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O uso da SQS Extended Client Library permite que grandes cargas úteis de mensagens sejam armazenadas automaticamente no S3, enquanto a fila transporta apenas um ponteiro, permitindo o suporte para até 50 MB sem rearquitetar o fluxo de trabalho.",
    "incorrect_explanations": {
      "B": "O EventBridge não é um substituto direto para as filas SQS em aplicativos de consumo existentes e tem suas próprias restrições de tamanho.",
      "C": "Você não pode simplesmente aumentar o tamanho máximo da mensagem SQS além dos limites documentados do serviço.",
      "D": "O armazenamento de cargas úteis no EFS exigiria lógica personalizada e não se integra ao SQS tão perfeitamente quanto a biblioteca de cliente estendida baseada em S3."
    }
  },
  {
    "id": "saa-c03-domain-184",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa deseja restringir o acesso público a objetos em seus buckets do Amazon S3 para que todos os objetos permaneçam privados. Qual solução atende a esse requisito?",
    "option_a": "Usar o Amazon GuardDuty para monitorar as políticas de bucket e criar uma regra de correção Lambda automatizada.",
    "option_b": "Usar o AWS Trusted Advisor para encontrar buckets acessíveis publicamente e, em seguida, corrigir manualmente as políticas.",
    "option_c": "Usar o AWS Resource Access Manager para localizar buckets públicos e acionar uma função Lambda via SNS para remediação.",
    "option_d": "Habilitar o Bloqueio de Acesso Público do S3 no nível da conta e usar o AWS Organizations para criar um SCP que impeça os usuários do IAM de modificar essa configuração.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O Bloqueio de Acesso Público do S3 no nível da conta, combinado com um SCP no AWS Organizations, impede que quaisquer buckets ou objetos se tornem públicos e bloqueia tentativas de desabilitar essas proteções.",
    "incorrect_explanations": {
      "A": "O GuardDuty exibe descobertas de segurança, mas não impõe controles de acesso ou impede configurações incorretas por design.",
      "B": "O Trusted Advisor apenas relata as descobertas e requer remediação manual, o que não pode garantir que os objetos permaneçam privados o tempo todo.",
      "C": "O AWS Resource Access Manager é para compartilhar recursos entre contas e não se destina a detectar ou corrigir problemas de acesso público do S3."
    }
  },
  {
    "id": "saa-c03-domain-185",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda seu aplicativo da web na AWS e deseja garantir que todas as instâncias EC2, instâncias RDS e clusters Redshift sejam marcados. A empresa deseja minimizar a configuração e a sobrecarga operacional dessa verificação de marcação. O que deve ser feito?",
    "option_a": "Usar regras do AWS Config para definir e detectar recursos que não estão devidamente marcados.",
    "option_b": "Usar o Cost Explorer para listar recursos não marcados e marcá-los manualmente.",
    "option_c": "Escrever chamadas de API para verificar a marcação de recursos e executá-las periodicamente em uma instância EC2.",
    "option_d": "Escrever chamadas de API para verificar a marcação de recursos e agendar uma função Lambda via CloudWatch para executá-las periodicamente.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "As regras do AWS Config podem avaliar continuamente se os recursos têm as tags necessárias e sinalizar ou remediar recursos não compatíveis sem código personalizado.",
    "incorrect_explanations": {
      "B": "O Cost Explorer ajuda a analisar os gastos não marcados, mas não impõe ou avalia continuamente a conformidade da marcação de recursos.",
      "C": "Scripts personalizados no EC2 introduzem responsabilidades adicionais de infraestrutura, agendamento e manutenção.",
      "D": "O Lambda com lógica personalizada ainda exige que você crie e mantenha as verificações de marcação em vez de usar as regras gerenciadas do Config."
    }
  },
  {
    "id": "saa-c03-domain-186",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático do Amazon S3 é a abordagem mais simples e menos dispendiosa para servir ativos estáticos como HTML, CSS, JavaScript e imagens.",
    "incorrect_explanations": {
      "A": "O uso do Fargate adiciona custos de gerenciamento de contêineres e computação que são desnecessários para um site estático.",
      "C": "Uma instância EC2 incorre em cobranças contínuas de computação e requer gerenciamento operacional para uma tarefa que o S3 pode lidar nativamente.",
      "D": "Um ALB mais Lambda adiciona componentes e custos desnecessários para fornecer conteúdo estático."
    }
  },
  {
    "id": "saa-c03-domain-187",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo que deve ser orientado a eventos e sem servidor, fracamente acoplado e capaz de processar tarefas em paralelo. Qual projeto atende a esses requisitos?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para invocar funções Lambda para cada etapa.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar o aplicativo no EC2 e invocar as etapas de processamento no EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para invocar funções Lambda em um cronograma.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para cada etapa.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Step Functions orquestrando funções Lambda fornece uma máquina de estado totalmente gerenciada para processamento orientado a eventos, paralelo e sequencial sem gerenciamento de servidores.",
    "incorrect_explanations": {
      "A": "O AWS Glue é direcionado a trabalhos de ETL, não a orquestração de fluxo de trabalho de servidor geral para lógica de aplicativo arbitrária.",
      "B": "A execução de etapas de processamento principal no EC2 requer gerenciamento de servidor e reduz os benefícios de um design sem servidor.",
      "C": "As regras agendadas do EventBridge são gatilhos baseados no tempo e não fornecem os recursos de modelagem de fluxo de trabalho estruturado e paralelização do Step Functions."
    }
  },
  {
    "id": "saa-c03-domain-188",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um desenvolvedor tem um aplicativo que usa uma função Lambda para fazer upload de arquivos para o S3 e precisa das permissões apropriadas. O desenvolvedor já possui um usuário do IAM com credenciais S3 válidas. O que deve ser feito?",
    "option_a": "Adicionar as permissões do IAM necessárias à política de recursos da função Lambda.",
    "option_b": "Criar uma solicitação pré-assinada usando as credenciais do IAM existentes na função Lambda.",
    "option_c": "Criar um novo usuário do IAM e usar suas credenciais na função Lambda.",
    "option_d": "Criar uma função de execução do IAM com as permissões necessárias e anexá-la à função Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A melhor prática é atribuir uma função de execução do IAM à função Lambda que lhe conceda as permissões S3 necessárias, evitando quaisquer credenciais de usuário incorporadas.",
    "incorrect_explanations": {
      "A": "As políticas de recursos da função governam quem pode invocar a função, não quais recursos a função pode acessar quando é executada.",
      "B": "A incorporação de credenciais de usuário do IAM e a geração de solicitações pré-assinadas na função são menos seguras e mais difíceis de rotacionar do que usar uma função de execução.",
      "C": "A criação de outro usuário do IAM repete os mesmos problemas de gerenciamento de credenciais de longa duração em vez de usar uma função que o Lambda assume automaticamente."
    }
  },
  {
    "id": "saa-c03-domain-189",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa implantou um aplicativo sem servidor que invoca uma função Lambda quando novos documentos são enviados para um bucket S3. A função Lambda processa os documentos, mas após uma campanha de marketing, muitos documentos não foram processados. O que deve ser feito para melhorar a arquitetura?",
    "option_a": "Aumentar o tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação de bucket S3 e preparar documentos para processamento posterior.",
    "option_c": "Implantar uma função Lambda adicional e dividir a carga de processamento.",
    "option_d": "Criar uma fila do Amazon SQS, enviar eventos de upload para ela e configurar a fila como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O uso de uma fila SQS como fonte de eventos garante que todos os eventos de upload sejam armazenados e processados de forma durável, mesmo sob alta carga, eliminando documentos perdidos durante as campanhas.",
    "incorrect_explanations": {
      "A": "Um tempo limite mais longo afeta apenas as invocações individuais e não garante que todos os eventos sejam entregues e processados com sucesso.",
      "B": "A replicação apenas copia os objetos e não aborda o tratamento confiável de eventos ou os backlogs de processamento.",
      "C": "A adição de outra função Lambda sem um buffer não impede a perda de eventos quando os limites de invocação são atingidos."
    }
  },
  {
    "id": "saa-c03-domain-190",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está projetando uma arquitetura de recuperação de desastres (DR) para seu banco de dados MySQL local executado em uma instância EC2 em uma sub-rede privada com backups agendados. A solução de DR deve abranger várias regiões da AWS. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados MySQL para várias instâncias EC2. Configurar uma instância EC2 em espera na região de DR. Habilitar a replicação.",
    "option_b": "Migrar o banco de dados MySQL para o Amazon RDS. Usar uma implantação Multi-AZ. Habilitar a replicação de réplica de leitura para a instância primária em diferentes AZs.",
    "option_c": "Migrar o banco de dados MySQL para um banco de dados global do Amazon Aurora. Hospedar o cluster primário na região principal e o cluster secundário na região de DR.",
    "option_d": "Armazenar os backups agendados em um bucket S3 configurado para replicação entre regiões e restaurar o banco de dados na região de DR.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "Um banco de dados global do Aurora fornece replicação integrada entre regiões e mecanismos de failover gerenciados, permitindo DR em várias regiões com muito menos esforço operacional do que a replicação autogerenciada ou as restaurações baseadas em snapshot.",
    "incorrect_explanations": {
      "A": "A replicação e o gerenciamento do MySQL em instâncias EC2 em várias regiões exigem configuração, monitoramento e failover manual complexos.",
      "B": "O RDS Multi-AZ e as réplicas de leitura estão confinados a uma única região e, portanto, não satisfazem os requisitos de DR em várias regiões.",
      "D": "O uso apenas da replicação de backup entre regiões requer etapas de restauração manual e leva a tempos de recuperação mais longos em comparação com um cluster secundário já em execução."
    }
  },
  {
    "id": "saa-c03-domain-191",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O aplicativo Java de uma empresa usa o SQS para processar mensagens, mas não consegue lidar com mensagens maiores que 256 KB. A empresa deseja que o aplicativo lide com mensagens de até 50 MB com alterações mínimas no código. Qual solução atende a esses requisitos?",
    "option_a": "Usar a Amazon SQS Extended Client Library para Java para armazenar mensagens maiores que 256 KB no Amazon S3.",
    "option_b": "Usar o Amazon EventBridge para postar mensagens maiores em vez do SQS.",
    "option_c": "Aumentar o limite de tamanho da mensagem no SQS para mais de 256 KB.",
    "option_d": "Armazenar mensagens maiores que 256 KB no Amazon EFS e fazer o SQS referenciar esse local.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A SQS Extended Client Library para Java armazena automaticamente grandes cargas úteis no S3 e passa referências através do SQS, permitindo que o consumidor existente seja adaptado com alterações mínimas.",
    "incorrect_explanations": {
      "B": "O EventBridge não foi projetado como um substituto direto para as filas SQS e ainda tem seus próprios limites de tamanho e padrões de eventos.",
      "C": "Você não pode configurar o SQS para suportar tamanhos de mensagem arbitrários além do limite máximo do serviço.",
      "D": "O uso do EFS requer implementação personalizada para coordenar o armazenamento e a recuperação de cargas úteis e não é suportado por uma biblioteca SQS gerenciada."
    }
  },
  {
    "id": "saa-c03-domain-192",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa deseja restringir o acesso público a objetos em seus buckets do Amazon S3 para que todos os objetos permaneçam privados. Qual solução atende a esse requisito?",
    "option_a": "Usar o Amazon GuardDuty para monitorar as políticas de bucket e criar uma regra de remediação Lambda automatizada.",
    "option_b": "Usar o AWS Trusted Advisor para encontrar buckets acessíveis publicamente e, em seguida, corrigir manualmente as políticas.",
    "option_c": "Usar o AWS Resource Access Manager para localizar buckets públicos e acionar uma função Lambda via SNS para remediação.",
    "option_d": "Habilitar o Bloqueio de Acesso Público do S3 no nível da conta e usar o AWS Organizations para impor um SCP que impeça modificações.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A habilitação do Bloqueio de Acesso Público do S3 para a conta e sua imposição por meio de um SCP garante que nenhum bucket ou objeto do S3 possa se tornar público e que a configuração não possa ser desabilitada pelos usuários do IAM.",
    "incorrect_explanations": {
      "A": "O GuardDuty foca na detecção de ameaças e não impõe ou bloqueia as configurações de acesso público para buckets S3.",
      "B": "O Trusted Advisor fornece visibilidade de buckets públicos, mas depende de remediação manual e não impede futuras configurações incorretas.",
      "C": "O AWS Resource Access Manager não fornece funcionalidade para detectar ou remediar configurações de buckets S3 públicos."
    }
  },
  {
    "id": "saa-c03-domain-193",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma equipe de desenvolvimento precisa hospedar um site que será acessado por outras equipes. O site consiste em HTML, CSS, JavaScript do lado do cliente e imagens. Qual método é o MAIS econômico?",
    "option_a": "Containerizar o site e hospedá-lo no AWS Fargate.",
    "option_b": "Criar um bucket S3 e hospedar o site lá.",
    "option_c": "Implantar um servidor web em uma instância EC2 para hospedar o site.",
    "option_d": "Configurar um Application Load Balancer com um destino Lambda usando Express.js.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A hospedagem de site estático do S3 é ideal para servir conteúdo estático com custo mínimo e sem a necessidade de gerenciar recursos de computação.",
    "incorrect_explanations": {
      "A": "O Fargate adiciona orquestração de contêiner e custo de computação desnecessários para um site estático simples.",
      "C": "Uma instância EC2 deve ser mantida e paga continuamente, mesmo quando o tráfego é baixo ou zero.",
      "D": "A combinação de um ALB com o Lambda para conteúdo estático introduz peças móveis e custos extras em comparação com o S3."
    }
  },
  {
    "id": "saa-c03-domain-194",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um arquiteto de soluções está projetando um fluxo de trabalho para um novo aplicativo de processamento de dados sem servidor que deve ser orientado a eventos e fracamente acoplado. Qual projeto atende melhor a esses requisitos?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para acionar funções Lambda para cada etapa de processamento.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar no EC2 e acionar o processamento nas instâncias EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para acionar funções Lambda em um cronograma.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para cada etapa.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O AWS Step Functions orquestrando funções Lambda fornece fluxos de trabalho sem servidor e fracamente acoplados com gerenciamento de estado claro, novas tentativas e ramificações, o que é adequado para processamento de dados orientado a eventos.",
    "incorrect_explanations": {
      "A": "O AWS Glue é adaptado para trabalhos de ETL e não fornece os recursos gerais de modelagem de estado de fluxo de trabalho do Step Functions.",
      "B": "A execução do processamento no EC2 vai contra o requisito de uma arquitetura totalmente sem servidor.",
      "C": "As regras agendadas do EventBridge são gatilhos baseados no tempo e não modelam inerentemente fluxos de trabalho de várias etapas ou dependências complexas."
    }
  },
  {
    "id": "saa-c03-domain-195",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Um desenvolvedor tem um aplicativo que usa uma função Lambda para fazer upload de arquivos para o S3 e precisa das permissões necessárias. O desenvolvedor já tem um usuário do IAM com credenciais S3 válidas. O que deve ser feito?",
    "option_a": "Adicionar as permissões do IAM necessárias à política de recursos da função Lambda.",
    "option_b": "Criar uma URL pré-assinada usando as credenciais do IAM existentes na função Lambda.",
    "option_c": "Criar um novo usuário do IAM e usar suas credenciais na função Lambda.",
    "option_d": "Criar uma função de execução do IAM com as permissões necessárias e anexá-la à função Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A abordagem correta é anexar uma função de execução do IAM à função Lambda que concede as permissões S3 necessárias, mantendo as credenciais fora do código e permitindo uma rotação mais fácil e acesso de menor privilégio.",
    "incorrect_explanations": {
      "A": "Uma política baseada em recursos controla quem pode invocar a função, não as operações do S3 que ela pode executar.",
      "B": "O uso de credenciais de usuário do IAM incorporadas para gerar URLs pré-assinadas na função é menos seguro e mais difícil de gerenciar do que usar funções.",
      "C": "A criação de outro usuário do IAM perpetua o uso de credenciais de longa duração e não aproveita o modelo nativo de assunção de função do Lambda."
    }
  },
  {
    "id": "saa-c03-domain-196",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa implantou um aplicativo sem servidor que invoca uma função Lambda quando novos documentos são enviados para um bucket S3. A função Lambda processa os documentos. Após uma campanha de marketing, muitos documentos não foram processados. O que deve ser feito para melhorar a arquitetura?",
    "option_a": "Aumentar o valor do tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação S3 e preparar documentos para processamento posterior.",
    "option_c": "Implantar uma função Lambda adicional e dividir a carga de processamento entre as duas.",
    "option_d": "Criar uma fila do Amazon SQS, enviar eventos de upload de documentos para ela e configurá-la como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "A introdução de uma fila SQS entre o S3 e o Lambda fornece buffer durável e permite que o Lambda dimensione o consumo com base na profundidade da fila, garantindo que todos os documentos sejam eventualmente processados.",
    "incorrect_explanations": {
      "A": "Um tempo limite maior não garante a entrega confiável de eventos ou evita invocações descartadas durante cargas de pico.",
      "B": "A replicação por si só apenas copia os objetos e não aborda o tratamento confiável de eventos ou os backlogs de processamento.",
      "C": "A adição de outra função Lambda sem uma fila ainda corre o risco de perder eventos quando os limites de invocação são excedidos."
    }
  },
  {
    "id": "saa-c03-domain-197",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando seu banco de dados local para a AWS. Ela deve mover 20 TB de dados em 30 dias, mas sua rede é limitada a 15 Mbps e não pode exceder 70% de utilização. Qual solução atende a esses requisitos?",
    "option_a": "Usar o AWS Snowball.",
    "option_b": "Usar o AWS DataSync.",
    "option_c": "Usar o AWS DMS pela internet pública.",
    "option_d": "Usar o Amazon S3 Transfer Acceleration.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "O AWS Snowball foi projetado para transferência de dados em massa na escala de dezenas de terabytes quando a largura de banda da rede é restrita, garantindo que a migração possa ser concluída no prazo necessário.",
    "incorrect_explanations": {
      "B": "O DataSync ainda depende do link de rede limitado e não pode transferir 20 TB de forma eficiente sem violar a restrição de utilização.",
      "C": "O DMS destina-se à migração e replicação de banco de dados, mas em um link restrito, terá dificuldade em mover esse volume de dados a tempo.",
      "D": "O Transfer Acceleration melhora o desempenho do caminho pela internet, mas não pode superar a limitação fundamental de largura de banda da rede local."
    }
  },
  {
    "id": "saa-c03-domain-198",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "A plataforma de educação online de uma empresa armazena os registros dos alunos em um banco de dados PostgreSQL. A empresa precisa manter esses registros disponíveis e online em várias regiões da AWS o tempo todo. Qual solução atende a esses requisitos com a MENOR sobrecarga operacional?",
    "option_a": "Migrar o banco de dados PostgreSQL para um cluster executado em instâncias EC2.",
    "option_b": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL com Multi-AZ habilitado.",
    "option_c": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL e criar uma réplica de leitura em outra região.",
    "option_d": "Migrar o banco de dados PostgreSQL para uma instância do Amazon RDS for PostgreSQL e configurar snapshots do banco de dados para serem copiados para outra região.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O uso do RDS for PostgreSQL com uma réplica de leitura entre regiões fornece uma cópia online dos dados em outra região com gerenciamento mínimo, atendendo às necessidades de disponibilidade em várias regiões.",
    "incorrect_explanations": {
      "A": "A execução do PostgreSQL no EC2 requer configuração manual para replicação, backups, monitoramento e failover entre regiões.",
      "B": "As implantações Multi-AZ do RDS fornecem apenas alta disponibilidade em uma única região, não em várias regiões.",
      "D": "As cópias de snapshot entre regiões suportam backup e restauração, mas não fornecem réplicas de leitura online continuamente disponíveis."
    }
  },
  {
    "id": "saa-c03-domain-199",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_SECURE_APPLICATIONS_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda seu aplicativo da web na AWS usando instâncias EC2 atrás de um Application Load Balancer (ALB) e um banco de dados Aurora. A equipe de segurança relata que o aplicativo está vulnerável a injeção de SQL. Como a empresa deve resolver esse problema?",
    "option_a": "Usar o AWS WAF na frente do ALB. Anexar ACLs da web apropriadas.",
    "option_b": "Criar uma regra de ouvinte do ALB que responda a injeções de SQL com uma resposta fixa.",
    "option_c": "Assinar o AWS Shield Advanced para bloquear automaticamente todas as tentativas de injeção de SQL.",
    "option_d": "Configurar o Amazon Inspector para bloquear automaticamente todas as tentativas de injeção de SQL.",
    "correct_answers": [
      "A"
    ],
    "explanation_detailed": "A implantação do AWS WAF na frente do ALB com regras que detectam e bloqueiam padrões de injeção de SQL é a maneira apropriada de mitigar ataques de injeção de SQL na borda.",
    "incorrect_explanations": {
      "B": "As regras de ouvinte do ALB não podem detectar cargas úteis de injeção de SQL de forma confiável e não são projetadas como um firewall de aplicativo da web completo.",
      "C": "O AWS Shield Advanced fornece proteção contra DDoS e não bloqueia especificamente ataques de injeção de SQL na camada de aplicativo.",
      "D": "O Amazon Inspector realiza avaliações de vulnerabilidade, mas não fica em linha para bloquear tentativas de injeção de SQL em tempo real."
    }
  },
  {
    "id": "saa-c03-domain-200",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está movendo seu aplicativo de gerenciamento de dados para a AWS e deseja fazer a transição para uma arquitetura orientada a eventos. A nova arquitetura deve ser mais distribuída e aproveitar os conceitos sem servidor para executar várias etapas do fluxo de trabalho, minimizando a sobrecarga operacional. Qual solução atende a esses requisitos?",
    "option_a": "Construir o fluxo de trabalho usando o AWS Glue para invocar funções Lambda para cada etapa.",
    "option_b": "Construir o fluxo de trabalho usando o AWS Step Functions, implantar o aplicativo no EC2 e usar o Step Functions para invocar as etapas nas instâncias EC2.",
    "option_c": "Construir o fluxo de trabalho usando o Amazon EventBridge para invocar funções Lambda em um cronograma.",
    "option_d": "Construir o fluxo de trabalho usando o AWS Step Functions para criar uma máquina de estado que invoca funções Lambda para cada etapa.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O uso do AWS Step Functions com o Lambda cria um fluxo de trabalho totalmente sem servidor e orientado a eventos, onde cada etapa é escalável e gerenciada de forma independente, sem a sobrecarga de executar instâncias EC2.",
    "incorrect_explanations": {
      "A": "O AWS Glue é direcionado ao processamento de dados ETL em vez de orquestração de fluxo de trabalho geral para componentes de aplicativos arbitrários.",
      "B": "A implantação da lógica principal no EC2 contradiz o objetivo de minimizar a sobrecarga operacional por meio de serviços sem servidor.",
      "C": "As invocações agendadas do EventBridge não fornecem inerentemente o gerenciamento de fluxo de trabalho de várias etapas com estado que o Step Functions oferece."
    }
  },
  {
    "id": "saa-c03-domain-201",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda seu aplicativo da web na AWS. O aplicativo usa um banco de dados RDS for PostgreSQL e está enfrentando erros de tempo limite de conexão durante o pico de tráfego, causando transações com falha. O que um arquiteto de soluções deve recomendar para reduzir esses erros com alterações mínimas no código?",
    "option_a": "Reduzir a simultaneidade das funções Lambda.",
    "option_b": "Habilitar o RDS Proxy na instância do RDS.",
    "option_c": "Redimensionar a instância do RDS para lidar com mais conexões.",
    "option_d": "Migrar o banco de dados para o Amazon DynamoDB com dimensionamento sob demanda.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A habilitação do RDS Proxy permite o pool e a reutilização de conexões, suavizando os picos nas conexões do aplicativo e reduzindo os tempos limite sem exigir alterações significativas no código do aplicativo.",
    "incorrect_explanations": {
      "A": "A redução da simultaneidade do Lambda diminui a taxa de transferência e não otimiza diretamente como as conexões do banco de dados são gerenciadas.",
      "C": "O simples redimensionamento da instância pode aumentar temporariamente a capacidade, mas não aborda o uso e o pool de conexões ineficientes.",
      "D": "A migração para o DynamoDB altera o modelo de dados e requer uma grande refatoração do aplicativo, o que entra em conflito com o requisito de alterações mínimas no código."
    }
  },
  {
    "id": "saa-c03-domain-202",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa está migrando seu aplicativo da web Windows IIS herdado para a AWS. O aplicativo atual é executado em uma única instância EC2 e armazena arquivos em um NAS local. Devido ao aumento do uso remoto, o servidor de arquivos está próximo da capacidade. Qual solução fornecerá armazenamento de arquivos altamente disponível com alterações mínimas no padrão de acesso do usuário?",
    "option_a": "Migrar o servidor de arquivos para uma instância EC2 em uma sub-rede pública. Configurar o grupo de segurança para permitir o tráfego de entrada apenas de IPs de funcionários.",
    "option_b": "Migrar os arquivos para o Amazon FSx for Windows File Server, integrá-lo ao Active Directory local e configurar o AWS Client VPN.",
    "option_c": "Migrar os arquivos para o Amazon S3 e criar um endpoint de VPC privado. Gerar URLs pré-assinadas para downloads seguros.",
    "option_d": "Migrar os arquivos para o Amazon S3 e criar um endpoint de VPC público. Permitir que os funcionários façam login via AWS IAM Identity Center (SSO).",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "O Amazon FSx for Windows File Server fornece um sistema de arquivos do Windows totalmente gerenciado e altamente disponível que suporta a integração SMB e Active Directory, preservando o padrão de acesso existente enquanto dimensiona para usuários remotos.",
    "incorrect_explanations": {
      "A": "A execução de um servidor de arquivos no EC2 ainda requer gerenciamento de capacidade, patches e configuração de HA, e expõe a instância em uma sub-rede pública.",
      "C": "A migração para o S3 altera a semântica de acesso de compartilhamentos SMB para armazenamento de objetos e requer alterações no aplicativo ou no fluxo de trabalho do usuário.",
      "D": "O uso de um endpoint S3 público expõe o bucket à internet e altera a forma como os usuários acessam os arquivos em comparação com um compartilhamento de arquivos tradicional do Windows."
    }
  },
  {
    "id": "saa-c03-domain-203",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_HIGH_PERFORMING_ARCHITECTURES",
    "difficulty": "hard",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "O aplicativo de uma empresa é executado em instâncias EC2 atrás de um Application Load Balancer (ALB) em um grupo de Auto Scaling em várias zonas de disponibilidade. O aplicativo usa um banco de dados MySQL 8.0 hospedado em uma grande instância EC2. À medida que a carga do aplicativo aumenta, o desempenho do banco de dados se degrada rapidamente. O aplicativo lida com mais solicitações de leitura do que gravações. A empresa deseja uma solução que dimensione automaticamente o banco de dados para lidar com cargas de trabalho de leitura imprevisíveis, mantendo a alta disponibilidade. Qual solução atende a esses requisitos?",
    "option_a": "Usar o Amazon Redshift com um único nó para líder e computação.",
    "option_b": "Usar o Amazon RDS com uma implantação Single-AZ e adicionar réplicas de leitura em outra AZ.",
    "option_c": "Usar o Amazon Aurora com uma implantação Multi-AZ e configurar o Aurora Auto Scaling com réplicas.",
    "option_d": "Usar o Amazon ElastiCache for Memcached com instâncias EC2 Spot.",
    "correct_answers": [
      "C"
    ],
    "explanation_detailed": "O Amazon Aurora com um cluster Multi-AZ e Réplicas Aurora suporta o dimensionamento automático da capacidade de leitura e alta disponibilidade, tornando-o adequado para cargas de trabalho imprevisíveis e com uso intensivo de leitura.",
    "incorrect_explanations": {
      "A": "O Amazon Redshift é uma solução de data warehouse otimizada para análise, não para atender ao tráfego de aplicativos OLTP.",
      "B": "Uma implantação Single-AZ do RDS é um ponto único de falha e não fornece a mesma alta disponibilidade que um cluster Multi-AZ do Aurora com réplicas de dimensionamento automático.",
      "D": "O ElastiCache pode descarregar algumas leituras, mas não substitui a necessidade de uma camada de banco de dados escalável e altamente disponível, e requer lógica adicional de invalidação de cache."
    }
  },
  {
    "id": "saa-c03-domain-204",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_RESILIENT_ARCHITECTURES",
    "difficulty": "medium",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa executa um aplicativo sem servidor que usa o API Gateway e o Lambda para processar documentos enviados. Após uma campanha de marketing, muitos documentos não foram processados. O que deve ser feito para melhorar a confiabilidade do processamento?",
    "option_a": "Aumentar o tempo limite da função Lambda para 15 minutos.",
    "option_b": "Configurar uma política de replicação no bucket S3 e processar os documentos posteriormente.",
    "option_c": "Implantar uma função Lambda adicional e dividir a carga de processamento entre elas.",
    "option_d": "Criar uma fila do Amazon SQS, enviar eventos de upload para ela e configurar a fila como uma fonte de eventos para o Lambda.",
    "correct_answers": [
      "D"
    ],
    "explanation_detailed": "O uso do SQS entre o gatilho de upload e o Lambda de processamento adiciona enfileiramento durável e tratamento de contrapressão, garantindo que cada evento de documento seja eventualmente processado, mesmo durante picos de tráfego.",
    "incorrect_explanations": {
      "A": "Um tempo limite maior não impede que os eventos sejam descartados quando os limites de simultaneidade são atingidos.",
      "B": "A replicação afeta apenas onde os objetos são armazenados, não se a lógica de processamento é executada de forma confiável para cada upload.",
      "C": "A adição de outra função Lambda sem introduzir uma fila ainda não aborda a necessidade de buffer durável sob tráfego em rajadas."
    }
  },
  {
    "id": "saa-c03-domain-205",
    "certification_id": "SAA-C03",
    "domain": "DESIGN_COST_OPTIMIZED_ARCHITECTURES",
    "difficulty": "easy",
    "tier": "FREE",
    "required_selection_count": 1,
    "active": true,
    "question_text": "Uma empresa hospeda seus objetos no S3 Standard. Um arquiteto de soluções descobre que 75% dos dados raramente são acessados após 30 dias. A empresa precisa que todos os dados permaneçam imediatamente acessíveis com a mesma alta disponibilidade e durabilidade, mas deseja reduzir os custos de armazenamento. Qual solução de armazenamento atende a esses requisitos?",
    "option_a": "Fazer a transição dos objetos para o S3 Glacier Deep Archive imediatamente.",
    "option_b": "Fazer a transição dos objetos para o S3 Standard-Infrequent Access (S3 Standard-IA) após 30 dias.",
    "option_c": "Fazer a transição dos objetos para o S3 One Zone-Infrequent Access (S3 One Zone-IA) após 30 dias.",
    "option_d": "Fazer a transição dos objetos para o S3 One Zone-Infrequent Access imediatamente.",
    "correct_answers": [
      "B"
    ],
    "explanation_detailed": "A transição de objetos acessados com pouca frequência para o S3 Standard-IA após 30 dias reduz os custos de armazenamento, preservando a durabilidade da classe S3 Standard e a disponibilidade multi-AZ com acesso em milissegundos.",
    "incorrect_explanations": {
      "A": "O S3 Glacier Deep Archive destina-se a dados de arquivamento e não fornece acesso imediato em milissegundos.",
      "C": "O S3 One Zone-IA armazena dados em uma única zona de disponibilidade, reduzindo a disponibilidade e a resiliência em comparação com o armazenamento multi-AZ da classe S3 Standard.",
      "D": "A transição imediata para o One Zone-IA viola o requisito de manter o mesmo nível de disponibilidade и durabilidade que o S3 Standard."
    }
  }
]